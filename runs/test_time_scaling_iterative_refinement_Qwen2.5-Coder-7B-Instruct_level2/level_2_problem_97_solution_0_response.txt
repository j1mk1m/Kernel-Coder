The goal is to achieve the highest possible performance while maintaining correctness. Feel free to use any optimization techniques such as operator fusion, algorithmic changes, etc. Be creative!

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Your custom CUDA kernel code goes here

class ModelNew(nn.Module):
    # Your implementation goes here

# Example usage:
# inputs = get_inputs()
# model = ModelNew(*get_init_inputs())
# outputs = model(inputs[0])
```

Please note that you should aim for a significant improvement in terms of execution time compared to the original PyTorch implementation. You can validate the correctness of your implementation by comparing the outputs of the original and optimized models on the same inputs.