```python
class ModelNew(nn.Module):
    def __init__(self, in_features, out_features, scale_shape, eps=1e-5, momentum=0.1):
        super(ModelNew, self).__init__()
        # Replace nn.Linear with a custom CUDA kernel for matrix multiplication
        self.gemm = CustomGEMM(in_features, out_features)
        # Replace nn.Parameter with a custom CUDA kernel for scaling
        self.scale = CustomScale(scale_shape)
        # Replace nn.BatchNorm1d with a custom CUDA kernel for batch normalization
        self.bn = CustomBatchNorm(out_features, eps=eps, momentum=momentum)

    def forward(self, x):
        x = self.gemm(x)
        x = x * self.scale
        x = self.bn(x)
        return x
```

The output should be a fully functional implementation of the `ModelNew` class using custom CUDA kernels. The code should include the necessary imports, definitions of the custom CUDA kernels, and the implementation of the `CustomGEMM`, `CustomScale`, and `CustomBatchNorm` classes. The code should compile and run without errors.

Please ensure that the custom CUDA kernels are implemented efficiently and accurately, taking into account the specifics of the operations being performed (matrix multiplication, scaling, batch normalization).

Also, please provide any additional information or explanations needed to understand the implementation of the custom CUDA kernels.

### Note:
- The custom CUDA kernels should be designed to take advantage of parallel processing capabilities of GPUs.
- The custom CUDA kernels should be optimized for performance, considering factors such as memory access patterns, thread/block sizes, and warp scheduling.
- The custom CUDA kernels should be tested extensively to ensure correctness and stability under various input conditions.
```