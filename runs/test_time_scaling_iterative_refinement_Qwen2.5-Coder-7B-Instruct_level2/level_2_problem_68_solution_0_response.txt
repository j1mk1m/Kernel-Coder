### Requirements:
- Replace at least one PyTorch operator with a custom CUDA kernel.
- Feel free to replace more than one PyTorch operator with a custom CUDA kernel.
- Consider operator fusion opportunities.
- Ensure that the custom CUDA kernels are implemented correctly and efficiently.

### Note:
- You can use `torch.utils.cpp_extension.load_inline` to compile and load the custom CUDA kernels.

Here's an example of how to use `load_inline`: 

```python
from torch.utils.cpp_extension import load_inline

# Define the CUDA source code
cuda_source = """
// Your CUDA source code here
"""

# Compile and load the CUDA extension
my_cuda_ext = load_inline(name="my_cuda_ext", cuda_sources=cuda_source, functions=["my_cuda_function"])
```

Make sure to include all necessary imports and ensure the code is fully functional when run.