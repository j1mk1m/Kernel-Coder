Please also provide a brief explanation of why each operator was replaced with a custom CUDA kernel. 

Note: Feel free to use any PyTorch functionality, including other modules from `torch.nn` and `torch.nn.functional`, but avoid using PyTorch's autograd engine for backpropagation. If needed, manually implement the backward pass for your custom CUDA kernels.