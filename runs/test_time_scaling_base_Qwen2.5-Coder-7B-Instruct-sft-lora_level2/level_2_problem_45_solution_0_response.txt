Note: Feel free to use any libraries or tools available in PyTorch or elsewhere to help you implement the custom CUDA kernels. For example, you can use `torch.utils.cpp_extension.load_inline` to compile the CUDA code directly within your Python script. 

Also note that while you're encouraged to optimize the entire architecture, it's okay to focus on optimizing just one or two parts of the architecture.

```