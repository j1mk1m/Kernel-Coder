Please ensure that all CUDA kernels are implemented correctly and efficiently. If possible, combine multiple operations into a single kernel to reduce memory bandwidth and improve performance. For instance, you could combine convolutions with batch norms or activations.

If you decide to use PyTorch extensions or other libraries, please include any necessary imports at the beginning of the code snippet. Also, provide a brief explanation of why you chose to implement certain operations using custom CUDA kernels and what optimizations they bring.