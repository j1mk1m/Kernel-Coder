The goal is to optimize the given architecture by replacing certain PyTorch operators with custom CUDA kernels to achieve better performance. Feel free to combine operators, use different algorithms, or implement optimizations as needed.

Please provide the new architecture code with custom CUDA kernels:

```python
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Custom CUDA kernels go here...

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, pool_kernel_size):
        super(ModelNew, self).__init__()
        # Initialize layers and custom CUDA kernels...

    def forward(self, x):
        # Implement forward pass using custom CUDA kernels...
        pass

# Example usage:
if __name__ == "__main__":
    batch_size = 128
    in_channels = 3
    out_channels = 16
    depth, height, width = 16, 32, 32
    kernel_size = 3
    pool_kernel_size = 2

    model_new = ModelNew(in_channels, out_channels, kernel_size, pool_kernel_size)
    inputs = get_inputs()[0].to("cuda")
    outputs = model_new(inputs)
    print(outputs.shape)
```

Ensure that the new architecture `ModelNew` is fully functional and performs the same operations as the original `Model`. The code should be well-documented and easy to understand.