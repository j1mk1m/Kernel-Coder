Consider operator fusion opportunities. The architecture's forward function has two operators: torch.matmul and torch.triu. You can replace both with a single fused kernel. Your kernel can compute the upper triangular part of the matrix product directly without computing the full product. 

The matrices are of size N=4096 which is large, so optimizing for this size is important. Also, the input matrices are upper triangular, so their lower triangular parts are zero. Exploit this structure for optimization. The output matrix must also be upper triangular.

The problem requires you to write a fused CUDA kernel that takes two upper triangular matrices A and B and computes their product's upper triangular part efficiently. The naive approach computes the full product and then takes the upper triangular part, but this is inefficient because the lower triangular part is discarded. Your kernel should compute only the necessary elements.

Specific steps you can take:

1. Observe that since A and B are upper triangular, their product C will also be upper triangular. So, we can compute only the upper triangular part of C. However, even within this, there's a pattern to exploit.

2. For the upper triangular part of C (i.e., indices where row <= column), compute C[i][j] only using the relevant elements of A and B that contribute to it. Since A and B are upper triangular, many terms in the dot product will be zero and can be skipped.

3. The standard matrix multiplication C[i,j] = sum_{k=0}^{N-1} A[i,k] * B[k,j]. However, because A is upper triangular, A[i,k] is zero when k < i. Similarly, B[k,j] is zero when j < k. Hence, the product A[i,k] * B[k,j] is non-zero only when i <= k <= j. Thus, the summation can be restricted to k from i to j.

4. This reduces the number of operations for each C[i,j]. For example, when computing C[0, N-1], you have to sum over all k from 0 to N-1. But for C[i,j] where j - i is small, the summation range is smaller.

5. The total number of operations for the entire upper triangle would then be roughly O(N^3/3), which is better than the O(N^3) for the full matrix multiplication, but still cubic. However, in practice, for upper triangular matrices, the summation can be optimized further.

6. To exploit parallelism, assign each thread or block to compute a specific C[i,j]. The upper triangular indices can be traversed in a way that maximizes coalesced memory access and minimizes divergence.

7. Also, since N is large (4096), shared memory can be used for caching parts of A and B to reduce global memory latency. However, the size of A and B is 4096x4096, so each element is 4 bytes (float), so each matrix is about 64MB. Using shared memory for tiling may be challenging due to limited capacity, but for small tile sizes, it might still be beneficial.

8. Alternatively, since each C[i,j] is independent (the computation doesn't depend on other C[i,j] values), you can compute them in parallel without worrying about dependencies, which is good for CUDA.

Your fused kernel should compute only the upper triangular part of the matrix product, utilizing the sparsity of the input matrices to reduce computation and memory accesses.

Additionally, the output must be an upper triangular matrix, so the kernel can directly store the result in the upper triangular part, leaving the lower triangular part as zeros (or uninitialized, but the function must return a tensor where the lower part is zero).

Please implement this fused kernel. Make sure to handle the indices correctly and avoid out-of-bounds accesses. Also, make sure the kernel is efficient for N=4096.

The kernel should take two input tensors A and B (both upper triangular), and return the upper triangular part of their product. The kernel must be fused, i.e., it should not first compute the full product and then take triu(). 

The kernel must be written in CUDA and called from the ModelNew class using the inline method as in the example. 

The final code should replace the original forward function's two operators with the fused CUDA kernel.



Okay, let's tackle this problem. I need to create a fused CUDA kernel that efficiently computes the upper triangular part of the product of two upper triangular matrices A and B, without computing the full product. The matrices are 4096x4096, which is pretty big, so efficiency is key.

First, I'll think about the structure of upper triangular matrices. Since both A and B are upper triangular, their product C will also be upper triangular. So, I only need to compute elements where the row index is less than or equal to the column index (i <= j). 

The standard matrix multiplication formula is C[i][j] = sum_{k=0}^{N-1} A[i][k] * B[k][j]. But because of the upper triangular nature, A[i][k] is zero when k < i, and B[k][j] is zero when j < k. Therefore, the product term A[i][k] * B[k][j] is non-zero only when i <= k <= j. That means for each C[i][j], the summation can be restricted to k from i to j. This reduces the number of terms in each sum.

So for each element C[i][j], the loop over k can start at k = i and end at k = j. That's a significant optimization. For example, if i and j are close, like in the diagonal area, the number of terms is small. For the farthest elements like (0, N-1), it's still N terms, but on average, this halves the number of operations compared to the full matrix multiplication.

Now, how to parallelize this in CUDA. Each thread can compute a single C[i][j] element. The problem is mapping threads to these (i,j) indices. The upper triangular part has N*(N+1)/2 elements. So maybe we can assign each thread to a specific (i,j) pair where i <= j.

To generate the thread indices, perhaps use a grid of threads where each thread corresponds to an index in a flattened upper triangular matrix. But flattening might complicate things. Alternatively, we can loop over i from 0 to N-1, and for each i, j ranges from i to N-1. So the total threads needed would be the number of elements in the upper triangle.

But in CUDA, threads are arranged in blocks and grids. Let's think about the thread indices. Let's say each thread computes one element of the upper triangular matrix. The total number of elements is (N*(N+1))/2. So maybe we can calculate the 1D thread index and map it to (i,j) pairs. 

Alternatively, using a 2D grid where each block handles a block of i and j. Hmm, but 2D grids can be tricky. Maybe a 1D grid is easier. Let's think of each thread as handling an (i,j) pair where i <= j. 

Wait, perhaps a better way is to loop over all i and j where i <= j, and have each thread compute one such (i,j). To do this, we can use a 1D grid where each thread corresponds to an index in the flattened upper triangle. Let's see:

The total number of elements is (N*(N+1))/2. Let's say the thread index is tid. To find i and j from tid, we can use the formula for triangular numbers. 

Alternatively, loop over all possible i and j in a way that is parallel. But maybe it's simpler to iterate over each i from 0 to N-1, and for each i, iterate over j from i to N-1. The problem is that in CUDA, each thread needs to independently compute its own (i,j). 

Another approach is to have each thread handle a specific (i,j) pair. Let's assign each thread to an index such that for each thread, i = row, j = column, where row <= column. To map a linear thread index to (row, column), perhaps we can use a nested loop structure in the kernel.

Alternatively, here's a method to compute i and j from a thread index:

Suppose the thread index is tid. We can compute i as the largest integer such that (i*(i+1))/2 <= tid. Once i is found, then the column j can be computed as tid - (i*(i+1))/2 + i. 

But calculating this for each thread might be computationally intensive. Maybe precomputing the starting indices for each row would be better, but that might require global memory access which is slower.

Alternatively, use a for loop over rows and columns in a way that's parallel. Hmm, perhaps a better approach is to let each thread compute one row and column pair. Since the number of elements is about 8 million (for N=4096, (4096*4097)/2 ≈ 8 million), we can have a grid of 8 million threads, but that's a lot. CUDA can handle that, but maybe we can find a way to tile or use shared memory for better performance.

Alternatively, we can structure the kernel so that each thread is responsible for a (i,j) pair. Let's see:

Each thread can compute (i,j) where i is the block index and j is the thread index within the block. Wait, perhaps not. Let's think in terms of block and thread indices.

Suppose we have a grid of blocks, each block processes a range of rows. For example, each block processes a single row i. Within the block, each thread handles a j value starting from i up to N-1. 

Let me formalize this. Suppose we have a grid where each block corresponds to a row i. The number of blocks is N. Each block has N threads, but for row i, only threads from i to N-1 are needed. The rest can be inactive. 

Wait, but in CUDA, each block has a fixed number of threads. So for row i, each block (i) would have N threads, but the first i threads would be inactive. That might not be efficient, but perhaps manageable. 

Alternatively, each block can process a block of rows. Let's think of using a 2D grid where blocks are arranged in a grid such that each block handles a range of rows and columns. Hmm, this might get too complex.

Alternatively, let's proceed with the row-wise approach. Let's say each block corresponds to a single row i. The block has N threads, but only the threads with thread index j >= i are active. Each thread in the block with index j computes C[i][j] (since j >= i). 

The block index is i (so blockDim.x = N, gridDim.x = N). But this might not be efficient because blocks with a large number of threads (like 4096) might exceed the maximum threads per block (which is 1024 on many GPUs). So that approach won't work because the block size can't exceed 1024.

Hmm, so need to think differently. Let's consider that each thread computes one element of the upper triangle. So, the total number of threads needed is about 8 million. To handle this, we can structure the grid with a large number of blocks. 

Let me think in terms of a 1D grid. The total number of elements is (N^2 + N)/2. Let's say N=4096. So (4096^2 +4096)/2 = (16,777,216 + 4096)/2 = ~8,388,608 elements. 

We can use a grid of blocks where each block has, say, 256 threads. The total number of blocks needed would be ceil(8388608 / 256) = 32,768 blocks. That's feasible as CUDA can handle up to 65535 blocks in a grid. 

Each thread in the grid can compute a single (i,j) pair. To map the thread index to (i,j), perhaps we can compute the row and column as follows:

The linear thread index is tid = blockIdx.x * blockDim.x + threadIdx.x. 

To find (i,j) for this tid, we can use the triangular number formula. The formula for the triangular number is T(n) = n*(n+1)/2. 

The idea is to find the largest i such that T(i-1) <= tid. Once i is found, then the offset within the row is tid - T(i-1). The column j would be i + offset. 

Wait, let me think. Let me rephrase:

The first row (i=0) has 4096 elements (j from 0 to 4095).

The second row (i=1) has 4095 elements (j from 1 to 4095).

...

The last row (i=4095) has 1 element (j=4095).

So the total up to row i is T(i) = i*(i+1)/2. 

Wait, T(i) is the number of elements up to and including row i. Wait no: the first row (i=0) has 4096 elements (from j=0 to 4095). Wait, no, actually, for row i, the number of elements is (N - i). Because j starts at i and goes up to N-1. So for row i, elements are from j=i to j=N-1. The count is N - i.

Therefore, the total number of elements up to and including row i is sum_{k=0}^i (N - k) = (i+1)*N - (i)(i+1)/2. Hmm, maybe it's easier to think of the cumulative sum.

Alternatively, to map a tid to (i,j):

We can find i such that the cumulative number of elements before row i is less than tid, and the cumulative up to row i is >= tid.

Alternatively, we can use binary search to find i given tid, but that might be computationally expensive per thread. Alternatively, there's a formula to find i given tid.

The cumulative number of elements up to row i is S(i) = sum_{k=0}^i (N -k) = (N+1)(i+1) - (i+1)(i+2)/2. Not sure if that helps.

Alternatively, let's see:

The total elements before row i is S(i-1) = sum_{k=0}^{i-1} (N -k) = N*i - (i)(i-1)/2. 

We need to find the i such that S(i-1) <= tid < S(i). 

Then, once i is found, the position within the row is pos = tid - S(i-1). 

Then j = i + pos.

Wait, let me verify with an example. Let N=4 for simplicity.

Suppose N=4, so rows:

Row 0: j=0,1,2,3 → 4 elements.

Row 1: j=1,2,3 → 3 elements.

Row 2: j=2,3 → 2 elements.

Row3: j=3 →1 element.

Total elements: 10.

Suppose tid is 5:

We need to find i where S(i-1) ≤5 < S(i).

Compute S(0)=0 (sum from k=0 to -1?), wait maybe need to adjust indices.

Wait, for i=0, the cumulative up to row i-1 (i=0, so row -1) is 0. 

Then S(0) = sum_{k=0}^0 (N -k) = N-0 =4. So S(0) is for row 0's elements. Wait, perhaps my formula is incorrect. Let me re-derive.

Wait, S(i) is the number of elements in rows 0 through i.

S(i) = sum_{k=0}^i (N -k)

Let me compute for N=4:

i=0: sum is 4 → S(0)=4.

i=1: 4+3=7 → S(1)=7.

i=2: 7+2=9 → S(2)=9.

i=3: 9+1=10 → S(3)=10.

So for tid=5:

Find i where S(i-1) ≤5 < S(i).

S(-1)=0 ≤5 < S(0)=4 → no.

S(0)=4 ≤5 < S(1)=7 → yes. So i=1.

Then pos=5 - S(0)=5-4=1.

Then j = i + pos → 1 +1=2. 

So for tid=5, the (i,j) would be (1,2). Let's see: row 1 has elements at positions 4,5,6 (since S(0)=4, so row 1 starts at 4). The elements are (1,1)=4, (1,2)=5, (1,3)=6. So yes, 5 corresponds to (1,2), which is correct. 

So the formula works. 

To compute i given tid:

We need to find i such that S(i-1) <= tid < S(i).

But how to compute this efficiently in CUDA without loops? 

We can rearrange the equation for S(i):

S(i) = (N+1)(i+1) - (i+1)(i+2)/2.

Wait, let's see:

sum_{k=0}^i (N -k) = sum_{k=0}^i N - sum_{k=0}^i k = (i+1)*N - (i)(i+1)/2.

Yes, so S(i) = (i+1)(N - (i)/2 )

Wait, more precisely:

S(i) = (i+1)*N - i*(i+1)/2.

We can rearrange this equation to solve for i given S(i) = tid. 

But solving this equation exactly for i might be tricky. Alternatively, approximate with quadratic formula.

We can consider the equation S(i) ≈ tid.

Set S(i) = (i+1)(N - (i+1)/2 ) ≈ tid.

Wait, maybe better to express the equation as quadratic in i:

Let me expand S(i):

S(i) = (i+1)*N - (i)(i+1)/2 = (i+1)(N - i/2).

We can write this as:

S(i) = (i+1)( (2N -i)/2 )

Hmm, maybe better to set S(i) = tid and solve for i numerically. 

Alternatively, use a binary search approach. Since N is 4096, which is manageable. 

Alternatively, approximate:

Let’s approximate S(i) ≈ (i+1)*(N - i/2). 

We can rearrange this to form a quadratic equation in terms of i. Let me try:

S(i) = (i+1)(N - (i)/2) ≈ tid.

Let me set S(i) = tid. 

Expand:

i*N + N - (i^2)/2 - (i)/2 = tid

Rearranged:

-0.5i² + (N -0.5)i + (N - tid) =0

Multiply by -2:

i² - (2N -1)i + (-2)(N - tid) =0

Wait, let me check again:

Original equation after expanding S(i):

S(i) = (i+1)(N - i/2) = tid

=> (i+1)( (2N -i)/2 ) = tid

Multiply both sides by 2:

(i+1)(2N -i) = 2 tid

Expanding:

i*(2N -i) + (2N -i) = 2 tid

2N i -i² + 2N -i = 2 tid

Combine terms:

- i² + (2N -1)i + 2N = 2 tid

Rearranged:

i² - (2N-1)i + (2 tid - 2N) =0

So quadratic equation in i:

i² - (2N-1)i + (2 tid -2N)=0

Solving this quadratic equation for i:

i = [ (2N-1) ± sqrt( (2N-1)^2 -4*1*(2tid - 2N) ) ] / 2

Hmm, but this is a bit messy, but perhaps computationally manageable. 

Alternatively, let's approximate using the quadratic formula. 

Alternatively, maybe use a binary search since N is known. Since for tid up to 8 million, and N is 4096, binary search over i from 0 to N would be feasible. 

Each thread can perform a binary search to find the correct i. Let's see:

Initialize low=0, high=N-1.

While low <= high:

mid = (low + high)/2

Compute S(mid) = (mid+1)*N - (mid*(mid+1))/2.

If S(mid) <= tid: then set low=mid+1.

Else: set high=mid-1.

At the end, i=high.

Wait, let me think through the loop conditions:

Wait, the binary search is looking for the largest i such that S(i) <= tid. 

Wait, perhaps better to structure it to find the correct i. Let me think of an example with N=4 and tid=5 as before:

Looking for i where S(i) <=5 and S(i+1) >5.

Wait S(1)=7>5, so the largest i with S(i) <=5 is i=0 (since S(0)=4 <=5, and S(1)=7>5). Wait no, that contradicts previous example. Wait in that case, S(1)=7>5, but the correct i was 1. Wait, maybe my approach is wrong.

Wait in the example, the correct i was 1 (since S(0)=4 ≤5 and S(1)=7>5, so the i would be 0, but that's not correct. Wait this is confusing.

Wait, in the example where tid=5, the desired i is 1, because the row is i=1. But S(1)=7 is greater than 5, so the previous i where S(i)<=5 is i=0. But that's not correct. 

Hmm, perhaps the binary search is for the row where S(i-1) <= tid < S(i). So, the i is the smallest i where S(i) > tid. 

So the correct i is the first i where S(i) exceeds tid. Then, the row is i-1. Wait, let's see:

For tid=5:

Looking for the smallest i where S(i) >5.

S(0)=4 <=5, S(1)=7>5 → so i=1 is the smallest where S(i) exceeds. So the desired row is i-1 =0?

Wait that would be wrong. 

Hmm, perhaps the correct approach is to find the largest i where S(i) <= tid. 

Wait in the example, the largest i where S(i) <=5 is i=0 (since S(0)=4 ≤5, and S(1)=7>5). But that would point to row 0, but the correct row is 1. 

Ah, I think I messed up the indices here. The cumulative S(i) is the sum up to and including row i. So S(i) is the total number of elements in rows 0 through i. 

So for tid=5, which is in row 1 (the second row), the cumulative up to row 0 (S(0)=4) is less than tid, and cumulative up to row1 (S(1)=7) exceeds tid. So the row is 1. 

So the correct i is the first i where S(i) > tid, so i=1, then the row is i-1? Wait no, the row is i=1. 

Hmm, perhaps the correct row is i where S(i-1) <= tid < S(i). So the row is i. 

Thus, the binary search should find the smallest i where S(i) > tid. Then the row is i. 

So in the example:

Find i where S(i) >5. The smallest such i is 1. So row is i=1. 

Then the offset within the row is tid - S(i-1) =5 -4=1. So j=1+1=2. Which is correct. 

So the steps are:

1. Find the smallest i where S(i) > tid → row is i.

2. offset = tid - S(i-1).

3. j = i + offset.

Thus, to compute this, for each tid:

- Perform a binary search over i from 0 to N-1 to find the smallest i where S(i) > tid.

Once found, the row is i.

Then compute the offset as above. 

But implementing this in CUDA may be slow if done in each thread. Maybe there's a smarter way. Alternatively, precompute an array of cumulative sums and do a lookup, but for N=4096, the array would be 4096 elements, which can be stored in shared memory. Let me think:

The cumulative S(i) for all rows can be precomputed and stored in an array. Then, for a given tid, we can perform a binary search on this array to find the row i. 

The array would have S[0] = N, S[1] = N + (N-1), etc., up to S[N-1] = N*(N+1)/2. 

So, in the kernel, first, the block can load this array into shared memory. But since each thread is independent, perhaps each thread can perform a binary search on the array. 

Alternatively, compute S(i) on the fly during the binary search. 

Hmm, the binary search approach is manageable. Let's see how many iterations it would take. For N=4096, the maximum i is 4095. The binary search would take log2(4096)=12 steps. Each step involves computing S(mid) which requires a few arithmetic operations. That's acceptable. 

So, in the kernel code, for each thread, first compute tid = blockIdx.x * blockDim.x + threadIdx.x. 

Then perform a binary search to find the row i. 

Once i is found, compute the offset. 

Then compute j = i + offset. 

Then, compute C[i][j] by looping over k from i to j, accumulating the product of A[i][k] and B[k][j]. 

Wait, but how do we access A and B?

Each thread will need to read A[i][k] and B[k][j], for k from i to j. 

The problem is that for each (i,j), the thread has to loop over k from i to j, multiply elements from A and B, and sum them. 

So for each thread, the work is O(j -i +1) operations. 

The maximum number of operations per thread is N (when i=0 and j=N-1), which is 4096 operations. That's a lot for a single thread. So this approach might have threads with varying workloads, leading to load imbalance. 

Hmm, that's a problem. Because some threads will have to do 4k operations, others just 1. 

This might cause some threads to take much longer, slowing down the whole kernel. 

Alternative idea: find a way to partition the computation such that each thread has roughly the same amount of work. 

Alternatively, perhaps use a different approach where the threads compute the k loops in a way that the workload is balanced. 

Hmm, but this is getting complicated. Let's think of the basic approach first, even if it has imbalances, and see if it can be optimized later. 

Alternatively, maybe it's better to reorganize the computation so that each thread processes a k value for a range of i and j. But that might be more complex. 

Alternatively, for each (i,j), the summation is over k from i to j. So the number of terms is (j - i +1). 

The worst case is O(N) terms per thread, but the average is O(N/2). 

For N=4096, that's 2048 terms on average per thread. 

But with 8 million threads, that's 8e6 * 2000 operations = 16e9 operations, which may be manageable on a GPU. 

But even so, the load imbalance might be a problem. 

Alternatively, maybe we can find a way to tile the computation or use a different indexing. 

Alternatively, perhaps the kernel can be structured so that each thread processes a block of rows and columns. 

Alternatively, let's proceed with the initial approach, and see. 

So, the steps in the kernel would be:

For each thread:

1. Compute tid.

2. Find row i and column j via binary search.

3. Compute the sum over k from i to j of A[i][k] * B[k][j].

4. Write the result to C[i][j].

Now, the main challenge is to implement the binary search efficiently. 

First, let's code the binary search function in CUDA. 

Let me draft some code:

```cpp
int find_row(int tid, int N) {
    int low = 0;
    int high = N-1;
    int i = -1;
    int mid;
    while (low <= high) {
        mid = (low + high) / 2;
        // Compute S(mid) = (mid+1)*N - mid*(mid+1)/2
        int s = (mid+1)*N - (mid*(mid+1))/2;
        if (s <= tid) {
            low = mid +1;
            i = mid;
        } else {
            high = mid -1;
        }
    }
    // After loop, low is the first i where S(i) > tid
    // So row is low -1 if i was updated? Wait need to think.

    // Wait the code above needs to be adjusted. Let's think again:

    // The loop finds the largest mid where S(mid) <= tid.
    // Wait, perhaps the code is not correct. Let me re-examine.

    // We want to find the smallest i where S(i) > tid. 

    // So initialize low=0, high=N.

    // Wait perhaps better to adjust the code:

    low = 0;
    high = N; // because S(N) is the total elements, which is (N)(N+1)/2. 

    while (low < high) {
        mid = (low + high) / 2;
        int s = compute_S(mid);
        if (s <= tid) {
            low = mid +1;
        } else {
            high = mid;
        }
    }
    // After loop, low is the smallest i where S(i) > tid.
    // So row is (low -1). 

    // Wait let's see:

    // Suppose S(low-1) <= tid < S(low). 

    // So the row is (low-1). 

    return (low -1);
}

int compute_S(int i, int N) {
    return (i+1)*N - (i*(i+1))/2;
}
```

Hmm, maybe this approach. 

But in CUDA code, this function must be inlined or written as a kernel function. 

But since it's per-thread, it can be done inline. 

Once we have the row i, then compute the offset:

int row = low -1;

int offset = tid - compute_S(row, N);

int j = row + offset;

Then, for the loop over k from i to j:

Wait, row is i. So j is row + offset. Wait, no:

Wait, the row is i = row. 

The offset is tid - S(row-1). Wait, no. Let me recheck:

The cumulative up to row (row-1) is S(row-1). 

The offset is tid - S(row-1). 

Then j = row + offset. 

Because in row i=row, the first element is S(row-1), and the elements in row are from j=row to N-1. 

So the offset (starting from 0) corresponds to j = row + offset. 

Yes. 

So now, once we have i=row and j=row+offset, we can proceed. 

Now, compute the sum:

float sum = 0.0f;

for (int k = i; k <= j; ++k) {

    float a = A[i][k]; 

    float b = B[k][j]; 

    sum += a * b;

}

C[i][j] = sum;

But how to access the A and B matrices in CUDA? 

The matrices are stored in row-major order. 

Assuming A and B are stored as 1D arrays (since in CUDA, tensors are contiguous), the element A[i][k] can be accessed as A[i*N + k]. Similarly, B[k][j] is B[k*N + j].

Wait, but in C++, the 2D arrays are stored in row-major, so for a matrix of size N x N, the index for row i and column k would be i*N + k. 

So in the kernel, the threads need to read from A and B as 1D arrays. 

So in the kernel:

float *a_data = A.data_ptr<float>();

float *b_data = B.data_ptr<float>();

Then, the value A[i][k] is a_data[i*N +k].

Similarly for B. 

So in code:

float sum = 0.0f;

for (int k = i; k <= j; ++k) {

    sum += a_data[i * N + k] * b_data[k * N + j];

}

c_data[i * N + j] = sum;

Now, the problem is that for large N (4096), each thread may have a long loop, leading to long execution time and potential thread divergence. 

Hmm, perhaps the loop can be vectorized or unrolled, but for variable loop lengths, that's hard. 

Alternatively, can we precompute some terms or use shared memory to cache parts of A and B? 

Since each thread's loop runs from k =i to j, and i and j vary per thread, it's hard to find a way to tile the matrices. 

Alternatively, maybe the kernel is too inefficient for large N, and we need a better approach. 

Alternative Idea: 

The key observation is that for a given i and j, the summation runs from k =i to j. 

This can be represented as the dot product of the vector A_row[i] from column i to j, and the vector B_col[j] from row i to j. 

Wait, A_row[i] is the row of A starting from column i to N-1, and B_col[j] is the column of B from row i to j. 

Wait, the B column j has elements from row 0 to N-1, but since B is upper triangular, rows before row i would have B[k][j] =0 for k <i. 

Therefore, B's column j from row i to j is non-zero. 

Wait, for B's column j, the entries B[k][j] are non-zero only when k <=j. Since k must also be >=i (from the A's row i), the valid k's are from i to j. 

Thus, the vectors for the dot product are A[i][i..j] and B[i..j][j].

The length of this vector is (j -i +1). 

But how to compute this efficiently in CUDA? 

Another Idea: 

Instead of having each thread compute a single (i,j) element, perhaps process in a way where threads cooperate in a block. 

For example, a block could process a tile of rows and columns, and each thread within the block processes a subset of the elements. 

Alternatively, use tiled matrix multiplication approach, but exploit the upper triangular structure. 

Alternatively, for each element (i,j), the number of terms in the sum is (j -i +1). 

If we can find a way to parallelize the computation of the sum for each (i,j), but that might complicate things. 

Alternatively, precompute all the elements of A and B and then compute the sum in parallel. 

Hmm, perhaps it's better to proceed with the initial approach and see. 

Now, considering memory access patterns. 

In the kernel, each thread is accessing A[i][k], which for a given i, the elements are contiguous from i*N +i to i*N +j. But since i varies, the accesses may be scattered. 

Similarly, B[k][j] is scattered in B's data. 

This might lead to poor memory coalescing, which is a problem. 

Perhaps we can reorganize the computation to have better memory access. 

Alternatively, transpose B so that columns become rows? 

Wait, if B is stored as rows, then B's column j is stored in B[j], B[j + N], etc. Wait, no, in row-major, B's column j is the elements B[0][j], B[1][j], ..., which are stored at positions j, N+j, 2N+j, etc. 

So accessing B[k][j] is a stride access with a stride of N. 

This is not coalesced. 

Hmm, so accessing B in this way may be slow. 

Perhaps we can transpose B and store it in column-major order? But that would require changing how the kernel is written. 

Alternatively, for each thread, when accessing B[k][j], which is B_data[k*N +j], but k varies from i to j. 

Perhaps for a given j, the B elements B[k][j] for varying k can be accessed more efficiently, but I'm not sure. 

Alternatively, this is unavoidable given the problem structure. 

Another Idea: 

The product matrix C's (i,j) entry depends on the rows of A and columns of B in a way that can be expressed as a matrix multiplication of upper triangular matrices. 

There might be a mathematical way to compute this more efficiently, but I can't think of one right now. 

Alternatively, precompute the upper triangular parts and use shared memory. 

Wait, for a block processing a range of rows and columns, they can load a tile of A and B into shared memory, then compute the necessary products. 

But this requires more complex kernel design. 

Alternatively, let's proceed with the initial approach, even if it's not the most optimal, and see. 

Now, writing the CUDA code. 

First, the kernel function:

The kernel will have to be launched with a grid of blocks and threads. 

Assuming that each thread handles one element in the upper triangle. 

The number of threads should be equal to the number of upper triangular elements, which is (N*(N+1))/2. 

The kernel will need to be launched with that number of threads, but in practice, we can compute the grid size as (ceil(num_elements / threads_per_block), 1).

Wait, in CUDA, the grid is specified as dim3(gridDim.x, gridDim.y, gridDim.z). 

Suppose we choose a block size of 256 threads. 

Then the total number of blocks is (num_elements + 255) / 256. 

So in the kernel:

The kernel will have to be something like:

__global__ void upper_triangular_mm(
    const float *A,
    const float *B,
    float *C,
    int N
) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;

    if (tid >= (N*(N+1))/2) {
        return; // out of bounds
    }

    // Find i and j
    int i, j;
    // compute i and j via binary search.

    // ... binary search code here ...

    // Then compute the sum for this i,j.

    float sum = 0.0f;
    for (int k = i; k <= j; k++) {
        sum += A[i * N +k] * B[k * N +j];
    }

    C[i * N +j] = sum;
}

Now, the binary search code must be implemented inside the kernel. 

But let's draft the code for finding i and j. 

Implementing the binary search to find the row i:

int find_row(int tid, int N) {

    int low = 0;
    int high = N;

    while (low < high) {
        int mid = (low + high) / 2;
        int s = (mid +1)*N - mid*(mid+1)/2;
        if (s <= tid) {
            low = mid +1;
        } else {
            high = mid;
        }
    }

    return low -1;
}

Wait, let's test this with the earlier example where N=4 and tid=5:

find_row(5,4):

low=0, high=4.

mid=2. s =3*4 - (3*2)/2 → wait no, s= (2+1)*4 - (2*3)/2 → 3*4=12, 3*2/2=3 → s=12-3=9? Wait N=4, so:

Wait s = (mid+1)*N - (mid*(mid+1))/2.

For mid=2, s= (3)*4 - (2*3)/2 → 12 - 3 =9. 

tid=5 is less than s (9). 

Since s=9 >5 → high=2.

Next loop: low=0, high=2.

mid=1 → s=(2)*4 - (1*2)/2 → 8 - 1 =7. 

7>5 → high=1.

Now low=0, high=1.

mid=0 → s=(1)*4 - (0*1)/2 =4 →4<=5 → set low=1.

Now low=1, high=1 → loop ends.

return low-1=0. 

Wait but the correct row is 1. 

Wait in this example, the result would return low-1 =0, which is wrong. 

Hmm, there's a mistake here. Let's see:

Wait in the example, the correct i (the row) is 1, which is the row where S(i)=7>5. 

The function returns low-1, where low is 1, so 1-1=0. Which is incorrect. 

Hmm, so what's wrong here?

Let me walk through the steps again for N=4, tid=5.

Initial low=0, high=4.

First iteration:

mid=(0+4)/2=2.

s= (2+1)*4 - (2*3)/2 → 3*4=12 minus 3 → 9. 

Since s=9>5 → set high=2.

Now low=0, high=2.

Second iteration:

mid=1 (0+2)/2 =1.

s= (1+1)*4 - (1*2)/2 → 2*4=8 -1 →7>5 → set high=1.

Now low=0, high=1.

Third iteration:

mid=0 (0+1)/2 =0.5 → rounded down to 0.

s= (0+1)*4 - (0*1)/2 →4-0=4<=5 → set low=0+1=1.

Now low=1, high=1. 

Exit loop. 

low is 1, so return low-1 →0. 

But the correct row is 1. 

Hmm, so the function is returning 0, but the correct row is 1. 

So there's a mistake in the logic. 

Wait the function is supposed to return the row where S(i) > tid. The row is (low -1). 

Wait in the example, the correct row is 1 because S(1)=7>5. 

The function's low after the loop is 1. 

So (low-1)=0 → which is not correct. 

Ah, the problem is that the row is low -1? 

Wait, let's think again: 

The loop exits when low == high. 

The value low is the first i where S(i) > tid. 

So the row is (low -1), since S(low-1) <= tid. 

Wait in the example, the correct row is 1, which is exactly low-1 =1-1=0? 

No. 

Wait this is conflicting. 

Wait, in the example, the correct row is 1, but the function returns 0. 

Hmm, so the formula is wrong. 

Wait, the loop is trying to find the first i where S(i) > tid. 

In the example, S(1)=7>5, so i=1 is the first i where this is true. 

Thus, low is 1, so the first i is 1, so the row should be i-1? 

Wait no, the row is exactly i=1. 

Wait, so why is the function returning (low-1)?

Ah, perhaps I made a mistake in the code. 

The function should return low-1? Or low?

Wait if the first i where S(i) > tid is low, then the row is low-1?

No. 

Wait, the row is the first i where S(i) > tid minus 1? 

No. 

Wait in the example, the first i where S(i) > tid is i=1, so the row is i=1. 

Thus, the function should return low, not low-1. 

Let me re-express the code:

The function returns low, not low-1. 

Wait let's re-examine the code. 

The loop is looking for the smallest i where S(i) > tid. 

When the loop exits, low is equal to high, which is the value of i where S(i) > tid. 

So the first i where S(i) > tid is low. 

Thus the row is (low -1)? 

No, the row is (low -1) only if S(low-1) <= tid. 

Wait the row is the i such that S(i) <= tid and S(i+1) > tid. 

Thus, the row is i = low-1. 

Wait let's see:

In the example, low=1, so row is 0? 

No. 

Hmm, this is getting confusing. Let me think with the example. 

The desired row is 1. 

The first i where S(i) >5 is i=1. 

Thus, the row is i-1 =0? That can't be. 

Wait no, the row is exactly i=1. 

Wait the row is the i where S(i-1) <= tid < S(i). 

Thus, the row is i. 

Wait, S(i-1) <= tid < S(i). 

So the row is i. 

The first i where S(i) > tid is the desired i. 

Thus, the row is i. 

Thus, the function should return low. 

Wait in the example, the first i where S(i) >5 is 1, so the row is 1. 

Thus, the function should return low=1. 

Therefore, the code should return low instead of low-1. 

Ah! So the mistake was in the formula. 

So the correct function would return low. 

Wait let's see:

In the example, after the loop, low is 1. 

Thus, row is low → 1. 

Then the offset is tid - S(row-1). 

row is 1 → S(row-1)=S(0)=4. 

offset is 5-4=1 → j =1 +1=2 → correct. 

Yes, that works. 

Thus the code should return low. 

So the function is:

int find_row(int tid, int N) {

    int low =0;

    int high =N; // since S(N) is the total elements.

    while (low < high) {

        int mid = (low + high)/2;

        int s = (mid +1)*N - mid*(mid+1)/2;

        if (s <= tid) {

            low = mid +1;

        } else {

            high = mid;

        }

    }

    return low;

}

Wait, but what if low reaches N?

Suppose tid is the last element (S(N-1) is the total elements minus 1? Or S(N-1) is the total elements. 

Wait the total elements is (N*(N+1))/2. 

Thus, for tid = (N*(N+1))/2 -1, 

the function should return row = N-1. 

Testing:

Let N=4, tid=9 (the last element, since total elements is 10 → indices 0 to9). 

find_row(9,4):

low=0, high=4.

mid=2 → s= (3)*4 - 3 =9 → s= 12-3=9.

tid=9 == s. 

Since s <=9 → set low=mid+1=3.

Now low=3, high=4.

mid=3.5 → 3. 

mid=3. 

s= (4)*4 - 3*4/2 →16 -6=10>9 → set high=3.

Now low=3, high=3 → exit.

return 3. 

Which is correct (row 3, j=3). 

Thus, the function returns the correct row. 

Thus, the code is fixed. 

So the function is returning low, which is the correct row. 

So now, the code for i and j:

i = find_row(tid, N);

int s_prev = compute_S(i-1, N); // S(i-1)

int offset = tid - s_prev;

j = i + offset;

where compute_S is:

int compute_S(int i, int N) {

    return (i+1)*N - (i*(i+1))/2;

}

Wait, but in code, since we can compute it inline. 

Alternatively, since in the find_row function, when we find i, perhaps we can also track S(i-1). But that might be more efficient. 

Alternatively, just recompute s_prev:

int s_prev = (i)*N - (i-1)*i/2;

Wait yes:

compute_S(i-1, N) = ( (i-1)+1)*N - ( (i-1)*i ) /2 → i*N - (i(i-1)/2). 

Thus:

s_prev = i*N - (i*(i-1))/2;

Thus, in code:

int s_prev = i*N - (i*(i-1))/2;

offset = tid - s_prev;

j = i + offset;

Now, this should work. 

Now, the kernel code:

Now, putting it all together. 

The CUDA kernel:

__global__ void upper_triangular_mm(
    const float* A,
    const float* B,
    float* C,
    const int N
) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;

    if (tid >= (N * (N + 1)) / 2) {
        return;
    }

    // Find row i
    int low = 0;
    int high = N;
    while (low < high) {
        int mid = (low + high) / 2;
        int s = (mid + 1) * N - (mid * (mid + 1)) / 2;
        if (s <= tid) {
            low = mid + 1;
        } else {
            high = mid;
        }
    }
    int i = low;

    // Compute S(i-1)
    int s_prev = (i) * N - (i * (i - 1)) / 2;

    int offset = tid - s_prev;
    int j = i + offset;

    // Compute the sum from k = i to j
    float sum = 0.0f;
    for (int k = i; k <= j; ++k) {
        sum += A[i * N + k] * B[k * N + j];
    }

    C[i * N + j] = sum;
}

This is the kernel function. 

Now, the host code needs to load this kernel, and the ModelNew class will call it. 

The input tensors A and B are expected to be upper triangular. 

Now, the kernel uses a 1D grid. 

The number of threads required is (N*(N+1))/2. 

The block size can be chosen, say 256. 

Thus, the number of blocks is ceil(num_elements / 256). 

In the Python code, the kernel is loaded as an inline CUDA extension. 

So, the Python code would be:

First, define the CUDA source code as a string. 

Then, compile it using load_inline.

The code would look like this:

elementwise_add_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void upper_triangular_mm(
    const float* A,
    const float* B,
    float* C,
    const int N
) {
    // ... kernel code as above ...
}
"""

Then, the functions to call it. 

Wait, the kernel is called upper_triangular_mm, so the Python function wrapper would need to set up the kernel launch. 

Wait in the example provided earlier, the Python code for the elementwise addition had a wrapper function elementwise_add_cuda that called the kernel. 

So in this case, we need a Python function that takes A and B tensors, and returns C. 

The wrapper function in CUDA code would be:

torch::Tensor upper_triangular_mm_cuda(torch::Tensor A, torch::Tensor B) {
    int N = A.size(0); // since A is NxN
    auto C = torch::zeros({N, N}, A.options()); // same dtype and device as A

    int num_elements = N * (N + 1) / 2;
    int threads_per_block = 256;
    int blocks = (num_elements + threads_per_block - 1) / threads_per_block;

    upper_triangular_mm<<<blocks, threads_per_block>>>(
        A.data_ptr<float>(),
        B.data_ptr<float>(),
        C.data_ptr<float>(),
        N
    );
    cudaDeviceSynchronize(); // Ensure kernel completes

    return C;
}

Wait, but in CUDA, the <<< >>> syntax is used in the kernel call. 

Wait the wrapper function in the C++ code (for the extension) must launch the kernel with the correct parameters. 

Thus, the complete CUDA source code would include the kernel and the wrapper function. 

So, putting it all together, the CUDA source code (elementwise_add_source) would be:

elementwise_add_source = r"""
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void upper_triangular_mm(
    const float* A,
    const float* B,
    float* C,
    const int N
) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;

    if (tid >= (N * (N + 1)) / 2) {
        return;
    }

    // Find row i
    int low = 0;
    int high = N;
    while (low < high) {
        int mid = (low + high) / 2;
        int s = (mid + 1) * N - (mid * (mid + 1)) / 2;
        if (s <= tid) {
            low = mid + 1;
        } else {
            high = mid;
        }
    }
    int i = low;

    // Compute S(i-1)
    int s_prev = (i) * N - (i * (i - 1)) / 2;

    int offset = tid - s_prev;
    int j = i + offset;

    float sum = 0.0f;
    for (int k = i; k <= j; ++k) {
        sum += A[i * N + k] * B[k * N + j];
    }

    C[i * N + j] = sum;
}

torch::Tensor upper_triangular_mm_cuda(torch::Tensor A, torch::Tensor B) {
    int N = A.size(0);
    auto C = torch::zeros({N, N}, A.options());

    int num_elements = N * (N + 1) / 2;
    int threads_per_block = 256;
    int blocks = (num_elements + threads_per_block - 1) / threads_per_block;

    upper_triangular_mm<<<blocks, threads_per_block>>>(
        A.data_ptr<float>(),
        B.data_ptr<float>(),
        C.data_ptr<float>(),
        N
    );
    cudaDeviceSynchronize();
    return C;
}
"""

Then, the header (cpp_sources) would have the function declaration:

elementwise_add_cpp_source = (
    "torch::Tensor upper_triangular_mm_cuda(torch::Tensor A, torch::Tensor B);"
)

Then, in the Python code, we load this as:

upper_triangular_mm = load_inline(
    name="upper_triangular_mm",
    cpp_sources=elementwise_add_cpp_source,
    cuda_sources=elementwise_add_source,
    functions=["upper_triangular_mm_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)

Wait, but the name passed to load_inline is "upper_triangular_mm", but the function is named upper_triangular_mm_cuda. 

Thus, in the ModelNew class:

class ModelNew(nn.Module):
    def __init__(self):
        super().__init__()
        self.upper_triangular_mm = upper_triangular_mm

    def forward(self, A, B):
        return self.upper_triangular_mm.upper_triangular_mm_cuda(A, B)

Wait, but in the example code, the elementwise_add was imported and used via elementwise_add.elementwise_add_cuda(a, b). 

Thus, the syntax here should be similar. 

Putting it all together, the complete code would be:

```python
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

elementwise_add_source = r"""
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void upper_triangular_mm(
    const float* A,
    const float* B,
    float* C,
    const int N
) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;

    if (tid >= (N * (N + 1)) / 2) {
        return;
    }

    // Find row i
    int low = 0;
    int high = N;
    while (low < high) {
        int mid = (low + high) / 2;
        int s = (mid + 1) * N - (mid * (mid + 1)) / 2;
        if (s <= tid) {
            low = mid + 1;
        } else {
            high = mid;
        }
    }
    int i = low;

    // Compute S(i-1)
    int s_prev = (i) * N - (i * (i - 1)) / 2;

    int offset = tid - s_prev;
    int j = i + offset;

    float sum = 0.0f;
    for (int k = i; k <= j; ++k) {
        sum += A[i * N + k] * B[k * N + j];
    }

    C[i * N + j] = sum;
}

torch::Tensor upper_triangular_mm_cuda(torch::Tensor A, torch::Tensor B) {
    int N = A.size(0);
    auto C = torch::zeros({N, N}, A.options());

    int num_elements = N * (N + 1) / 2;
    int threads_per_block = 256;
    int blocks = (num_elements + threads_per_block - 1) / threads_per_block;

    upper_triangular_mm<<<blocks, threads_per_block>>>(
        A.data_ptr<float>(),
        B.data_ptr<float>(),
        C.data_ptr<float>(),
        N
    );
    cudaDeviceSynchronize();
    return C;
}
"""

elementwise_add_cpp_source = (
    "torch::Tensor upper_triangular_mm_cuda(torch::Tensor A, torch::Tensor B);"
)

upper_triangular_mm = load_inline(
    name="upper_triangular_mm",
    cpp_sources=elementwise_add_cpp_source,
    cuda_sources=elementwise_add_source,
    functions=["upper_triangular_mm_cuda"],
    verbose=True,
    extra_cflags=["-O3"],
    extra_ldflags=[""],
)

class ModelNew(nn.Module):
    def __init__(self):
        super().__init__()
        self.upper_triangular_mm = upper_triangular_mm

    def forward(self, A, B):
        return self.upper_triangular_mm.upper_triangular_mm_cuda(A, B)

```

Wait, but in the example, the function was called via self.elementwise_add.elementwise_add_cuda(a, b). Here, similarly, the function is in the module, so the forward function would call self.upper_triangular_mm.upper_triangular_mm_cuda(A, B).

Yes. 

Now, checking the code for possible issues:

- The kernel uses 1D grid and threads.

- The loop for k from i to j is inside each thread.

- For large N (4096), this loop could be long, leading to long execution time per thread.

- Memory access patterns for B may be non-coalesced (since B[k][j] is accessed with stride N).

- The binary search for i is done per thread, which adds some overhead but manageable.

- The number of threads is about 8 million, which is acceptable.

Possible optimizations:

1. Use shared memory to cache parts of A and B for better memory access. 

For example, each block could load a tile of A and B into shared memory. However, given that the block is processing a single element (i,j), this might not help. 

Alternatively, if threads within a block can cooperate to compute multiple elements, but this requires reorganizing the kernel.

2. Unroll the k loop for small increments, but it's hard for variable ranges.

3. Precompute the row i and j indices on the CPU and pass them as arrays to the kernel. 

But that would require additional memory and may not be worth it. 

4. Optimize the binary search by using a lookup table for the cumulative sums. 

If we precompute an array S[i] = (i+1)*N - i*(i+1)/2 for all i from 0 to N, then the binary search can use this array. 

This array can be stored in __device__ memory. 

But in the current setup, since the kernel is launched with all threads needing to compute S, perhaps precomputing it would be better. 

The kernel can first load S into shared memory, then each thread can perform the binary search on the shared array. 

This could reduce the computation time in the binary search loop. 

To do this:

- In the kernel, have each block load the S array into shared memory. 

- But since each thread needs to access it, this requires that all blocks have access. 

Alternatively, use a static __device__ array. 

But for dynamic N (though in this problem N is fixed to 4096), we can precompute it once. 

In the wrapper function upper_triangular_mm_cuda, before launching the kernel, compute the S array and store it in a static __device__ array. 

Alternatively, compute it in the kernel once per block. 

This would be more complex but could speed up the binary search. 

But for simplicity, perhaps leave it as is for now, as the code is functional.

Potential issues in the current code:

- The kernel may have a lot of divergence in the binary search loops, since each thread is doing different numbers of iterations. 

- The for loop for k is sequential and may be slow for large ranges. 

- Memory access to B is with stride N, which may be slow. 

Possible optimization for B's access:

Notice that B is also upper triangular. So B's elements B[k][j] are zero when k > j. 

Wait, no: B is upper triangular, so B[k][j] is zero if k > j. But in our case, k is between i and j. Since i <= j, and k ranges from i to j, then for B's elements B[k][j], since k <=j (because k <=j), B[k][j] is non-zero only when k <=j, which it is. 

Thus, B[k][j] is valid. 

But the access pattern for B is B[k][j], which for varying k and fixed j is scattered. 

Hmm. 

Another Idea: 

Since B is upper triangular, B can be stored in a packed format where only the upper triangle is stored. 

But in the current setup, the user passes full tensors, so we can't assume that. 

Thus, the code as is accesses the full matrices, but only uses the upper triangle. 

Thus, the current code should work correctly. 

Testing the code:

In the forward function, when A and B are upper triangular, the result C should also be upper triangular. 

The kernel correctly computes only the upper triangular elements and leaves the lower as zero (since C is initialized with zeros, and only the upper is computed). 

Thus, the code should work. 

Now, the final code as per the user's instructions should be enclosed in markdown codeblocks. 

The user also mentioned to not output testing code, so the code provided should be the complete ModelNew class with the fused kernel. 

Thus, the final answer is the Python code above, formatted in a code block.
</think>

```python
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

elementwise_add_source = r"""
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void upper_triangular_mm(
    const float* A,
    const float* B,
    float* C,
    const int N
) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;

    if (tid >= (N * (N + 1)) / 2) {
        return;
    }

    // Find row i
    int low = 0;
    int high = N;
    while (low < high) {
        int mid = (low + high) / 2;
        int s = (mid + 1) * N - (mid * (mid + 1)) / 2;
        if (s <= tid) {
            low = mid + 1;
        } else {
            high = mid;
        }
    }
    int i = low;

    // Compute S(i-1)
    int s_prev = (i) * N - (i * (i - 1)) / 2;

    int offset = tid - s_prev;
    int j = i + offset;

    float sum = 0.0f;
    for (int k = i; k <= j; ++k) {
        sum += A[i * N + k] * B[k * N + j];
    }

    C[i * N + j] = sum;
}

torch::Tensor upper_triangular_mm_cuda(torch::Tensor A, torch::Tensor B) {
    int N = A.size(0);
    auto C = torch::zeros({N, N}, A.options());

    int num_elements = N * (N + 1) / 2;
    int threads_per_block = 256;
    int blocks = (num_elements + threads_per_block - 1) / threads_per_block;

    upper_triangular_mm<<<blocks, threads_per_block>>>(
        A.data_ptr<float>(),
        B.data_ptr<float>(),
        C.data_ptr<float>(),
        N
    );
    cudaDeviceSynchronize();
    return C;
}
"""

elementwise_add_cpp_source = (
    "torch::Tensor upper_triangular_mm_cuda(torch::Tensor A, torch::Tensor B);"
)

upper_triangular_mm = load_inline(
    name="upper_triangular_mm",
    cpp_sources=elementwise_add_cpp_source,
    cuda_sources=elementwise_add_source,
    functions=["upper_triangular_mm_cuda"],
    verbose=True,
    extra_cflags=["-O3"],
    extra_ldflags=[""],
)

class ModelNew(nn.Module):
    def __init__(self):
        super().__init__()
        self.upper_triangular_mm = upper_triangular_mm

    def forward(self, A, B):
        return self.upper_triangular_mm.upper_triangular_mm_cuda(A, B)
```