The new code should have the same API as the original code. I will test it by loading it and running the original test code. 

Make sure the new model's forward() returns the same shape as the original. 

Only replace the pytorch operators with your own implementation. Don't replace the nn.Module or other infrastructure code. 

You can import other pytorch modules as needed. 

The input tensor x has shape (batch_size, in_channels, height, width). 

The output tensor should have the same shape except in_channels is replaced by out_channels. 

The original code uses a 1x1 Conv2d operator. You can implement this as a custom CUDA kernel. 

You can also consider fusing other operations if you want. 

Your code will be compiled with torch.utils.cpp_extension.load_inline. 

You can choose to implement the 1x1 convolution as a GEMM or as a custom element-wise kernel. 

Make sure that your code handles bias if bias=True. 

You may need to handle broadcasting and striding, but in the given architecture, the convolution is pointwise (kernel_size=1, stride=1, padding=0). 

Consider the computation pattern of pointwise convolutions and how to optimize it.


<think>
Okay, I need to optimize the given PyTorch model that uses a pointwise 2D convolution (1x1 Conv2d) by replacing it with a custom CUDA kernel. Let me think through the steps required here.

First, I remember that a 1x1 convolution in 2D is essentially a linear transformation applied to each spatial location. Since the kernel size is 1, there's no spatial filtering, just a channel-wise transformation. So for each position (h, w), the input channels are transformed into output channels via a matrix multiplication. 

The standard PyTorch implementation uses a Conv2d layer, which under the hood probably uses a GEMM (General Matrix Multiply) optimized for this case. But maybe writing a custom kernel can offer better performance, especially for large input sizes. The given input dimensions are 16x64x1024x1024, which is quite big. 

The key here is to structure the computation efficiently. Since it's a 1x1 convolution, the spatial dimensions (height and width) can be flattened, turning the problem into a batched matrix multiplication. Let me see: the input has shape (batch, in_channels, H, W). If we reshape it to (batch, in_channels, H*W), then transpose to (H*W, in_channels, batch), and then multiply by the weight matrix (out_channels x in_channels), we can get the output. 

Alternatively, another way is to treat each spatial location as a separate vector. Since all spatial positions are independent, we can process them all at once. The total number of elements in the spatial dimensions is H*W. The weights are a matrix of size [out_channels, in_channels]. So for each element in the spatial grid, the output channels are computed by multiplying the input channels (a vector of length in_channels) with the weight matrix, resulting in a vector of length out_channels. 

So the computation can be viewed as a matrix multiplication between the reshaped input (batch * H * W, in_channels) and the weight matrix (in_channels, out_channels). The output would then be (batch * H * W, out_channels), which can be reshaped back to (batch, out_channels, H, W). 

This suggests that the core computation is a GEMM (matrix multiply), so using CUDA's cuBLAS might be efficient, but if we want to write a custom kernel, perhaps we can exploit the structure better. However, writing a custom CUDA kernel for GEMM might be challenging unless we can vectorize or find a way to parallelize it efficiently. 

Alternatively, since each spatial location is independent, the kernel can process each spatial position in parallel. For each input element (over batch, height, width), the computation is: 

output[b, oc, h, w] = sum_{ic} (input[b, ic, h, w] * weight[oc, ic]) + bias[oc]

This can be parallelized across all spatial positions and batches. 

So each thread can handle one output element (per spatial position and batch). Let me think about the CUDA kernel structure. 

The input is a tensor of shape (B, Cin, H, W). The weights are (Cout, Cin). The output is (B, Cout, H, W). 

The total number of elements to process is B * H * W. For each of these elements, we have to compute Cout values. 

Wait, actually, for each spatial position (h, w) and each batch element, we compute all Cout channels. So the total number of operations is B*H*W*Cout*Cin. 

The naive approach is to loop over all these indices in the kernel. But that might be inefficient. 

Alternatively, we can structure the kernel to handle each (h, w) and batch as a thread block, and each thread compute a Cout element. Hmm, not sure. 

Alternatively, we can process each spatial position's computation as follows: 

Each thread block can be assigned to a spatial position (h, w). Then, each thread in the block can handle a batch element and an output channel. 

Alternatively, since the spatial dimensions are large (1024x1024), the number of spatial positions is 1,048,576. That's a lot, so we need to handle that efficiently. 

Perhaps the best approach is to use a kernel that for each output element (b, oc, h, w), computes the value. 

The index can be computed as a single linear index, which can be mapped to the 4D coordinates. 

The kernel would need to loop over the input channels (Cin) for each output channel (oc). 

The kernel's pseudocode might look like this:

for each output position (b, h, w):
    for each output channel oc:
        sum = 0
        for ic in 0..Cin-1:
            sum += input[b][ic][h][w] * weight[oc][ic]
        if bias is present:
            sum += bias[oc]
        output[b][oc][h][w] = sum

This approach has O(Cin*Cout*B*H*W) operations, which is O(64*128*16*1024^2) for the given parameters. That's a lot, but maybe we can vectorize or find a way to parallelize more efficiently. 

But writing this in CUDA might be straightforward. Let's see how to structure it. 

First, the input is stored in (B, Cin, H, W) order. In CUDA, memory layout is row-major, so the strides might be important. However, in PyTorch, tensors are stored in contiguous memory, so the access pattern needs to consider the strides. 

Alternatively, we can transpose the input to (B, H, W, Cin) and then flatten B, H, W into a single dimension. Let me think. 

Let me think of the input tensor as a 4D tensor. To compute the output, each spatial element (h, w) across all batches can be treated independently for each output channel. 

The key is to have each thread compute one output element (b, oc, h, w). 

The grid size would be the total number of output elements, which is B * Cout * H * W. 

But that might be too large, as grid dimensions have limits (max threads per block is 1024, max grid dimensions are 2^31-1 in each dimension). For the given parameters, B=16, Cout=128, H=1024, W=1024: total elements are 16*128*1024*1024 â‰ˆ 2,147,483,648. Which is over 2 billion. That might exceed the maximum grid size if using 1D grid. 

Alternatively, we can structure the grid and blocks more cleverly. Let's think in terms of blocks and threads. 

The total number of spatial positions is H*W (1,048,576). The batch size is 16, so per spatial position, there are 16 batches. The output channels are 128. 

So the total work is (H*W) * B * Cout. 

Perhaps we can structure the grid such that each block handles a spatial position and a batch. Then, each thread in the block computes an output channel. 

Let me think:

Block dimensions: let's say each block handles one spatial (h, w) and a batch. 

The number of blocks would be H * W * B. 

Each block would have threads equal to Cout (or a multiple thereof for better occupancy). 

But Cout is 128, so a block of 128 threads can handle each output channel. 

Wait, but 128 threads per block is manageable. Let me see:

Each block (h, w, b) has threads for each output channel. 

Each thread in the block (thread_id) would be responsible for one output channel (oc = thread_id). 

Then, for each thread, it can compute the sum over input channels. 

The steps for each thread would be:

1. Compute the input value for each ic in input[b, ic, h, w].
2. Multiply by weight[oc, ic], accumulate sum.
3. Add bias[oc] if applicable.
4. Write to output[b, oc, h, w].

The problem here is that for each oc, the thread has to loop over all ic (64 times). 

The loop over ic can be done in a loop within the thread. 

This approach could work. Let's see the CUDA code structure.

First, the kernel function:

__global__ void pointwise_conv_kernel(const float* input, const float* weight, const float* bias, float* output, 
    int B, int Cin, int Cout, int H, int W) {

    // Get the spatial position (h, w)
    int w = blockIdx.x % W;
    int h = (blockIdx.x / W) % H;
    int batch = blockIdx.x / (H * W);

    // Thread id corresponds to output channel
    int oc = threadIdx.x;

    // Only handle if within Cout
    if (oc >= Cout) return;

    float sum = 0.0f;
    for (int ic = 0; ic < Cin; ++ic) {
        // Input is [B, Cin, H, W]
        int input_idx = batch * Cin * H * W + ic * H * W + h * W + w;
        sum += input[input_idx] * weight[oc * Cin + ic];
    }

    if (bias) {
        sum += bias[oc];
    }

    // Output is [B, Cout, H, W]
    int output_idx = batch * Cout * H * W + oc * H * W + h * W + w;
    output[output_idx] = sum;
}

Wait, but the blockIdx.x here is per spatial position and batch? Let me think:

The block index is blockIdx.x, which can be up to (B*H*W) -1. 

Each block processes one (batch, h, w). 

The threads in the block process each output channel (up to Cout). 

Thus, the gridDim.x should be B*H*W, and each block has blockDim.x = Cout (or the next power of two, but ideally exactly Cout if possible). 

Wait, but the blockDim.x must be a power of two? Not necessarily, but the CUDA programming guide says that the block dimensions can be any number up to 1024. 

If Cout is 128, then that's acceptable. 

The problem here is that for B=16, H=1024, W=1024, the total number of blocks is B*H*W = 16*1024*1024 = 16,777,216. 

CUDA's maximum grid size in 1D is 2^31-1 (about 2.1 billion), so 16 million is acceptable. 

Each block has 128 threads, which is okay. 

The kernel would have to be launched with:

dim3 blocks(B * H * W);
dim3 threads(Cout); 

But wait, if Cout is not a multiple of the threads per block, then some threads in the block would be inactive (since oc >= Cout). 

Alternatively, we can use a block size that is a power of two and handle it with a loop, but perhaps for simplicity, we can set the threads per block to exactly Cout. 

Wait, but in CUDA, the maximum number of threads per block is 1024. Since Cout here is 128, that's okay. 

So this approach should work. 

Now, the input and output pointers must be in contiguous memory. So in PyTorch, we have to ensure that the input tensor is contiguous. 

In the forward function, the input is passed as a tensor, so we can call .contiguous() if necessary. 

The weight is a matrix of size [Cout, Cin], and the bias is a vector of size [Cout]. 

So, in the CUDA code, we need to pass these tensors. 

Now, handling the bias: 

If the model is initialized with bias=True, then the bias is present. 

In the kernel, we need to check if bias is not null. 

In the code, the parameters for the kernel would be:

elementwise_add_kernel<<<...>>>(input_ptr, weight_ptr, bias_ptr, output_ptr, B, Cin, Cout, H, W);

Wait, in the kernel function definition, the parameters must be passed in the correct order. 

Now, the code in Python would look like this:

First, define the CUDA source code for the kernel. 

But wait, in the example given earlier, the user used a kernel function with a grid and block structure, and a separate launcher function. 

So the structure would be similar to the example. 

Another point: when the input tensor is in (B, C, H, W) layout, the index calculation for input is correct. 

But in the kernel's input access: 

input_idx = batch * Cin * H * W + ic * H * W + h * W + w 

Yes. Because the input tensor is stored in row-major order. 

Similarly for output_idx. 

Now, the problem with this kernel is that if Cin is large (like 64), the loop over ic can take time. But since each thread's loop is independent, it's unavoidable. 

Alternatively, we can unroll the loop if Cin is a constant, but since it's variable, that might not be possible. 

Another optimization could be to use shared memory to cache the weights or inputs, but for Cin=64, it might not be worth it. 

Alternatively, since the weight matrix is the same for all spatial positions and batches, perhaps we can transpose it and precompute, but the kernel as written already accesses it in a way that for each oc, ic, the weight[oc*Cin + ic] is accessed. 

Wait, the weight is stored as [Cout, Cin], so for a given oc, the row is contiguous. 

The loop over ic for a given oc will access contiguous memory in the weight array, which is good for cache. 

So that's okay. 

Now, handling the bias: 

If there's a bias, each thread adds it once. 

Now, in the PyTorch model's __init__, we have to save the weight and bias as parameters. 

Wait, in the original model, the Conv2d layer has parameters. So in the new model, we need to have our own parameters. 

Wait a second! Oh right, in the original code, the model uses nn.Conv2d, which has its own parameters (weight and bias). 

In the new model, we need to replace the Conv2d with our own parameters. 

Therefore, in the ModelNew class, instead of using nn.Conv2d, we need to store the weight and bias as parameters. 

So the original code's __init__:

def __init__(self, in_channels, out_channels, bias=False):
    super().__init__()
    self.conv1d = nn.Conv2d(...)

In the new model, we need to do:

def __init__(self, in_channels, out_channels, bias=False):
    super().__init__()
    self.weight = nn.Parameter(torch.empty(out_channels, in_channels))
    if bias:
        self.bias = nn.Parameter(torch.empty(out_channels))
    else:
        self.register_buffer('bias', None)  # Or handle in kernel as null.

    # Initialize the parameters as per Conv2d initialization
    nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
    if bias:
        fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
        bound = 1 / math.sqrt(fan_in)
        nn.init.uniform_(self.bias, -bound, bound)

Wait, the original Conv2d's initialization is done via kaiming uniform for weights and uniform for bias. 

Therefore, in the new model's __init__ we have to initialize the parameters similarly to the original Conv2d. 

Otherwise, the weights won't match, and the outputs would differ, which is a problem. 

So the user must ensure that the parameters are initialized in the same way as the original Conv2d layer. 

Therefore, in the new ModelNew class, the parameters must be set up correctly. 

Therefore, the new code must:

1. In the __init__ method, create parameters for weight and bias (if applicable), with the same initialization as the original Conv2d.

2. In the forward method, call the custom CUDA kernel using these parameters. 

So putting this all together, the code would look like this:

First, define the CUDA kernel code. 

The CUDA source code would be something like:

#include <torch/extension.h>
#include <cuda_runtime.h>

template <typename T>
__global__ void pointwise_conv_kernel(const T* input, const T* weight, const T* bias, T* output,
    int B, int Cin, int Cout, int H, int W) {
    int w = blockIdx.x % W;
    int h = (blockIdx.x / W) % H;
    int batch = blockIdx.x / (H * W);

    int oc = threadIdx.x;

    if (oc >= Cout) return;

    T sum = static_cast<T>(0);
    for (int ic = 0; ic < Cin; ++ic) {
        int input_idx = batch * Cin * H * W + ic * H * W + h * W + w;
        sum += input[input_idx] * weight[oc * Cin + ic];
    }

    if (bias) {
        sum += bias[oc];
    }

    int output_idx = batch * Cout * H * W + oc * H * W + h * W + w;
    output[output_idx] = sum;
}

void pointwise_conv_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, torch::Tensor output,
    int B, int Cin, int Cout, int H, int W) {
    // Launch the kernel
    const int threads = Cout; // Each thread handles one output channel
    const int blocks = B * H * W;

    AT_DISPATCH_FLOATING_TYPES(input.type(), "pointwise_conv_cuda", ([&] {
        pointwise_conv_kernel<scalar_t><<<blocks, threads>>>(
            input.data<scalar_t>(),
            weight.data<scalar_t>(),
            bias.defined() ? bias.data<scalar_t>() : nullptr,
            output.data<scalar_t>(),
            B, Cin, Cout, H, W);
    }));

    // Check for errors
    cudaError_t err = cudaGetLastError();
    if (err != cudaSuccess) {
        printf("Error in pointwise_conv_kernel: %s\n", cudaGetErrorString(err));
    }
}

Wait, but in the kernel, the blockDim.x must be at least the maximum thread index. Since Cout can be 128, which is okay as the block size. 

Wait, the threads parameter is set to Cout, so the block dimension is blockDim.x = Cout. 

But for example, if Cout is 128, that's within the limit (max 1024). 

Now, in the kernel function, the threadIdx.x can go up to Cout-1, so all are valid. 

The function pointwise_conv_cuda is the launcher. 

Now, in the Python code, we need to define this as an inline CUDA extension. 

The code would look like this:

First, define the CUDA source as a string. 

pointwise_conv_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

template <typename T>
__global__ void pointwise_conv_kernel(const T* input, const T* weight, const T* bias, T* output,
    int B, int Cin, int Cout, int H, int W) {
    int w = blockIdx.x % W;
    int h = (blockIdx.x / W) % H;
    int batch = blockIdx.x / (H * W);

    int oc = threadIdx.x;

    if (oc >= Cout) return;

    T sum = static_cast<T>(0);
    for (int ic = 0; ic < Cin; ++ic) {
        int input_idx = batch * Cin * H * W + ic * H * W + h * W + w;
        sum += input[input_idx] * weight[oc * Cin + ic];
    }

    if (bias) {
        sum += bias[oc];
    }

    int output_idx = batch * Cout * H * W + oc * H * W + h * W + w;
    output[output_idx] = sum;
}

void pointwise_conv_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, torch::Tensor output,
    int B, int Cin, int Cout, int H, int W) {
    const int threads = Cout; // Each thread handles one output channel
    const int blocks = B * H * W;

    AT_DISPATCH_FLOATING_TYPES(input.type(), "pointwise_conv_cuda", ([&] {
        pointwise_conv_kernel<scalar_t><<<blocks, threads>>>(
            input.data<scalar_t>(),
            weight.data<scalar_t>(),
            bias.defined() ? bias.data<scalar_t>() : nullptr,
            output.data<scalar_t>(),
            B, Cin, Cout, H, W);
    }));

    cudaError_t err = cudaGetLastError();
    if (err != cudaSuccess) {
        printf("CUDA error: %s\\n", cudaGetErrorString(err));
    }
}
"""

Then, the corresponding C++ header (the function declaration):

pointwise_conv_cpp_source = """
void pointwise_conv_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, torch::Tensor output,
    int B, int Cin, int Cout, int H, int W);
"""

Then, load this inline:

pointwise_conv = load_inline(
    name="pointwise_conv",
    cpp_sources=pointwise_conv_cpp_source,
    cuda_sources=pointwise_conv_source,
    functions=["pointwise_conv_cuda"],
    verbose=True,
)

Now, the ModelNew class needs to have the parameters and forward function. 

Wait, in the original Model class, the parameters are stored in the Conv2d layer. So in the new ModelNew class, we need to create the parameters ourselves. 

So the __init__ function of ModelNew will be:

class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, bias: bool = False):
        super().__init__()
        self.weight = nn.Parameter(torch.empty(out_channels, in_channels))
        if bias:
            self.bias = nn.Parameter(torch.empty(out_channels))
        else:
            self.register_buffer('bias', None)  # Or maybe set to a None tensor?

        # Initialize the weight and bias like Conv2d
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if bias:
            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in)
            nn.init.uniform_(self.bias, -bound, bound)

        # Also, need to load the CUDA function
        self.pointwise_conv = pointwise_conv  # The module from load_inline

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Get the dimensions
        B, Cin, H, W = x.shape
        Cout = self.weight.size(0)
        assert Cin == self.weight.size(1), "Input channels must match weight dimensions"

        # Create output tensor
        output = torch.empty(B, Cout, H, W, device=x.device, dtype=x.dtype)

        # Call the CUDA kernel
        self.pointwise_conv.pointwise_conv_cuda(
            x.contiguous(),
            self.weight.contiguous(),
            self.bias.contiguous() if self.bias is not None else torch.tensor([], device=x.device),
            output,
            B, Cin, Cout, H, W
        )

        return output

Wait, but in the kernel function, the weight is passed as a tensor, and the bias as well. 

Wait, in the CUDA function pointwise_conv_cuda, the parameters are torch::Tensor weight and bias. So in the Python code, the bias can be passed as self.bias if it's present, or a dummy tensor if not. 

But in the code above, when bias is None, we pass a tensor with no elements. But in the kernel code, we check if bias is defined. 

Wait, in the C++ code, the bias is passed as a tensor, and in the kernel launcher, we do:

bias.defined() ? bias.data... : nullptr 

Wait, but in the Python code, if bias is None, then we can pass a tensor that is not defined. However, the code above passes a tensor with no elements. 

Wait, perhaps better to check in Python whether self.bias is present. 

In the forward function, the code would be:

if self.bias is not None:
    bias_tensor = self.bias
else:
    bias_tensor = torch.tensor([], device=x.device)

Then pass that to the kernel. 

Alternatively, in the kernel function, if bias is a tensor with zero elements, then we can treat it as not present. 

Alternatively, in the C++ code, when bias is not defined, we can pass a nullptr. 

Wait in the Python code, the function signature is:

pointwise_conv_cuda(input, weight, bias, output, ...)

So when bias is None, perhaps we can pass it as a tensor that is not present. 

Wait, the kernel launcher in C++ checks if bias.defined() before accessing. 

In the Python code, if the bias is None, we can pass an empty tensor, but in C++, the bias.defined() would return false if the tensor is empty? 

Wait, no. The bias tensor in PyTorch is defined even if it's empty. So perhaps in the Python code, when there's no bias, we should pass a None, but the kernel expects a tensor. 

Hmm, this might be a problem. 

Wait, the function in C++ expects a torch::Tensor. If in Python, we pass a None, that would be a problem. 

Therefore, in the Python code, when there is no bias, we need to pass an empty tensor. However, in the kernel code, we can check if bias.defined(). 

Wait, in PyTorch, a tensor with zero elements is still a valid tensor. So even if it's empty, bias.defined() would return true. 

Hmm, so perhaps in the Python code, when there is no bias, we can pass an empty tensor, but in the kernel, check if the tensor's numel() is zero. 

Alternatively, in the C++ code, we can check if the bias tensor's numel() is zero. 

Alternatively, perhaps the best way is to pass a None in the Python code when there's no bias, but in C++, the function expects a Tensor, so we can't pass None. 

Hmm, so perhaps the Python code should pass the bias tensor if it exists, else pass a tensor with zero elements but also check in the kernel if the pointer is null. 

Wait, in the kernel launcher, when bias is not present, in Python code, set:

bias = torch.tensor([], device=x.device) 

Then in the C++ code, when bias.defined() is true, but the tensor has size zero. So we can check the size in the kernel. 

Alternatively, in the kernel function, the pointer is passed as:

bias.defined() ? bias.data<scalar_t>() : nullptr

Wait, in the code above, the launcher does:

bias.defined() ? bias.data<scalar_t>() : nullptr

So in the C++ code, if the bias tensor is not defined (i.e., if it's not present in the parameters), then the pointer is null. 

But in the Python code, when the bias is not present, how do we pass a tensor that is not defined? 

Wait, perhaps in the Python code, when there is no bias, the bias parameter is passed as a tensor that is None, but in PyTorch, that's not allowed. So in Python, the function expects a tensor. Therefore, we need to pass a tensor, even if it's empty. 

Wait, perhaps the solution is to pass the bias tensor as self.bias if it exists, else pass an empty tensor. 

Wait, in the __init__ of ModelNew, when bias is False, we have self.bias = None. 

Wait no, in the code I wrote earlier, when bias=False, self.register_buffer('bias', None). But in PyTorch, you can't have a None buffer. Alternatively, perhaps set self.bias to None and in forward check for that. 

Wait, in PyTorch, parameters can be None. So in the __init__ function:

if bias:
    self.bias = nn.Parameter(torch.empty(out_channels))
else:
    self.bias = None

Then, in forward:

if self.bias is not None:
    bias_tensor = self.bias
else:
    bias_tensor = torch.tensor([], device=x.device)

Then, in the kernel launcher, the code will check if bias is defined. 

Wait, but in C++, when we pass an empty tensor, bias.defined() is true. So the kernel will think there is a bias but with size 0. 

Hmm, this is a problem. 

Alternative approach: in the kernel launcher, when there is no bias, pass a tensor that is not defined. But how? 

Alternatively, in the C++ code, the third parameter is a torch::Tensor, but in the kernel, if the bias is not present, then the pointer is null. 

Wait, perhaps in the C++ code, the bias tensor can be passed as an optional. 

Alternatively, in the Python code, when there is no bias, we can pass a None, but in the C++ code, the function must accept that. 

Wait, perhaps I need to rework the kernel launcher function to accept an optional bias. 

Alternatively, perhaps the function can be written in C++ to handle the bias as an optional. 

Wait, let me adjust the C++ code:

Modify the pointwise_conv_cuda function to accept a torch::Tensor bias, and check if it's defined. 

Wait, in the code above, that's already done. 

Therefore, in Python, when there is no bias, we can pass an empty tensor, but in the C++ code, the check for bias.defined() would be true (since the tensor is present), but then the code would try to access the data, which may have incorrect size. 

Wait, no. The bias tensor, when bias is not present, has to have a size of [Cout]. 

Wait, this is a problem. Because the kernel expects that if bias is present, it's a tensor of size [Cout]. 

Therefore, in the case when there is no bias, the bias tensor must be passed as an empty tensor, and the kernel will not use it. 

But in the code above, the kernel would add bias[oc], but if the tensor is empty, then accessing bias[oc] would be out of bounds. 

Therefore, the correct way is to pass a null pointer when the bias is not present. 

To do that in the C++ code, the bias tensor must be optional. 

Hmm, perhaps in the Python code, when bias is not present, we can pass a tensor with no elements, but in the C++ code, we can check if the bias tensor's numel() is zero. 

Wait, in the kernel launcher:

if (bias.defined() && bias.size(0) == Cout) { 

then use the bias. 

But this requires knowing Cout. 

Alternatively, perhaps the kernel code can check if the bias is null. 

Wait, in the C++ code, the pointer is set to nullptr when bias is not passed. 

Wait, in the Python code, when the bias is not present, then in the function call, we can pass a None. 

Wait, but in the C++ code, the function expects a torch::Tensor. 

Wait, perhaps the function can be modified to accept an optional. 

Alternatively, perhaps in the Python code, when there's no bias, we can pass an empty tensor with 0 elements. 

Wait, let me think again. 

The kernel function requires that if the bias is present, it is a 1D tensor of size Cout. 

In the __init__ of ModelNew, when bias is False, the self.bias is None. 

In the forward function:

bias_tensor = self.bias if self.bias is not None else torch.tensor([], device=x.device)

Then, when passing to the CUDA function, the bias is either a tensor of size [Cout] or empty. 

In the C++ code, the kernel launcher can check if the bias tensor has a size of Cout. 

Wait, but how to get Cout in C++? 

Alternatively, in the kernel code, if the bias is not null, then the code adds bias[oc]. 

But if the bias tensor has size zero, then accessing bias[oc] is invalid. 

Therefore, to avoid this, the C++ code should check whether the bias tensor's numel() is zero. 

Wait, in the kernel launcher code, perhaps before launching the kernel, we can check if the bias tensor's numel() is zero and set the pointer to null if so. 

Wait, the C++ launcher can do:

if (bias.defined() && bias.size(0) == Cout) {
    // proceed
} else {
    // set bias pointer to null
}

Wait, but how to know Cout? 

Wait, Cout is passed as an argument to the launcher function. 

Ah, right. The launcher function has parameters:

void pointwise_conv_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, torch::Tensor output,
    int B, int Cin, int Cout, int H, int W)

Therefore, the launcher can check if the bias tensor's size(0) is Cout, and if not, treat it as not present. 

Wait, but when bias is not present, the user should have passed a tensor of size 0. 

Alternatively, in the launcher code:

if (bias.defined()) {
    if (bias.size(0) != Cout) {
        throw std::runtime_error("Bias size must match output channels");
    }
}

But the user will ensure that when bias is present, it's correct. 

In the case when there is no bias, the user should pass an empty tensor. 

Alternatively, perhaps the best way is in Python code, when no bias, pass a tensor with zero elements, and in the kernel, check if the bias's numel() is zero. 

Wait, but how do I get the numel() in the kernel launcher? 

Wait, in the launcher code:

if (bias.defined()) {
    if (bias.size(0) != Cout) {
        // error
    }
    // else proceed
} else {
    // bias is not present
}

Wait, but in Python, when the user passes a tensor with zero elements, bias.defined() is true but the size is zero. 

Hmm, perhaps the Python code should pass None when bias is not present. 

Wait, but the function expects a torch.Tensor. 

Wait, perhaps the Python code can pass the bias as a tensor, but when no bias, pass a tensor with zero elements. 

Wait, no, because that would have a size of 0, which is not equal to Cout. 

Hmm, this is a problem. 

Alternative approach: 

In the C++ code, the kernel launcher can check if the bias tensor is defined and has a size of Cout. 

Wait, in the launcher code:

if (bias.defined()) {
    if (bias.size(0) != Cout) {
        throw std::runtime_error("Bias must have size equal to output channels");
    }
}

Then, in the kernel function:

if (bias) {
    sum += bias[oc];
}

Wait, but in the case when there's no bias, then in Python, we can pass an empty tensor. 

Wait, no. If there is no bias, the user should not pass a tensor, but the function requires it. 

Hmm, this is getting complicated. 

Perhaps the solution is to have the Python code, when there is no bias, pass an empty tensor but in the kernel, only add the bias if the bias tensor's numel() is equal to Cout. 

Alternatively, perhaps the kernel code can check whether the bias pointer is null. 

Wait, the current kernel code has:

if (bias) {
    sum += bias[oc];
}

Here, "bias" is a pointer. So if the pointer is null, then it's skipped. 

Therefore, in the launcher code:

const T* bias_ptr = bias.defined() ? bias.data<scalar_t>() : nullptr;

Then, pass bias_ptr to the kernel. 

Wait, in the kernel function, the parameters would be:

const T* bias,

So in the launcher code:

pointwise_conv_kernel<scalar_t><<<blocks, threads>>>(
    input.data<scalar_t>(),
    weight.data<scalar_t>(),
    bias.defined() ? bias.data<scalar_t>() : nullptr,
    output.data<scalar_t>(),
    B, Cin, Cout, H, W);

This way, if bias is not defined, the kernel gets a null pointer, and the if (bias) check will skip the addition. 

In Python code, when there is no bias, we can pass a tensor that is not defined? 

Wait, no. 

Wait, in Python, the function requires passing a tensor. So if the bias is not present, perhaps pass a tensor with zero elements. But then, in C++, the bias.defined() is true. 

Therefore, the solution is to have the Python code pass None when there is no bias, but that's not allowed. 

Ah, right! In PyTorch, the tensors are always defined, so passing a tensor with zero elements is okay. But the launcher code needs to check if bias is present. 

Wait, but how do I know in the launcher whether the user intended to have a bias or not? 

Ah, this is a problem. 

Wait, perhaps the kernel's bias argument should be optional. 

Alternatively, maybe the Python code should pass a tensor of size Cout, even if no bias. 

Wait, but when bias is not present, the kernel should not add anything. 

Hmm. Let me think again. 

In the __init__ of the new model, when bias=False, the user does not have a bias parameter. 

Therefore, in the forward function, when the bias is not present, the Python code should pass a tensor with zero elements. 

Wait, but then, in the launcher code, bias.defined() is true, so the kernel would try to read the bias data. 

This is a problem. 

Alternatively, the Python code can pass the bias as None, but in C++, the function must accept a torch::Tensor. 

Hmm. 

Wait, perhaps in the __init__ function, when there's no bias, we can create a buffer that is a dummy tensor of size zero, and pass that. 

Alternatively, perhaps the kernel can be adjusted to take an optional bias pointer. 

Wait, maybe the Python code should pass the bias as a tensor, and if it's not present, the tensor is empty. Then, in the kernel, if the bias tensor has zero elements, we don't use it. 

Wait, but in that case, in the kernel code, we can check if the bias pointer is null, but how to get the size? 

Alternatively, in the kernel code, the bias pointer is passed as:

const T* bias = ... 

Then, if the pointer is null, we don't add the bias. 

But in Python, when no bias is present, the code needs to pass a tensor that is not defined, but PyTorch doesn't allow that. 

Hmm, maybe I need to change the kernel function to take an optional parameter. 

Alternatively, perhaps the Python code can pass a tensor with a single element, but set to zero when no bias is present. 

Wait, but that would add a zero bias, which is not correct. 

Hmm, this is getting a bit stuck. Let me think of a different approach. 

Maybe the problem can be sidestepped by always including the bias in the parameters, but when bias=False, set the bias to zero and not require gradient. 

Wait, but the user may want to have no bias at all. 

Alternatively, in the kernel, if the bias is not present, we just don't add anything. 

Thus, in the Python code, when there's no bias, the bias tensor can be an empty tensor. 

In the kernel, the code can check if bias is null. 

Therefore, in the C++ code, when there's no bias, we pass a null pointer. 

To do that, in the Python code:

if self.bias is not None:
    bias_tensor = self.bias
else:
    bias_tensor = None 

Wait, but the function requires passing a Tensor. 

Hmm. 

Wait, perhaps the solution is to make the bias tensor optional in the kernel function. 

Alternatively, in the kernel function, the bias can be passed as an optional. 

Wait, in the C++ code, the function can be written as:

void pointwise_conv_cuda(torch::Tensor input, torch::Tensor weight, torch::optional<torch::Tensor> bias, torch::Tensor output, ... )

But in the current setup, the code uses:

functions=["pointwise_conv_cuda"], 

and the parameters must be tensors. 

Alternatively, in the Python code, when there is no bias, we can pass an empty tensor. 

Wait, in the launcher code, we can check if the bias has a numel() of zero. 

Wait, in the launcher code:

if (bias.defined()) {
    if (bias.size(0) != Cout) {
        throw ... 
    }
    // proceed
} else {
    // treat as no bias
}

Wait, but in Python, when passing an empty tensor, the .defined() is true. 

Hmm. 

This is a problem. 

Maybe the solution is to have the Python code pass the bias tensor as None when not present. 

Wait, but in the C++ function, the parameter is a torch::Tensor. 

Ah! Perhaps the Python code can pass a None, but in the C++ function, the first argument is a torch::Tensor, so that would cause an error. 

Hmm, maybe I need to restructure the code so that the bias is an optional parameter. 

Alternatively, perhaps I can modify the kernel launcher function to accept a bias tensor and a flag indicating whether it's present. 

But that complicates the interface. 

Alternatively, perhaps I should just set the bias to zero when it's not present. But that would change the computation. 

Hmm. 

Alternatively, perhaps the problem can be handled by the user ensuring that when bias is not present, the bias tensor has zero elements. 

Wait, but then the kernel code will crash when accessing it. 

Hmm, this is getting too stuck. Let me try to proceed with the code and see if there's a way around it. 

Alternatively, in the Python forward function:

if self.bias is not None:
    bias_tensor = self.bias
else:
    bias_tensor = torch.tensor([], device=x.device)

Then, in the C++ code, the kernel checks if the bias tensor is defined and has the correct size. 

Wait, in the launcher code:

if (bias.defined()) {
    if (bias.size(0) != Cout) {
        throw ... 
    }
    // proceed with bias
} else {
    // no bias
}

Wait, but if the user passes an empty tensor (size 0), then the first condition is true (bias.defined()), but bias.size(0) is 0, which is not equal to Cout. So this would throw an error. 

Therefore, to prevent that, the user must not pass an empty tensor when bias is not present, but pass a tensor that is not defined. 

But in Python, how to do that? 

Alternatively, the user can pass a tensor with size Cout but initialized to zero when there's no bias. But that's not correct. 

Hmm. 

This is a problem that needs to be addressed. 

Perhaps the best approach is to structure the kernel to take an optional bias, and in the Python code, when bias is not present, pass an empty tensor but check in the kernel. 

Alternatively, perhaps the kernel can accept a bias tensor and a flag indicating whether it's present. 

But that requires adding another parameter to the kernel function. 

Alternatively, perhaps in the kernel function, the bias is an optional parameter. 

Wait, in the C++ code, the kernel launcher can pass a nullptr for bias when it's not present. 

In Python, the function can be written to pass a None, but the kernel function expects a tensor. 

Wait, perhaps the solution is to use a tensor with no elements (size zero), and in the kernel, check whether the bias pointer is null. 

Wait, but in Python, when passing a None, the function would throw an error. 

Hmm. 

Alternatively, perhaps in the kernel code, the bias is optional, and the kernel will only use it if the pointer is non-null. 

Thus, in Python, when there is no bias, the code passes a tensor with no elements, but the pointer is passed as null. 

Wait, how to do that? 

Wait, the Python code can pass a tensor that is not present, but the function requires it. 

Hmm, perhaps this is a dead end. Let me try to proceed with the code and see if there's a way to handle it. 

Alternatively, perhaps I can modify the kernel code to check if the bias tensor has enough elements. 

Wait, in the launcher:

const T* bias_ptr = bias.defined() ? bias.data<scalar_t>() : nullptr;

Then, in the kernel, the check is if (bias_ptr) { ... }

Thus, if the user passes an empty tensor (size 0), then bias.defined() is true, but the bias.size(0) is zero, so bias_ptr is valid but the indices may go out of bounds. 

Thus, to prevent that, the Python code must ensure that when bias is present, it has the correct size. 

Therefore, the Python code should pass the bias tensor when it's present, and when not present, pass a None, but in the C++ code, how to handle that. 

Wait, perhaps in the Python code, when no bias, the code can pass a tensor with zero elements, and in the kernel, the code checks if the bias has at least Cout elements. 

But that's not possible in the kernel. 

Hmm. 

Perhaps it's better to proceed with the code and assume that the user passes the correct parameters. 

In the ModelNew's __init__:

When bias is False, self.bias is None. 

In the forward function:

bias_tensor = self.bias if self.bias is not None else torch.tensor([], device=x.device)

Thus, when there is no bias, the bias tensor is an empty tensor. 

In the C++ kernel launcher:

if (bias.defined()) {
    if (bias.size(0) != Cout) {
        throw std::runtime_error("Bias size must match output channels");
    }
    // proceed
} else {
    // no bias
}

Wait, but when the bias is an empty tensor (size 0), then bias.defined() is true but the size is zero. 

Thus, the error is thrown. 

Hmm. 

So this approach won't work. 

Therefore, perhaps the Python code should pass a None when there's no bias. 

But how to do that in PyTorch? 

Wait, in Python, the function can be written to accept a None for the bias, but in the C++ code, the kernel expects a tensor. 

Hmm. 

Alternatively, perhaps the kernel can be modified to take an optional bias. 

Wait, in the C++ code, the function signature can have an optional parameter. 

Like:

void pointwise_conv_cuda(torch::Tensor input, torch::Tensor weight, torch::optional<torch::Tensor> bias, torch::Tensor output, ... )

Then, in Python, when there's no bias, we can pass None as the third argument. 

But I'm not sure if PyTorch's cpp extension supports optional tensors. 

Looking it up: 

The torch.utils.cpp_extension documentation says that functions can have optional parameters using the torch::optional type in C++. 

Yes, so perhaps that's the way to go. 

Let me adjust the C++ code. 

First, modify the kernel launcher function to take an optional bias:

void pointwise_conv_cuda(torch::Tensor input, torch::Tensor weight, torch::optional<torch::Tensor> bias, torch::Tensor output,
    int B, int Cin, int Cout, int H, int W) {

    const int threads = Cout;
    const int blocks = B * H * W;

    AT_DISPATCH_FLOATING_TYPES(input.type(), "pointwise_conv_cuda", ([&] {
        const T* bias_ptr = bias.has_value() ? bias->data<scalar_t>() : nullptr;
        pointwise_conv_kernel<scalar_t><<<blocks, threads>>>(
            input.data<scalar_t>(),
            weight.data<scalar_t>(),
            bias_ptr,
            output.data<scalar_t>(),
            B, Cin, Cout, H, W);
    }));

    // Error checking
}

Then, the function declaration in the C++ header:

pointwise_conv_cpp_source = """
void pointwise_conv_cuda(torch::Tensor input, torch::Tensor weight, torch::optional<torch::Tensor> bias, torch::Tensor output,
    int B, int Cin, int Cout, int W, int H);
"""

Wait, also, the order of parameters may need to be adjusted. 

Now, in the Python code, when calling the function:

bias_tensor = self.bias if self.bias is not None else torch::optional<torch::Tensor>()

Wait, in Python, to pass an optional, you can pass None, and the C++ function will see it as torch::nullopt. 

Wait, the Python code can do:

bias_param = self.bias if self.bias is not None else torch.utils.dlpack.to_dlpack(torch.tensor([], device=x.device))  # Not sure. 

Alternatively, when calling the function:

if self.bias is not None:
    bias = self.bias
else:
    bias = None 

Then, in the function call:

pointwise_conv.pointwise_conv_cuda(
    x.contiguous(),
    self.weight.contiguous(),
    bias,  # passed as None
    output,
    B, Cin, Cout, H, W
)

Wait, but in C++, the third argument is a torch::optional<torch::Tensor>. 

Therefore, in Python, passing None would map to torch::nullopt. 

Yes, this should work. 

Thus, this is the correct way. 

Therefore, the C++ code needs to have the optional parameter. 

So the kernel launcher function is modified as above. 

Now, in the Python forward function:

def forward(self, x: torch.Tensor) -> torch.Tensor:
    B, Cin, H, W = x.shape
    Cout = self.weight.size(0)
    assert Cin == self.weight.size(1), "Input channels must match weight dimensions"

    output = torch.empty(B, Cout, H, W, device=x.device, dtype=x.dtype)

    bias = self.bias if self.bias is not None else None 

    self.pointwise_conv.pointwise_conv_cuda(
        x.contiguous(),
        self.weight.contiguous(),
        bias,
        output,
        B, Cin, Cout, H, W
    )

    return output

Wait, the kernel launcher in C++ takes the parameters in the order:

input, weight, bias (optional), output, B, Cin, Cout, H, W 

Wait, in the current setup, the kernel launcher function's parameters are:

input, weight, bias (optional), output, B, Cin, Cout, H, W 

So the parameters are passed correctly. 

Now, the CUDA code should be correct. 

Another thing to consider: the kernel uses threadIdx.x to index the output channels. 

The block size is set to Cout, which must be <= 1024. 

In the given example, Cout is 128, so it's okay. 

But if Cout were larger than 1024, this would fail. 

However, the problem specifies to optimize the given architecture, and the given parameters have Cout=128, so it's okay. 

Another point: the kernel assumes that the input and output tensors are contiguous and in the correct memory layout. 

Thus, in the forward function, we must call .contiguous() on the input and weight tensors to ensure they are stored in contiguous memory. 

The output is created as an empty tensor, which should be contiguous. 

Now, putting all together, the code should work. 

Now, the ModelNew class should have the parameters initialized correctly. 

The initialization of the weight and bias must match that of the original Conv2d layer. 

In the original code, the Conv2d's weight initialization is done via the default initialization (kaiming_uniform_ with a=sqrt(5)). 

The bias initialization is uniform between -1/sqrt(fan_in) and 1/sqrt(fan_in). 

Thus, in the ModelNew's __init__, we must copy this initialization. 

Therefore, the __init__ function is correct as written earlier. 

Thus, the complete code should look like this:

The CUDA kernel code:

pointwise_conv_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

template <typename T>
__global__ void pointwise_conv_kernel(const T* input, const T* weight, const T* bias, T* output,
    int B, int Cin, int Cout, int H, int W) {
    int w = blockIdx.x % W;
    int h = (blockIdx.x / W) % H;
    int batch = blockIdx.x / (H * W);

    int oc = threadIdx.x;

    if (oc >= Cout) return;

    T sum = static_cast<T>(0);
    for (int ic = 0; ic < Cin; ++ic) {
        int input_idx = batch * Cin * H * W + ic * H * W + h * W + w;
        sum += input[input_idx] * weight[oc * Cin + ic];
    }

    if (bias) {
        sum += bias[oc];
    }

    int output_idx = batch * Cout * H * W + oc * H * W + h * W + w;
    output[output_idx] = sum;
}

void pointwise_conv_cuda(torch::Tensor input, torch::Tensor weight, torch::optional<torch::Tensor> bias, torch::Tensor output,
    int B, int Cin, int Cout, int H, int W) {
    const int threads = Cout;
    const int blocks = B * H * W;

    AT_DISPATCH_FLOATING_TYPES(input.type(), "pointwise_conv_cuda", ([&] {
        const T* bias_ptr = bias.has_value() ? bias->data<scalar_t>() : nullptr;
        pointwise_conv_kernel<scalar_t><<<blocks, threads>>>(
            input.data<scalar_t>(),
            weight.data<scalar_t>(),
            bias_ptr,
            output.data<scalar_t>(),
            B, Cin, Cout, H, W);
    }));

    cudaError_t err = cudaGetLastError();
    if (err != cudaSuccess) {
        printf("CUDA error: %s\\n", cudaGetErrorString(err));
    }
}
"""

pointwise_conv_cpp_source = """
void pointwise_conv_cuda(torch::Tensor input, torch::Tensor weight, torch::optional<torch::Tensor> bias, torch::Tensor output,
    int B, int Cin, int Cout, int H, int W);
"""

Then, load it:

pointwise_conv = load_inline(
    name="pointwise_conv",
    cpp_sources=pointwise_conv_cpp_source,
    cuda_sources=pointwise_conv_source,
    functions=["pointwise_conv_cuda"],
    verbose=True,
)

Then the ModelNew class:

import math
import torch
import torch.nn as nn

class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, bias: bool = False):
        super().__init__()
        self.weight = nn.Parameter(torch.empty(out_channels, in_channels))
        self.bias = nn.Parameter(torch.empty(out_channels)) if bias else None

        # Initialize weights like torch's Conv2d
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if self.bias is not None:
            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in)
            nn.init.uniform_(self.bias, -bound, bound)

        # Load the CUDA function
        self.pointwise_conv = pointwise_conv

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        B, Cin, H, W = x.shape
        Cout = self.weight.size(0)
        assert Cin == self.weight.size(1), "Input channels must match weight dimensions"

        output = torch.empty(B, Cout, H, W, device=x.device, dtype=x.dtype)

        # Prepare bias parameter
        bias = self.bias if self.bias is not None else None

        self.pointwise_conv.pointwise_conv_cuda(
            x.contiguous(),
            self.weight.contiguous(),
            bias,
            output,
            B, Cin, Cout, H, W
        )

        return output

Wait, but in the __init__ for the bias:

if bias:
    self.bias = nn.Parameter(...)
else:
    self.bias = None 

Thus, in the forward function, checking self.bias is not None is okay. 

Testing this code should work. 

Now, checking the shapes: 

The output tensor is created with shape (B, Cout, H, W), same as the original model. 

The kernel correctly computes each element. 

The weights are initialized correctly. 

The bias is handled properly. 

Therefore, this should be the correct implementation. 

Now, putting this all together into the required code block. 

Also, note that in the forward function, the parameters passed to the kernel include H and W in the correct order. 

Wait, in the kernel function's parameters, after B, Cin, Cout comes H and W? 

Wait, in the kernel code:

the function parameters are:

int B, int Cin, int Cout, int H, int W

In the forward function:

the call is:

B, Cin, Cout, H, W 

Yes, since the parameters in the function are:

void pointwise_conv_cuda(..., int B, int Cin, int Cout, int H, int W)

Thus, the order is correct. 

Therefore, the code should work.
</think>

```python
import math
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Custom CUDA kernel for pointwise 2D convolution
pointwise_conv_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

template <typename T>
__global__ void pointwise_conv_kernel(const T* input, const T* weight, const T* bias, T* output,
    int B, int Cin, int Cout, int H, int W) {
    int w = blockIdx.x % W;
    int h = (blockIdx.x / W) % H;
    int batch = blockIdx.x / (H * W);

    int oc = threadIdx.x;

    if (oc >= Cout) return;

    T sum = static_cast<T>(0);
    for (int ic = 0; ic < Cin; ++ic) {
        int input_idx = batch * Cin * H * W + ic * H * W + h * W + w;
        sum += input[input_idx] * weight[oc * Cin + ic];
    }

    if (bias) {
        sum += bias[oc];
    }

    int output_idx = batch * Cout * H * W + oc * H * W + h * W + w;
    output[output_idx] = sum;
}

void pointwise_conv_cuda(torch::Tensor input, torch::Tensor weight, torch::optional<torch::Tensor> bias, torch::Tensor output,
    int B, int Cin, int Cout, int H, int W) {
    const int threads = Cout;
    const int blocks = B * H * W;

    AT_DISPATCH_FLOATING_TYPES(input.type(), "pointwise_conv_cuda", ([&] {
        const T* bias_ptr = bias.has_value() ? bias->data<scalar_t>() : nullptr;
        pointwise_conv_kernel<scalar_t><<<blocks, threads>>>(
            input.data<scalar_t>(),
            weight.data<scalar_t>(),
            bias_ptr,
            output.data<scalar_t>(),
            B, Cin, Cout, H, W);
    }));

    cudaError_t err = cudaGetLastError();
    if (err != cudaSuccess) {
        printf("CUDA error: %s\\n", cudaGetErrorString(err));
    }
}
"""

pointwise_conv_cpp_source = """
void pointwise_conv_cuda(torch::Tensor input, torch::Tensor weight, torch::optional<torch::Tensor> bias, torch::Tensor output,
    int B, int Cin, int Cout, int H, int W);
"""

# Compile the CUDA kernel
pointwise_conv = load_inline(
    name="pointwise_conv",
    cpp_sources=pointwise_conv_cpp_source,
    cuda_sources=pointwise_conv_source,
    functions=["pointwise_conv_cuda"],
    verbose=True,
)

class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, bias: bool = False):
        super().__init__()
        self.weight = nn.Parameter(torch.empty(out_channels, in_channels))
        self.bias = nn.Parameter(torch.empty(out_channels)) if bias else None

        # Initialize weights and bias like PyTorch's Conv2d
        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))
        if self.bias is not None:
            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)
            bound = 1 / math.sqrt(fan_in)
            nn.init.uniform_(self.bias, -bound, bound)

        # Attach the CUDA function
        self.pointwise_conv = pointwise_conv

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        B, Cin, H, W = x.shape
        Cout = self.weight.size(0)
        assert Cin == self.weight.size(1), "Input channels must match weight dimensions"

        output = torch.empty(B, Cout, H, W, device=x.device, dtype=x.dtype)

        # Handle bias parameter
        bias = self.bias if self.bias is not None else None

        # Launch CUDA kernel
        self.pointwise_conv.pointwise_conv_cuda(
            x.contiguous(),
            self.weight.contiguous(),
            bias,
            output,
            B, Cin, Cout, H, W
        )

        return output
```