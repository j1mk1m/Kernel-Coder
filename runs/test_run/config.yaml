_tags: test_test_time_scaling
api_query_interval: 0.0
autorule: false
autorule_path: null
build_cache_with_cpu: true
dataset_name: ScalingIntelligence/KernelBench
dataset_src: local
eval_mode: local
eval_server_host: localhost
eval_server_port: 12345
gpu_arch: Ampere
hardware: H100
level: 2
log_prompt: true
log_response: true
max_tokens: 8192
measure_performance: true
method: base
model_name: gemini/gemini-2.0-flash
num_best: 1
num_correct_trials: 5
num_cpu_workers: 1
num_eval_devices: 1
num_iterations: 1
num_parallel: 1
num_perf_trials: 100
num_samples: 1
num_workers: 1
prompt: regular
run_name: test_time_scaling_1_2
server_type: litellm
store_type: local
subset: !!python/tuple
- 1
- 2
temperature: 0.7
timeout: 300
verbose: false
vllm_host: localhost
vllm_port: 8081
