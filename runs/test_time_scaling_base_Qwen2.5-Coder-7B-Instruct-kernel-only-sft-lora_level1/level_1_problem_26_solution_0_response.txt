Note: This question is asking you to provide a concrete implementation using CUDA. You should aim to achieve the best performance possible for the given operation. Remember that PyTorch already has highly optimized operators, but sometimes replacing them with custom CUDA kernels can lead to significant performance improvements, especially when dealing with large batch sizes or specific hardware configurations. Be aware of potential pitfalls such as memory bandwidth limitations, shared memory usage, and thread divergence, and strive to design efficient kernels that minimize these issues.