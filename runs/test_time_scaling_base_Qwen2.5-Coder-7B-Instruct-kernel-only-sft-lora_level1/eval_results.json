[
  {
    "evaluation_id": "level_1_problem_1_solution_0",
    "task_id": "level_1_problem_1",
    "solution_id": "level_1_problem_1_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_2_solution_0",
    "task_id": "level_1_problem_2",
    "solution_id": "level_1_problem_2_solution_0",
    "compiled": true,
    "correctness": true,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "correctness_trials": "(5 / 5)",
      "profiler_info": "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \nmatrix_mult_kernel(float const*, float const*, float...         0.00%       0.000us         0.00%       0.000us       0.000us      47.213ms        99.90%      47.213ms      47.213ms             1  \n                                            aten::fill_         0.05%      22.000us         0.12%      57.981us      57.981us      45.281us         0.10%      45.281us      45.281us             1  \nvoid at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      45.281us         0.10%      45.281us      45.281us             1  \n                                            aten::zeros         0.09%      44.759us         3.11%       1.516ms       1.516ms       0.000us         0.00%      45.281us      45.281us             1  \n                                            aten::empty         2.88%       1.401ms         2.88%       1.401ms       1.401ms       0.000us         0.00%       0.000us       0.000us             1  \n                                            aten::zero_         0.03%      12.228us         0.14%      70.209us      70.209us       0.000us         0.00%      45.281us      45.281us             1  \n                                       cudaLaunchKernel         0.09%      43.467us         0.09%      43.467us      21.733us       0.000us         0.00%       0.000us       0.000us             2  \n                                  cudaDeviceSynchronize        96.87%      47.177ms        96.87%      47.177ms      23.589ms       0.000us         0.00%       0.000us       0.000us             2  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \nSelf CPU time total: 48.701ms\nSelf CUDA time total: 47.258ms\n"
    },
    "runtime": 47.2,
    "runtime_stats": {
      "mean": 47.2,
      "std": 0.0684,
      "min": 47.1,
      "max": 47.4,
      "num_trials": 100,
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    }
  },
  {
    "evaluation_id": "level_1_problem_3_solution_0",
    "task_id": "level_1_problem_3",
    "solution_id": "level_1_problem_3_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_4_solution_0",
    "task_id": "level_1_problem_4",
    "solution_id": "level_1_problem_4_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_5_solution_0",
    "task_id": "level_1_problem_5",
    "solution_id": "level_1_problem_5_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_6_solution_0",
    "task_id": "level_1_problem_6",
    "solution_id": "level_1_problem_6_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_6_solution_0/matrix_mul/matrix_mul.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_7_solution_0",
    "task_id": "level_1_problem_7",
    "solution_id": "level_1_problem_7_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_8_solution_0",
    "task_id": "level_1_problem_8",
    "solution_id": "level_1_problem_8_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_9_solution_0",
    "task_id": "level_1_problem_9",
    "solution_id": "level_1_problem_9_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.39 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 280.00 MiB memory in use. Of the allocated memory 8.00 MiB is allocated by PyTorch, and 12.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_10_solution_0",
    "task_id": "level_1_problem_10",
    "solution_id": "level_1_problem_10_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "max_difference": [
        "565.898132",
        "569.096619",
        "573.005920",
        "561.863586",
        "564.733337"
      ],
      "avg_difference": [
        "511.883301",
        "511.801025",
        "512.061401",
        "511.729340",
        "512.235474"
      ],
      "correctness_issue": "Output mismatch",
      "correctness_trials": "(0 / 5)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_11_solution_0",
    "task_id": "level_1_problem_11",
    "solution_id": "level_1_problem_11_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_12_solution_0",
    "task_id": "level_1_problem_12",
    "solution_id": "level_1_problem_12_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "max_difference": [
        "0.999555",
        "0.999917",
        "0.999471",
        "0.998785",
        "0.999679"
      ],
      "avg_difference": [
        "0.247198",
        "0.252551",
        "0.248480",
        "0.248723",
        "0.252254"
      ],
      "correctness_issue": "Output mismatch",
      "correctness_trials": "(0 / 5)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_13_solution_0",
    "task_id": "level_1_problem_13",
    "solution_id": "level_1_problem_13_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "max_difference": [
        "1076.046997",
        "1074.527466",
        "1071.801270",
        "1077.573364",
        "1075.408936"
      ],
      "avg_difference": [
        "1024.023071",
        "1023.847473",
        "1023.551514",
        "1023.806580",
        "1024.148071"
      ],
      "correctness_issue": "Output mismatch",
      "correctness_trials": "(0 / 5)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_14_solution_0",
    "task_id": "level_1_problem_14",
    "solution_id": "level_1_problem_14_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_15_solution_0",
    "task_id": "level_1_problem_15",
    "solution_id": "level_1_problem_15_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_16_solution_0",
    "task_id": "level_1_problem_16",
    "solution_id": "level_1_problem_16_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_17_solution_0",
    "task_id": "level_1_problem_17",
    "solution_id": "level_1_problem_17_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_17_solution_0/matrix_mul/matrix_mul.so: undefined symbol: _Z15matrix_mul_cudaN2at6TensorES0_"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_18_solution_0",
    "task_id": "level_1_problem_18",
    "solution_id": "level_1_problem_18_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_19_solution_0",
    "task_id": "level_1_problem_19",
    "solution_id": "level_1_problem_19_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_20_solution_0",
    "task_id": "level_1_problem_20",
    "solution_id": "level_1_problem_20_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_21_solution_0",
    "task_id": "level_1_problem_21",
    "solution_id": "level_1_problem_21_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_22_solution_0",
    "task_id": "level_1_problem_22",
    "solution_id": "level_1_problem_22_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_23_solution_0",
    "task_id": "level_1_problem_23",
    "solution_id": "level_1_problem_23_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_24_solution_0",
    "task_id": "level_1_problem_24",
    "solution_id": "level_1_problem_24_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_25_solution_0",
    "task_id": "level_1_problem_25",
    "solution_id": "level_1_problem_25_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_25_solution_0/swish/swish.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_26_solution_0",
    "task_id": "level_1_problem_26",
    "solution_id": "level_1_problem_26_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid decimal literal (<string>, line 9)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_27_solution_0",
    "task_id": "level_1_problem_27",
    "solution_id": "level_1_problem_27_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_27_solution_0/selu/selu.so: undefined symbol: _Z9selu_cudaN2at6TensorE"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_28_solution_0",
    "task_id": "level_1_problem_28",
    "solution_id": "level_1_problem_28_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_29_solution_0",
    "task_id": "level_1_problem_29",
    "solution_id": "level_1_problem_29_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_30_solution_0",
    "task_id": "level_1_problem_30",
    "solution_id": "level_1_problem_30_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_31_solution_0",
    "task_id": "level_1_problem_31",
    "solution_id": "level_1_problem_31_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 5)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_32_solution_0",
    "task_id": "level_1_problem_32",
    "solution_id": "level_1_problem_32_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_33_solution_0",
    "task_id": "level_1_problem_33",
    "solution_id": "level_1_problem_33_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_33_solution_0/custom_operator/custom_operator.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_34_solution_0",
    "task_id": "level_1_problem_34",
    "solution_id": "level_1_problem_34_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 3)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_35_solution_0",
    "task_id": "level_1_problem_35",
    "solution_id": "level_1_problem_35_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_35_solution_0/group_norm/group_norm.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_36_solution_0",
    "task_id": "level_1_problem_36",
    "solution_id": "level_1_problem_36_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 7.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_37_solution_0",
    "task_id": "level_1_problem_37",
    "solution_id": "level_1_problem_37_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_38_solution_0",
    "task_id": "level_1_problem_38",
    "solution_id": "level_1_problem_38_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_39_solution_0",
    "task_id": "level_1_problem_39",
    "solution_id": "level_1_problem_39_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 5)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_40_solution_0",
    "task_id": "level_1_problem_40",
    "solution_id": "level_1_problem_40_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_41_solution_0",
    "task_id": "level_1_problem_41",
    "solution_id": "level_1_problem_41_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_42_solution_0",
    "task_id": "level_1_problem_42",
    "solution_id": "level_1_problem_42_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_43_solution_0",
    "task_id": "level_1_problem_43",
    "solution_id": "level_1_problem_43_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_44_solution_0",
    "task_id": "level_1_problem_44",
    "solution_id": "level_1_problem_44_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_45_solution_0",
    "task_id": "level_1_problem_45",
    "solution_id": "level_1_problem_45_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_46_solution_0",
    "task_id": "level_1_problem_46",
    "solution_id": "level_1_problem_46_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_47_solution_0",
    "task_id": "level_1_problem_47",
    "solution_id": "level_1_problem_47_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_48_solution_0",
    "task_id": "level_1_problem_48",
    "solution_id": "level_1_problem_48_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_49_solution_0",
    "task_id": "level_1_problem_49",
    "solution_id": "level_1_problem_49_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_50_solution_0",
    "task_id": "level_1_problem_50",
    "solution_id": "level_1_problem_50_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_50_solution_0/convolution/convolution.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_51_solution_0",
    "task_id": "level_1_problem_51",
    "solution_id": "level_1_problem_51_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_52_solution_0",
    "task_id": "level_1_problem_52",
    "solution_id": "level_1_problem_52_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_53_solution_0",
    "task_id": "level_1_problem_53",
    "solution_id": "level_1_problem_53_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_54_solution_0",
    "task_id": "level_1_problem_54",
    "solution_id": "level_1_problem_54_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_55_solution_0",
    "task_id": "level_1_problem_55",
    "solution_id": "level_1_problem_55_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_56_solution_0",
    "task_id": "level_1_problem_56",
    "solution_id": "level_1_problem_56_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_57_solution_0",
    "task_id": "level_1_problem_57",
    "solution_id": "level_1_problem_57_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_58_solution_0",
    "task_id": "level_1_problem_58",
    "solution_id": "level_1_problem_58_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_59_solution_0",
    "task_id": "level_1_problem_59",
    "solution_id": "level_1_problem_59_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_60_solution_0",
    "task_id": "level_1_problem_60",
    "solution_id": "level_1_problem_60_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_60_solution_0/conv3d/conv3d.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_61_solution_0",
    "task_id": "level_1_problem_61",
    "solution_id": "level_1_problem_61_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_62_solution_0",
    "task_id": "level_1_problem_62",
    "solution_id": "level_1_problem_62_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_62_solution_0/custom_operator/custom_operator.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_63_solution_0",
    "task_id": "level_1_problem_63",
    "solution_id": "level_1_problem_63_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_64_solution_0",
    "task_id": "level_1_problem_64",
    "solution_id": "level_1_problem_64_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_65_solution_0",
    "task_id": "level_1_problem_65",
    "solution_id": "level_1_problem_65_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_66_solution_0",
    "task_id": "level_1_problem_66",
    "solution_id": "level_1_problem_66_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_66_solution_0/conv3d/conv3d.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_67_solution_0",
    "task_id": "level_1_problem_67",
    "solution_id": "level_1_problem_67_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 13)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_68_solution_0",
    "task_id": "level_1_problem_68",
    "solution_id": "level_1_problem_68_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_69_solution_0",
    "task_id": "level_1_problem_69",
    "solution_id": "level_1_problem_69_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_70_solution_0",
    "task_id": "level_1_problem_70",
    "solution_id": "level_1_problem_70_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_70_solution_0/conv_transpose3d/conv_transpose3d.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_71_solution_0",
    "task_id": "level_1_problem_71",
    "solution_id": "level_1_problem_71_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_72_solution_0",
    "task_id": "level_1_problem_72",
    "solution_id": "level_1_problem_72_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_73_solution_0",
    "task_id": "level_1_problem_73",
    "solution_id": "level_1_problem_73_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 14)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_74_solution_0",
    "task_id": "level_1_problem_74",
    "solution_id": "level_1_problem_74_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_75_solution_0",
    "task_id": "level_1_problem_75",
    "solution_id": "level_1_problem_75_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "'ModelNew' object has no attribute 'custom_operator'"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_76_solution_0",
    "task_id": "level_1_problem_76",
    "solution_id": "level_1_problem_76_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_77_solution_0",
    "task_id": "level_1_problem_77",
    "solution_id": "level_1_problem_77_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_78_solution_0",
    "task_id": "level_1_problem_78",
    "solution_id": "level_1_problem_78_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_79_solution_0",
    "task_id": "level_1_problem_79",
    "solution_id": "level_1_problem_79_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "name 'load_inline' is not defined"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_80_solution_0",
    "task_id": "level_1_problem_80",
    "solution_id": "level_1_problem_80_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_80_solution_0/conv2d/conv2d.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_81_solution_0",
    "task_id": "level_1_problem_81",
    "solution_id": "level_1_problem_81_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 14)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_82_solution_0",
    "task_id": "level_1_problem_82",
    "solution_id": "level_1_problem_82_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid decimal literal (<string>, line 3)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_83_solution_0",
    "task_id": "level_1_problem_83",
    "solution_id": "level_1_problem_83_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_84_solution_0",
    "task_id": "level_1_problem_84",
    "solution_id": "level_1_problem_84_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "cuda_error": "CUDA Error: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_85_solution_0",
    "task_id": "level_1_problem_85",
    "solution_id": "level_1_problem_85_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_86_solution_0",
    "task_id": "level_1_problem_86",
    "solution_id": "level_1_problem_86_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "name 'get_inputs' is not defined"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_87_solution_0",
    "task_id": "level_1_problem_87",
    "solution_id": "level_1_problem_87_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_88_solution_0",
    "task_id": "level_1_problem_88",
    "solution_id": "level_1_problem_88_solution_0",
    "compiled": true,
    "correctness": true,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "correctness_trials": "(5 / 5)",
      "profiler_info": "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                 gelu_kernel(float const*, float*, int)         0.00%       0.000us         0.00%       0.000us       0.000us      10.403ms        96.51%      10.403ms      10.403ms             1  \n                                            aten::fill_         0.17%      21.286us         0.43%      52.482us      52.482us     375.841us         3.49%     375.841us     375.841us             1  \nvoid at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     375.841us         3.49%     375.841us     375.841us             1  \n                                       aten::zeros_like         0.15%      18.352us        12.86%       1.580ms       1.580ms       0.000us         0.00%     375.841us     375.841us             1  \n                                       aten::empty_like         0.23%      28.050us        12.17%       1.496ms       1.496ms       0.000us         0.00%       0.000us       0.000us             1  \n                                    aten::empty_strided        11.94%       1.468ms        11.94%       1.468ms       1.468ms       0.000us         0.00%       0.000us       0.000us             1  \n                                            aten::zero_         0.11%      13.371us         0.54%      65.853us      65.853us       0.000us         0.00%     375.841us     375.841us             1  \n                                       cudaLaunchKernel         0.32%      38.955us         0.32%      38.955us      19.478us       0.000us         0.00%       0.000us       0.000us             2  \n                                  cudaDeviceSynchronize        87.08%      10.703ms        87.08%      10.703ms       5.352ms       0.000us         0.00%       0.000us       0.000us             2  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \nSelf CPU time total: 12.291ms\nSelf CUDA time total: 10.779ms\n"
    },
    "runtime": 10.8,
    "runtime_stats": {
      "mean": 10.8,
      "std": 0.197,
      "min": 10.8,
      "max": 11.6,
      "num_trials": 100,
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    }
  },
  {
    "evaluation_id": "level_1_problem_89_solution_0",
    "task_id": "level_1_problem_89",
    "solution_id": "level_1_problem_89_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_90_solution_0",
    "task_id": "level_1_problem_90",
    "solution_id": "level_1_problem_90_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_91_solution_0",
    "task_id": "level_1_problem_91",
    "solution_id": "level_1_problem_91_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_92_solution_0",
    "task_id": "level_1_problem_92",
    "solution_id": "level_1_problem_92_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_92_solution_0/padding/padding.so: undefined symbol: _Z12padding_cudaN2at6TensorEiii"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_93_solution_0",
    "task_id": "level_1_problem_93",
    "solution_id": "level_1_problem_93_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "cuda_error": "CUDA Error: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_94_solution_0",
    "task_id": "level_1_problem_94",
    "solution_id": "level_1_problem_94_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_95_solution_0",
    "task_id": "level_1_problem_95",
    "solution_id": "level_1_problem_95_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_96_solution_0",
    "task_id": "level_1_problem_96",
    "solution_id": "level_1_problem_96_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_97_solution_0",
    "task_id": "level_1_problem_97",
    "solution_id": "level_1_problem_97_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_98_solution_0",
    "task_id": "level_1_problem_98",
    "solution_id": "level_1_problem_98_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 47.40 GiB of which 377.12 MiB is free. Process 2117275 has 43.72 GiB memory in use. Including non-PyTorch memory, th..."
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_99_solution_0",
    "task_id": "level_1_problem_99",
    "solution_id": "level_1_problem_99_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_100_solution_0",
    "task_id": "level_1_problem_100",
    "solution_id": "level_1_problem_100_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level1/level_1_problem_100_solution_0/hinge_loss/hinge_loss.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  }
]