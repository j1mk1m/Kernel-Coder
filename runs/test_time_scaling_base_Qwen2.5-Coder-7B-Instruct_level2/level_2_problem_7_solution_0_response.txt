Please ensure your implementation includes the following:

- Custom CUDA kernels for operations such as `conv`, `relu`, `leaky_relu`, `gelu`, `sigmoid`, and `bias` addition.
- Proper handling of tensor shapes and data types within the CUDA kernels.
- Compilation and linking of the CUDA kernels using PyTorch's `load_inline`.
- Efficient memory management and execution strategies within the CUDA kernels.

Your solution should aim to maximize performance while maintaining correctness and readability. Feel free to experiment with different optimizations and algorithms within the constraints provided.

```markdown
## Solution
```python
[Insert your code here]
```python
```

## Explanation
[Provide a brief explanation of your optimization strategy and any key insights gained during the process.]
```markdown
```
```

































