The goal here is to use CUDA to accelerate the operations in the `forward` method of the `Model` class. Feel free to replace any of the operations in the forward pass with custom CUDA kernels, fuse multiple operations together, or optimize algorithms where possible. Be creative and aim for maximum performance.

### Constraints:

- Your solution should be completely self-contained within the provided code blocks.
- Ensure that the new architecture (`ModelNew`) has the same functionality as the original (`Model`). It should produce identical outputs for the same inputs.
- Optimize for both memory bandwidth and compute efficiency wherever possible.
- You can assume that the input tensors are already on the GPU when they are passed to the `forward` method.

### Tips:

- Consider optimizing the convolution operation using CUDA libraries such as cuDNN.
- Explore ways to combine multiple operations into a single kernel to reduce overhead.
- Experiment with different data layouts (e.g., NCHW vs NHWC) to maximize memory access patterns.
- Use profiling tools to identify bottlenecks and focus optimization efforts there.
- Don't hesitate to ask for help or clarification if needed!

### Submission:

Submit your optimized architecture `ModelNew` as a complete Python script. Ensure that it imports all necessary packages and defines everything needed to run the model, including the `get_inputs` and `get_init_inputs` functions.