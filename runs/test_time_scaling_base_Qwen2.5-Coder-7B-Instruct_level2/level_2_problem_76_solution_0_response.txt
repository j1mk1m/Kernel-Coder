### Hints:

- **Matrix Multiplication**: Consider using cuBLAS for efficient matrix multiplication.
- **Bias Addition**: This can be done efficiently using vectorized operations.
- **ReLU Activation**: Implementing ReLU directly in CUDA can offer performance benefits.

### Expected Output:

```python
# Your optimized code here
```