api_query_interval: 0.0
base_traceset_path: /data/user_data/gyeongwk/flashinfer-trace
benchmark: KernelBench
build_cache_with_cpu: false
build_dir: /data/user_data/zichunyu/Kernel-Coder/cache
dataset_name: ScalingIntelligence/KernelBench
dataset_src: local
gpu_arch: Ampere
hardware: A6000_babel
language: CUDA
level: 2
max_tokens: 16384
measure_performance: true
method: base
model_name: hosted_vllm//data/group_data/cx_group/data_centric_llm/zichunyu/11891/kernel-coder_qwen2.5-coder-7b-instruct_kernel-only_sft-lora/global_step_80/hf
num_best: 1
num_correct_trials: 5
num_cpu_workers: 16
num_eval_devices: 1
num_iterations: 1
num_parallel: 1
num_perf_trials: 100
num_samples: 1
num_workers: 1
prompt: regular
rules_file: null
run_name: test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-kernel-only-sft-lora_level2
server_type: vllm
target_gpu: H100
temperature: 0.7
test: false
timeout: 300
verbose: false
vllm_host: babel-u9-16
vllm_port: 8082
