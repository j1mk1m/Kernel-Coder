The new code should include the necessary imports, class definition, and any other code needed to run the architecture. The final code should be runnable using standard PyTorch setup.

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Your custom CUDA kernel definitions go here

class ModelNew(nn.Module):
    # Your implementation goes here

# Example usage:
model_new = ModelNew(*get_init_inputs())
inputs = get_inputs()
output = model_new(inputs[0])
print(output.shape)
```

Please provide a detailed explanation of how each custom CUDA operator was chosen and why it was beneficial for the performance of the architecture. Include details about the specific operations being replaced and the optimizations applied.