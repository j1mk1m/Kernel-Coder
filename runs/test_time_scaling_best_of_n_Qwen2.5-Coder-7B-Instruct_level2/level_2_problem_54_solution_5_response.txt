```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for convolution
convolution_source = """
// TODO: Implement convolution kernel here
"""

convolution_cpp_source = (
    // TODO: Implement convolution kernel here
)

# Compile the inline CUDA code for convolution
convolution = load_inline(
    name="convolution",
    cpp_sources=convolution_cpp_source,
    cuda_sources=convolution_source,
    functions=["convolution_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for LeakyReLU
leaky_relu_source = """
// TODO: Implement LeakyReLU kernel here
"""

leaky_relu_cpp_source = (
    // TODO: Implement LeakyReLU kernel here
)

# Compile the inline CUDA code for LeakyReLU
leaky_relu = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for GELU
gelu_source = """
// TODO: Implement GELU kernel here
"""

gelu_cpp_source = (
    // TODO: Implement GELU kernel here
)

# Compile the inline CUDA code for GELU
gelu = load_inline(
    name="gelu",
    cpp_sources=gelu_cpp_source,
    cuda_sources=gelu_source,
    functions=["gelu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super(ModelNew, self).__init__()
        self.conv = convolution
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = leaky_relu
        self.gelu = gelu

    def forward(self, x):
        x = self.conv.convolution_cuda(x, self.conv.weight, self.conv.bias, self.conv.stride, self.conv.padding, self.conv.dilation, self.conv.groups)
        x = x * self.multiplier
        x = self.leaky_relu.leaky_relu_cuda(x)
        x = self.gelu.gelu_cuda(x)
        return x
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for convolution
convolution_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void convolution_kernel(const float* input, const float* weight, const float* bias, float* output, int batch_size, int in_channels, int out_channels, int height, int width, int kernel_size, int stride, int padding, int dilation, int groups) {
    int n = blockIdx.x / (groups * out_channels);
    int c = blockIdx.x % (groups * out_channels);
    int oc = c / groups;
    int ic = c % groups;
    int h = blockIdx.y;
    int w = blockIdx.z;

    int ih_start = h * stride - padding;
    int iw_start = w * stride - padding;

    float sum = 0.0f;
    for (int kh = 0; kh < kernel_size; ++kh) {
        for (int kw = 0; kw < kernel_size; ++kw) {
            int ih = ih_start + kh * dilation;
            int iw = iw_start + kw * dilation;

            if (ih >= 0 && ih < height && iw >= 0 && iw < width) {
                int i_idx = ((n * in_channels + ic) * height + ih) * width + iw;
                int k_idx = ((oc * kernel_size + kh) * kernel_size + kw) * groups + ic;
                sum += input[i_idx] * weight[k_idx];
            }
        }
    }

    int o_idx = ((n * out_channels + oc) * height + h) * width + w;
    output[o_idx] = sum + bias[c];
}

torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups) {
    auto batch_size = input.size(0);
    auto in_channels = input.size(1);
    auto out_channels = weight.size(0);
    auto height = input.size(2);
    auto width = input.size(3);
    auto kernel_size = weight.size(2);

    auto output = torch::zeros({batch_size, out_channels, height, width}, input.options());

    dim3 block_size(16, 16, 1);
    dim3 grid_size((out_channels * groups + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y, (width + block_size.z - 1) / block_size.z);

    convolution_kernel<<<grid_size, block_size>>>(input.data_ptr<float>(), weight.data_ptr<float>(), bias.data_ptr<float>(), output.data_ptr<float>(), batch_size, in_channels, out_channels, height, width, kernel_size, stride, padding, dilation, groups);

    return output;
}
"""

convolution_cpp_source = (
    "torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups);"
)

# Compile the inline CUDA code for convolution
convolution = load_inline(
    name="convolution",
    cpp_sources=convolution_cpp_source,
    cuda_sources=convolution_source,
    functions=["convolution_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for LeakyReLU
leaky_relu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void leaky_relu_kernel(const float* input, float* output, int size, float negative_slope) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        output[idx] = input[idx] > 0 ? input[idx] : negative_slope * input[idx];
    }
}

torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    leaky_relu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size, negative_slope);

    return output;
}
"""

leaky_relu_cpp_source = (
    "torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope);"
)

# Compile the inline CUDA code for LeakyReLU
leaky_relu = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for GELU
gelu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void gelu_kernel(const float* input, float* output, int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        float x = input[idx];
        output[idx] = 0.5f * (x + tanh(sqrt(2.0f / M_PI) * (x + 0.044715f * pow(x, 3.0f))));
    }
}

torch::Tensor gelu_cuda(torch::Tensor input) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    gelu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size);

    return output;
}
"""

gelu_cpp_source = (
    "torch::Tensor gelu_cuda(torch::Tensor input);"
)

# Compile the inline CUDA code for GELU
gelu = load_inline(
    name="gelu",
    cpp_sources=gelu_cpp_source,
    cuda_sources=gelu_source,
    functions=["gelu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super(ModelNew, self).__init__()
        self.conv = convolution
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = leaky_relu
        self.gelu = gelu

    def forward(self, x):
        x = self.conv.convolution_cuda(x, self.conv.weight, self.conv.bias, self.conv.stride, self.conv.padding, self.conv.dilation, self.conv.groups)
        x = x * self.multiplier
        x = self.leaky_relu.leaky_relu_cuda(x, 0.01)
        x = self.gelu.gelu_cuda(x)
        return x
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for convolution
convolution_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void convolution_kernel(const float* input, const float* weight, const float* bias, float* output, int batch_size, int in_channels, int out_channels, int height, int width, int kernel_size, int stride, int padding, int dilation, int groups) {
    int n = blockIdx.x / (groups * out_channels);
    int c = blockIdx.x % (groups * out_channels);
    int oc = c / groups;
    int ic = c % groups;
    int h = blockIdx.y;
    int w = blockIdx.z;

    int ih_start = h * stride - padding;
    int iw_start = w * stride - padding;

    float sum = 0.0f;
    for (int kh = 0; kh < kernel_size; ++kh) {
        for (int kw = 0; kw < kernel_size; ++kw) {
            int ih = ih_start + kh * dilation;
            int iw = iw_start + kw * dilation;

            if (ih >= 0 && ih < height && iw >= 0 && iw < width) {
                int i_idx = ((n * in_channels + ic) * height + ih) * width + iw;
                int k_idx = ((oc * kernel_size + kh) * kernel_size + kw) * groups + ic;
                sum += input[i_idx] * weight[k_idx];
            }
        }
    }

    int o_idx = ((n * out_channels + oc) * height + h) * width + w;
    output[o_idx] = sum + bias[c];
}

torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups) {
    auto batch_size = input.size(0);
    auto in_channels = input.size(1);
    auto out_channels = weight.size(0);
    auto height = input.size(2);
    auto width = input.size(3);
    auto kernel_size = weight.size(2);

    auto output = torch::zeros({batch_size, out_channels, height, width}, input.options());

    dim3 block_size(16, 16, 1);
    dim3 grid_size((out_channels * groups + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y, (width + block_size.z - 1) / block_size.z);

    convolution_kernel<<<grid_size, block_size>>>(input.data_ptr<float>(), weight.data_ptr<float>(), bias.data_ptr<float>(), output.data_ptr<float>(), batch_size, in_channels, out_channels, height, width, kernel_size, stride, padding, dilation, groups);

    return output;
}
"""

convolution_cpp_source = (
    "torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups);"
)

# Compile the inline CUDA code for convolution
convolution = load_inline(
    name="convolution",
    cpp_sources=convolution_cpp_source,
    cuda_sources=convolution_source,
    functions=["convolution_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for LeakyReLU
leaky_relu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void leaky_relu_kernel(const float* input, float* output, int size, float negative_slope) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        output[idx] = input[idx] > 0 ? input[idx] : negative_slope * input[idx];
    }
}

torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    leaky_relu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size, negative_slope);

    return output;
}
"""

leaky_relu_cpp_source = (
    "torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope);"
)

# Compile the inline CUDA code for LeakyReLU
leaky_relu = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for GELU
gelu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void gelu_kernel(const float* input, float* output, int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        float x = input[idx];
        output[idx] = 0.5f * (x + tanh(sqrt(2.0f / M_PI) * (x + 0.044715f * pow(x, 3.0f))));
    }
}

torch::Tensor gelu_cuda(torch::Tensor input) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    gelu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size);

    return output;
}
"""

gelu_cpp_source = (
    "torch::Tensor gelu_cuda(torch::Tensor input);"
)

# Compile the inline CUDA code for GELU
gelu = load_inline(
    name="gelu",
    cpp_sources=gelu_cpp_source,
    cuda_sources=gelu_source,
    functions=["gelu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super(ModelNew, self).__init__()
        self.conv = convolution
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = leaky_relu
        self.gelu = gelu

    def forward(self, x):
        x = self.conv.convolution_cuda(x, self.conv.weight, self.conv.bias, self.conv.stride, self.conv.padding, self.conv.dilation, self.conv.groups)
        x = x * self.multiplier
        x = self.leaky_relu.leaky_relu_cuda(x, 0.01)
        x = self.gelu.gelu_cuda(x)
        return x
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for convolution
convolution_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void convolution_kernel(const float* input, const float* weight, const float* bias, float* output, int batch_size, int in_channels, int out_channels, int height, int width, int kernel_size, int stride, int padding, int dilation, int groups) {
    int n = blockIdx.x / (groups * out_channels);
    int c = blockIdx.x % (groups * out_channels);
    int oc = c / groups;
    int ic = c % groups;
    int h = blockIdx.y;
    int w = blockIdx.z;

    int ih_start = h * stride - padding;
    int iw_start = w * stride - padding;

    float sum = 0.0f;
    for (int kh = 0; kh < kernel_size; ++kh) {
        for (int kw = 0; kw < kernel_size; ++kw) {
            int ih = ih_start + kh * dilation;
            int iw = iw_start + kw * dilation;

            if (ih >= 0 && ih < height && iw >= 0 && iw < width) {
                int i_idx = ((n * in_channels + ic) * height + ih) * width + iw;
                int k_idx = ((oc * kernel_size + kh) * kernel_size + kw) * groups + ic;
                sum += input[i_idx] * weight[k_idx];
            }
        }
    }

    int o_idx = ((n * out_channels + oc) * height + h) * width + w;
    output[o_idx] = sum + bias[c];
}

torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups) {
    auto batch_size = input.size(0);
    auto in_channels = input.size(1);
    auto out_channels = weight.size(0);
    auto height = input.size(2);
    auto width = input.size(3);
    auto kernel_size = weight.size(2);

    auto output = torch::zeros({batch_size, out_channels, height, width}, input.options());

    dim3 block_size(16, 16, 1);
    dim3 grid_size((out_channels * groups + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y, (width + block_size.z - 1) / block_size.z);

    convolution_kernel<<<grid_size, block_size>>>(input.data_ptr<float>(), weight.data_ptr<float>(), bias.data_ptr<float>(), output.data_ptr<float>(), batch_size, in_channels, out_channels, height, width, kernel_size, stride, padding, dilation, groups);

    return output;
}
"""

convolution_cpp_source = (
    "torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups);"
)

# Compile the inline CUDA code for convolution
convolution = load_inline(
    name="convolution",
    cpp_sources=convolution_cpp_source,
    cuda_sources=convolution_source,
    functions=["convolution_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for LeakyReLU
leaky_relu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void leaky_relu_kernel(const float* input, float* output, int size, float negative_slope) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        output[idx] = input[idx] > 0 ? input[idx] : negative_slope * input[idx];
    }
}

torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    leaky_relu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size, negative_slope);

    return output;
}
"""

leaky_relu_cpp_source = (
    "torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope);"
)

# Compile the inline CUDA code for LeakyReLU
leaky_relu = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for GELU
gelu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void gelu_kernel(const float* input, float* output, int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        float x = input[idx];
        output[idx] = 0.5f * (x + tanh(sqrt(2.0f / M_PI) * (x + 0.044715f * pow(x, 3.0f))));
    }
}

torch::Tensor gelu_cuda(torch::Tensor input) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    gelu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size);

    return output;
}
"""

gelu_cpp_source = (
    "torch::Tensor gelu_cuda(torch::Tensor input);"
)

# Compile the inline CUDA code for GELU
gelu = load_inline(
    name="gelu",
    cpp_sources=gelu_cpp_source,
    cuda_sources=gelu_source,
    functions=["gelu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super(ModelNew, self).__init__()
        self.conv = convolution
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = leaky_relu
        self.gelu = gelu

    def forward(self, x):
        x = self.conv.convolution_cuda(x, self.conv.weight, self.conv.bias, self.conv.stride, self.conv.padding, self.conv.dilation, self.conv.groups)
        x = x * self.multiplier
        x = self.leaky_relu.leaky_relu_cuda(x, 0.01)
        x = self.gelu.gelu_cuda(x)
        return x
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for convolution
convolution_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void convolution_kernel(const float* input, const float* weight, const float* bias, float* output, int batch_size, int in_channels, int out_channels, int height, int width, int kernel_size, int stride, int padding, int dilation, int groups) {
    int n = blockIdx.x / (groups * out_channels);
    int c = blockIdx.x % (groups * out_channels);
    int oc = c / groups;
    int ic = c % groups;
    int h = blockIdx.y;
    int w = blockIdx.z;

    int ih_start = h * stride - padding;
    int iw_start = w * stride - padding;

    float sum = 0.0f;
    for (int kh = 0; kh < kernel_size; ++kh) {
        for (int kw = 0; kw < kernel_size; ++kw) {
            int ih = ih_start + kh * dilation;
            int iw = iw_start + kw * dilation;

            if (ih >= 0 && ih < height && iw >= 0 && iw < width) {
                int i_idx = ((n * in_channels + ic) * height + ih) * width + iw;
                int k_idx = ((oc * kernel_size + kh) * kernel_size + kw) * groups + ic;
                sum += input[i_idx] * weight[k_idx];
            }
        }
    }

    int o_idx = ((n * out_channels + oc) * height + h) * width + w;
    output[o_idx] = sum + bias[c];
}

torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups) {
    auto batch_size = input.size(0);
    auto in_channels = input.size(1);
    auto out_channels = weight.size(0);
    auto height = input.size(2);
    auto width = input.size(3);
    auto kernel_size = weight.size(2);

    auto output = torch::zeros({batch_size, out_channels, height, width}, input.options());

    dim3 block_size(16, 16, 1);
    dim3 grid_size((out_channels * groups + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y, (width + block_size.z - 1) / block_size.z);

    convolution_kernel<<<grid_size, block_size>>>(input.data_ptr<float>(), weight.data_ptr<float>(), bias.data_ptr<float>(), output.data_ptr<float>(), batch_size, in_channels, out_channels, height, width, kernel_size, stride, padding, dilation, groups);

    return output;
}
"""

convolution_cpp_source = (
    "torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups);"
)

# Compile the inline CUDA code for convolution
convolution = load_inline(
    name="convolution",
    cpp_sources=convolution_cpp_source,
    cuda_sources=convolution_source,
    functions=["convolution_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for LeakyReLU
leaky_relu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void leaky_relu_kernel(const float* input, float* output, int size, float negative_slope) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        output[idx] = input[idx] > 0 ? input[idx] : negative_slope * input[idx];
    }
}

torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    leaky_relu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size, negative_slope);

    return output;
}
"""

leaky_relu_cpp_source = (
    "torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope);"
)

# Compile the inline CUDA code for LeakyReLU
leaky_relu = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for GELU
gelu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void gelu_kernel(const float* input, float* output, int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        float x = input[idx];
        output[idx] = 0.5f * (x + tanh(sqrt(2.0f / M_PI) * (x + 0.044715f * pow(x, 3.0f))));
    }
}

torch::Tensor gelu_cuda(torch::Tensor input) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    gelu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size);

    return output;
}
"""

gelu_cpp_source = (
    "torch::Tensor gelu_cuda(torch::Tensor input);"
)

# Compile the inline CUDA code for GELU
gelu = load_inline(
    name="gelu",
    cpp_sources=gelu_cpp_source,
    cuda_sources=gelu_source,
    functions=["gelu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super(ModelNew, self).__init__()
        self.conv = convolution
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = leaky_relu
        self.gelu = gelu

    def forward(self, x):
        x = self.conv.convolution_cuda(x, self.conv.weight, self.conv.bias, self.conv.stride, self.conv.padding, self.conv.dilation, self.conv.groups)
        x = x * self.multiplier
        x = self.leaky_relu.leaky_relu_cuda(x, 0.01)
        x = self.gelu.gelu_cuda(x)
        return x
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for convolution
convolution_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void convolution_kernel(const float* input, const float* weight, const float* bias, float* output, int batch_size, int in_channels, int out_channels, int height, int width, int kernel_size, int stride, int padding, int dilation, int groups) {
    int n = blockIdx.x / (groups * out_channels);
    int c = blockIdx.x % (groups * out_channels);
    int oc = c / groups;
    int ic = c % groups;
    int h = blockIdx.y;
    int w = blockIdx.z;

    int ih_start = h * stride - padding;
    int iw_start = w * stride - padding;

    float sum = 0.0f;
    for (int kh = 0; kh < kernel_size; ++kh) {
        for (int kw = 0; kw < kernel_size; ++kw) {
            int ih = ih_start + kh * dilation;
            int iw = iw_start + kw * dilation;

            if (ih >= 0 && ih < height && iw >= 0 && iw < width) {
                int i_idx = ((n * in_channels + ic) * height + ih) * width + iw;
                int k_idx = ((oc * kernel_size + kh) * kernel_size + kw) * groups + ic;
                sum += input[i_idx] * weight[k_idx];
            }
        }
    }

    int o_idx = ((n * out_channels + oc) * height + h) * width + w;
    output[o_idx] = sum + bias[c];
}

torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups) {
    auto batch_size = input.size(0);
    auto in_channels = input.size(1);
    auto out_channels = weight.size(0);
    auto height = input.size(2);
    auto width = input.size(3);
    auto kernel_size = weight.size(2);

    auto output = torch::zeros({batch_size, out_channels, height, width}, input.options());

    dim3 block_size(16, 16, 1);
    dim3 grid_size((out_channels * groups + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y, (width + block_size.z - 1) / block_size.z);

    convolution_kernel<<<grid_size, block_size>>>(input.data_ptr<float>(), weight.data_ptr<float>(), bias.data_ptr<float>(), output.data_ptr<float>(), batch_size, in_channels, out_channels, height, width, kernel_size, stride, padding, dilation, groups);

    return output;
}
"""

convolution_cpp_source = (
    "torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups);"
)

# Compile the inline CUDA code for convolution
convolution = load_inline(
    name="convolution",
    cpp_sources=convolution_cpp_source,
    cuda_sources=convolution_source,
    functions=["convolution_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for LeakyReLU
leaky_relu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void leaky_relu_kernel(const float* input, float* output, int size, float negative_slope) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        output[idx] = input[idx] > 0 ? input[idx] : negative_slope * input[idx];
    }
}

torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    leaky_relu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size, negative_slope);

    return output;
}
"""

leaky_relu_cpp_source = (
    "torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope);"
)

# Compile the inline CUDA code for LeakyReLU
leaky_relu = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for GELU
gelu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void gelu_kernel(const float* input, float* output, int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        float x = input[idx];
        output[idx] = 0.5f * (x + tanh(sqrt(2.0f / M_PI) * (x + 0.044715f * pow(x, 3.0f))));
    }
}

torch::Tensor gelu_cuda(torch::Tensor input) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    gelu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size);

    return output;
}
"""

gelu_cpp_source = (
    "torch::Tensor gelu_cuda(torch::Tensor input);"
)

# Compile the inline CUDA code for GELU
gelu = load_inline(
    name="gelu",
    cpp_sources=gelu_cpp_source,
    cuda_sources=gelu_source,
    functions=["gelu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super(ModelNew, self).__init__()
        self.conv = convolution
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = leaky_relu
        self.gelu = gelu

    def forward(self, x):
        x = self.conv.convolution_cuda(x, self.conv.weight, self.conv.bias, self.conv.stride, self.conv.padding, self.conv.dilation, self.conv.groups)
        x = x * self.multiplier
        x = self.leaky_relu.leaky_relu_cuda(x, 0.01)
        x = self.gelu.gelu_cuda(x)
        return x
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for convolution
convolution_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void convolution_kernel(const float* input, const float* weight, const float* bias, float* output, int batch_size, int in_channels, int out_channels, int height, int width, int kernel_size, int stride, int padding, int dilation, int groups) {
    int n = blockIdx.x / (groups * out_channels);
    int c = blockIdx.x % (groups * out_channels);
    int oc = c / groups;
    int ic = c % groups;
    int h = blockIdx.y;
    int w = blockIdx.z;

    int ih_start = h * stride - padding;
    int iw_start = w * stride - padding;

    float sum = 0.0f;
    for (int kh = 0; kh < kernel_size; ++kh) {
        for (int kw = 0; kw < kernel_size; ++kw) {
            int ih = ih_start + kh * dilation;
            int iw = iw_start + kw * dilation;

            if (ih >= 0 && ih < height && iw >= 0 && iw < width) {
                int i_idx = ((n * in_channels + ic) * height + ih) * width + iw;
                int k_idx = ((oc * kernel_size + kh) * kernel_size + kw) * groups + ic;
                sum += input[i_idx] * weight[k_idx];
            }
        }
    }

    int o_idx = ((n * out_channels + oc) * height + h) * width + w;
    output[o_idx] = sum + bias[c];
}

torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups) {
    auto batch_size = input.size(0);
    auto in_channels = input.size(1);
    auto out_channels = weight.size(0);
    auto height = input.size(2);
    auto width = input.size(3);
    auto kernel_size = weight.size(2);

    auto output = torch::zeros({batch_size, out_channels, height, width}, input.options());

    dim3 block_size(16, 16, 1);
    dim3 grid_size((out_channels * groups + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y, (width + block_size.z - 1) / block_size.z);

    convolution_kernel<<<grid_size, block_size>>>(input.data_ptr<float>(), weight.data_ptr<float>(), bias.data_ptr<float>(), output.data_ptr<float>(), batch_size, in_channels, out_channels, height, width, kernel_size, stride, padding, dilation, groups);

    return output;
}
"""

convolution_cpp_source = (
    "torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups);"
)

# Compile the inline CUDA code for convolution
convolution = load_inline(
    name="convolution",
    cpp_sources=convolution_cpp_source,
    cuda_sources=convolution_source,
    functions=["convolution_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for LeakyReLU
leaky_relu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void leaky_relu_kernel(const float* input, float* output, int size, float negative_slope) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        output[idx] = input[idx] > 0 ? input[idx] : negative_slope * input[idx];
    }
}

torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    leaky_relu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size, negative_slope);

    return output;
}
"""

leaky_relu_cpp_source = (
    "torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope);"
)

# Compile the inline CUDA code for LeakyReLU
leaky_relu = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for GELU
gelu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void gelu_kernel(const float* input, float* output, int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        float x = input[idx];
        output[idx] = 0.5f * (x + tanh(sqrt(2.0f / M_PI) * (x + 0.044715f * pow(x, 3.0f))));
    }
}

torch::Tensor gelu_cuda(torch::Tensor input) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    gelu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size);

    return output;
}
"""

gelu_cpp_source = (
    "torch::Tensor gelu_cuda(torch::Tensor input);"
)

# Compile the inline CUDA code for GELU
gelu = load_inline(
    name="gelu",
    cpp_sources=gelu_cpp_source,
    cuda_sources=gelu_source,
    functions=["gelu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super(ModelNew, self).__init__()
        self.conv = convolution
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = leaky_relu
        self.gelu = gelu

    def forward(self, x):
        x = self.conv.convolution_cuda(x, self.conv.weight, self.conv.bias, self.conv.stride, self.conv.padding, self.conv.dilation, self.conv.groups)
        x = x * self.multiplier
        x = self.leaky_relu.leaky_relu_cuda(x, 0.01)
        x = self.gelu.gelu_cuda(x)
        return x
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for convolution
convolution_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void convolution_kernel(const float* input, const float* weight, const float* bias, float* output, int batch_size, int in_channels, int out_channels, int height, int width, int kernel_size, int stride, int padding, int dilation, int groups) {
    int n = blockIdx.x / (groups * out_channels);
    int c = blockIdx.x % (groups * out_channels);
    int oc = c / groups;
    int ic = c % groups;
    int h = blockIdx.y;
    int w = blockIdx.z;

    int ih_start = h * stride - padding;
    int iw_start = w * stride - padding;

    float sum = 0.0f;
    for (int kh = 0; kh < kernel_size; ++kh) {
        for (int kw = 0; kw < kernel_size; ++kw) {
            int ih = ih_start + kh * dilation;
            int iw = iw_start + kw * dilation;

            if (ih >= 0 && ih < height && iw >= 0 && iw < width) {
                int i_idx = ((n * in_channels + ic) * height + ih) * width + iw;
                int k_idx = ((oc * kernel_size + kh) * kernel_size + kw) * groups + ic;
                sum += input[i_idx] * weight[k_idx];
            }
        }
    }

    int o_idx = ((n * out_channels + oc) * height + h) * width + w;
    output[o_idx] = sum + bias[c];
}

torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups) {
    auto batch_size = input.size(0);
    auto in_channels = input.size(1);
    auto out_channels = weight.size(0);
    auto height = input.size(2);
    auto width = input.size(3);
    auto kernel_size = weight.size(2);

    auto output = torch::zeros({batch_size, out_channels, height, width}, input.options());

    dim3 block_size(16, 16, 1);
    dim3 grid_size((out_channels * groups + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y, (width + block_size.z - 1) / block_size.z);

    convolution_kernel<<<grid_size, block_size>>>(input.data_ptr<float>(), weight.data_ptr<float>(), bias.data_ptr<float>(), output.data_ptr<float>(), batch_size, in_channels, out_channels, height, width, kernel_size, stride, padding, dilation, groups);

    return output;
}
"""

convolution_cpp_source = (
    "torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups);"
)

# Compile the inline CUDA code for convolution
convolution = load_inline(
    name="convolution",
    cpp_sources=convolution_cpp_source,
    cuda_sources=convolution_source,
    functions=["convolution_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for LeakyReLU
leaky_relu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void leaky_relu_kernel(const float* input, float* output, int size, float negative_slope) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        output[idx] = input[idx] > 0 ? input[idx] : negative_slope * input[idx];
    }
}

torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    leaky_relu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size, negative_slope);

    return output;
}
"""

leaky_relu_cpp_source = (
    "torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope);"
)

# Compile the inline CUDA code for LeakyReLU
leaky_relu = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for GELU
gelu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void gelu_kernel(const float* input, float* output, int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        float x = input[idx];
        output[idx] = 0.5f * (x + tanh(sqrt(2.0f / M_PI) * (x + 0.044715f * pow(x, 3.0f))));
    }
}

torch::Tensor gelu_cuda(torch::Tensor input) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    gelu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size);

    return output;
}
"""

gelu_cpp_source = (
    "torch::Tensor gelu_cuda(torch::Tensor input);"
)

# Compile the inline CUDA code for GELU
gelu = load_inline(
    name="gelu",
    cpp_sources=gelu_cpp_source,
    cuda_sources=gelu_source,
    functions=["gelu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super(ModelNew, self).__init__()
        self.conv = convolution
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = leaky_relu
        self.gelu = gelu

    def forward(self, x):
        x = self.conv.convolution_cuda(x, self.conv.weight, self.conv.bias, self.conv.stride, self.conv.padding, self.conv.dilation, self.conv.groups)
        x = x * self.multiplier
        x = self.leaky_relu.leaky_relu_cuda(x, 0.01)
        x = self.gelu.gelu_cuda(x)
        return x
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for convolution
convolution_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void convolution_kernel(const float* input, const float* weight, const float* bias, float* output, int batch_size, int in_channels, int out_channels, int height, int width, int kernel_size, int stride, int padding, int dilation, int groups) {
    int n = blockIdx.x / (groups * out_channels);
    int c = blockIdx.x % (groups * out_channels);
    int oc = c / groups;
    int ic = c % groups;
    int h = blockIdx.y;
    int w = blockIdx.z;

    int ih_start = h * stride - padding;
    int iw_start = w * stride - padding;

    float sum = 0.0f;
    for (int kh = 0; kh < kernel_size; ++kh) {
        for (int kw = 0; kw < kernel_size; ++kw) {
            int ih = ih_start + kh * dilation;
            int iw = iw_start + kw * dilation;

            if (ih >= 0 && ih < height && iw >= 0 && iw < width) {
                int i_idx = ((n * in_channels + ic) * height + ih) * width + iw;
                int k_idx = ((oc * kernel_size + kh) * kernel_size + kw) * groups + ic;
                sum += input[i_idx] * weight[k_idx];
            }
        }
    }

    int o_idx = ((n * out_channels + oc) * height + h) * width + w;
    output[o_idx] = sum + bias[c];
}

torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups) {
    auto batch_size = input.size(0);
    auto in_channels = input.size(1);
    auto out_channels = weight.size(0);
    auto height = input.size(2);
    auto width = input.size(3);
    auto kernel_size = weight.size(2);

    auto output = torch::zeros({batch_size, out_channels, height, width}, input.options());

    dim3 block_size(16, 16, 1);
    dim3 grid_size((out_channels * groups + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y, (width + block_size.z - 1) / block_size.z);

    convolution_kernel<<<grid_size, block_size>>>(input.data_ptr<float>(), weight.data_ptr<float>(), bias.data_ptr<float>(), output.data_ptr<float>(), batch_size, in_channels, out_channels, height, width, kernel_size, stride, padding, dilation, groups);

    return output;
}
"""

convolution_cpp_source = (
    "torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups);"
)

# Compile the inline CUDA code for convolution
convolution = load_inline(
    name="convolution",
    cpp_sources=convolution_cpp_source,
    cuda_sources=convolution_source,
    functions=["convolution_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for LeakyReLU
leaky_relu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void leaky_relu_kernel(const float* input, float* output, int size, float negative_slope) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        output[idx] = input[idx] > 0 ? input[idx] : negative_slope * input[idx];
    }
}

torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    leaky_relu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size, negative_slope);

    return output;
}
"""

leaky_relu_cpp_source = (
    "torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope);"
)

# Compile the inline CUDA code for LeakyReLU
leaky_relu = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for GELU
gelu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void gelu_kernel(const float* input, float* output, int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        float x = input[idx];
        output[idx] = 0.5f * (x + tanh(sqrt(2.0f / M_PI) * (x + 0.044715f * pow(x, 3.0f))));
    }
}

torch::Tensor gelu_cuda(torch::Tensor input) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    gelu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size);

    return output;
}
"""

gelu_cpp_source = (
    "torch::Tensor gelu_cuda(torch::Tensor input);"
)

# Compile the inline CUDA code for GELU
gelu = load_inline(
    name="gelu",
    cpp_sources=gelu_cpp_source,
    cuda_sources=gelu_source,
    functions=["gelu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super(ModelNew, self).__init__()
        self.conv = convolution
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = leaky_relu
        self.gelu = gelu

    def forward(self, x):
        x = self.conv.convolution_cuda(x, self.conv.weight, self.conv.bias, self.conv.stride, self.conv.padding, self.conv.dilation, self.conv.groups)
        x = x * self.multiplier
        x = self.leaky_relu.leaky_relu_cuda(x, 0.01)
        x = self.gelu.gelu_cuda(x)
        return x
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for convolution
convolution_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void convolution_kernel(const float* input, const float* weight, const float* bias, float* output, int batch_size, int in_channels, int out_channels, int height, int width, int kernel_size, int stride, int padding, int dilation, int groups) {
    int n = blockIdx.x / (groups * out_channels);
    int c = blockIdx.x % (groups * out_channels);
    int oc = c / groups;
    int ic = c % groups;
    int h = blockIdx.y;
    int w = blockIdx.z;

    int ih_start = h * stride - padding;
    int iw_start = w * stride - padding;

    float sum = 0.0f;
    for (int kh = 0; kh < kernel_size; ++kh) {
        for (int kw = 0; kw < kernel_size; ++kw) {
            int ih = ih_start + kh * dilation;
            int iw = iw_start + kw * dilation;

            if (ih >= 0 && ih < height && iw >= 0 && iw < width) {
                int i_idx = ((n * in_channels + ic) * height + ih) * width + iw;
                int k_idx = ((oc * kernel_size + kh) * kernel_size + kw) * groups + ic;
                sum += input[i_idx] * weight[k_idx];
            }
        }
    }

    int o_idx = ((n * out_channels + oc) * height + h) * width + w;
    output[o_idx] = sum + bias[c];
}

torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups) {
    auto batch_size = input.size(0);
    auto in_channels = input.size(1);
    auto out_channels = weight.size(0);
    auto height = input.size(2);
    auto width = input.size(3);
    auto kernel_size = weight.size(2);

    auto output = torch::zeros({batch_size, out_channels, height, width}, input.options());

    dim3 block_size(16, 16, 1);
    dim3 grid_size((out_channels * groups + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y, (width + block_size.z - 1) / block_size.z);

    convolution_kernel<<<grid_size, block_size>>>(input.data_ptr<float>(), weight.data_ptr<float>(), bias.data_ptr<float>(), output.data_ptr<float>(), batch_size, in_channels, out_channels, height, width, kernel_size, stride, padding, dilation, groups);

    return output;
}
"""

convolution_cpp_source = (
    "torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups);"
)

# Compile the inline CUDA code for convolution
convolution = load_inline(
    name="convolution",
    cpp_sources=convolution_cpp_source,
    cuda_sources=convolution_source,
    functions=["convolution_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for LeakyReLU
leaky_relu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void leaky_relu_kernel(const float* input, float* output, int size, float negative_slope) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        output[idx] = input[idx] > 0 ? input[idx] : negative_slope * input[idx];
    }
}

torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    leaky_relu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size, negative_slope);

    return output;
}
"""

leaky_relu_cpp_source = (
    "torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope);"
)

# Compile the inline CUDA code for LeakyReLU
leaky_relu = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for GELU
gelu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void gelu_kernel(const float* input, float* output, int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        float x = input[idx];
        output[idx] = 0.5f * (x + tanh(sqrt(2.0f / M_PI) * (x + 0.044715f * pow(x, 3.0f))));
    }
}

torch::Tensor gelu_cuda(torch::Tensor input) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    gelu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size);

    return output;
}
"""

gelu_cpp_source = (
    "torch::Tensor gelu_cuda(torch::Tensor input);"
)

# Compile the inline CUDA code for GELU
gelu = load_inline(
    name="gelu",
    cpp_sources=gelu_cpp_source,
    cuda_sources=gelu_source,
    functions=["gelu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super(ModelNew, self).__init__()
        self.conv = convolution
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = leaky_relu
        self.gelu = gelu

    def forward(self, x):
        x = self.conv.convolution_cuda(x, self.conv.weight, self.conv.bias, self.conv.stride, self.conv.padding, self.conv.dilation, self.conv.groups)
        x = x * self.multiplier
        x = self.leaky_relu.leaky_relu_cuda(x, 0.01)
        x = self.gelu.gelu_cuda(x)
        return x
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for convolution
convolution_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void convolution_kernel(const float* input, const float* weight, const float* bias, float* output, int batch_size, int in_channels, int out_channels, int height, int width, int kernel_size, int stride, int padding, int dilation, int groups) {
    int n = blockIdx.x / (groups * out_channels);
    int c = blockIdx.x % (groups * out_channels);
    int oc = c / groups;
    int ic = c % groups;
    int h = blockIdx.y;
    int w = blockIdx.z;

    int ih_start = h * stride - padding;
    int iw_start = w * stride - padding;

    float sum = 0.0f;
    for (int kh = 0; kh < kernel_size; ++kh) {
        for (int kw = 0; kw < kernel_size; ++kw) {
            int ih = ih_start + kh * dilation;
            int iw = iw_start + kw * dilation;

            if (ih >= 0 && ih < height && iw >= 0 && iw < width) {
                int i_idx = ((n * in_channels + ic) * height + ih) * width + iw;
                int k_idx = ((oc * kernel_size + kh) * kernel_size + kw) * groups + ic;
                sum += input[i_idx] * weight[k_idx];
            }
        }
    }

    int o_idx = ((n * out_channels + oc) * height + h) * width + w;
    output[o_idx] = sum + bias[c];
}

torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups) {
    auto batch_size = input.size(0);
    auto in_channels = input.size(1);
    auto out_channels = weight.size(0);
    auto height = input.size(2);
    auto width = input.size(3);
    auto kernel_size = weight.size(2);

    auto output = torch::zeros({batch_size, out_channels, height, width}, input.options());

    dim3 block_size(16, 16, 1);
    dim3 grid_size((out_channels * groups + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y, (width + block_size.z - 1) / block_size.z);

    convolution_kernel<<<grid_size, block_size>>>(input.data_ptr<float>(), weight.data_ptr<float>(), bias.data_ptr<float>(), output.data_ptr<float>(), batch_size, in_channels, out_channels, height, width, kernel_size, stride, padding, dilation, groups);

    return output;
}
"""

convolution_cpp_source = (
    "torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups);"
)

# Compile the inline CUDA code for convolution
convolution = load_inline(
    name="convolution",
    cpp_sources=convolution_cpp_source,
    cuda_sources=convolution_source,
    functions=["convolution_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for LeakyReLU
leaky_relu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void leaky_relu_kernel(const float* input, float* output, int size, float negative_slope) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        output[idx] = input[idx] > 0 ? input[idx] : negative_slope * input[idx];
    }
}

torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    leaky_relu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size, negative_slope);

    return output;
}
"""

leaky_relu_cpp_source = (
    "torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope);"
)

# Compile the inline CUDA code for LeakyReLU
leaky_relu = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for GELU
gelu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void gelu_kernel(const float* input, float* output, int size) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        float x = input[idx];
        output[idx] = 0.5f * (x + tanh(sqrt(2.0f / M_PI) * (x + 0.044715f * pow(x, 3.0f))));
    }
}

torch::Tensor gelu_cuda(torch::Tensor input) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    gelu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size);

    return output;
}
"""

gelu_cpp_source = (
    "torch::Tensor gelu_cuda(torch::Tensor input);"
)

# Compile the inline CUDA code for GELU
gelu = load_inline(
    name="gelu",
    cpp_sources=gelu_cpp_source,
    cuda_sources=gelu_source,
    functions=["gelu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super(ModelNew, self).__init__()
        self.conv = convolution
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = leaky_relu
        self.gelu = gelu

    def forward(self, x):
        x = self.conv.convolution_cuda(x, self.conv.weight, self.conv.bias, self.conv.stride, self.conv.padding, self.conv.dilation, self.conv.groups)
        x = x * self.multiplier
        x = self.leaky_relu.leaky_relu_cuda(x, 0.01)
        x = self.gelu.gelu_cuda(x)
        return x
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for convolution
convolution_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void convolution_kernel(const float* input, const float* weight, const float* bias, float* output, int batch_size, int in_channels, int out_channels, int height, int width, int kernel_size, int stride, int padding, int dilation, int groups) {
    int n = blockIdx.x / (groups * out_channels);
    int c = blockIdx.x % (groups * out_channels);
    int oc = c / groups;
    int ic = c % groups;
    int h = blockIdx.y;
    int w = blockIdx.z;

    int ih_start = h * stride - padding;
    int iw_start = w * stride - padding;

    float sum = 0.0f;
    for (int kh = 0; kh < kernel_size; ++kh) {
        for (int kw = 0; kw < kernel_size; ++kw) {
            int ih = ih_start + kh * dilation;
            int iw = iw_start + kw * dilation;

            if (ih >= 0 && ih < height && iw >= 0 && iw < width) {
                int i_idx = ((n * in_channels + ic) * height + ih) * width + iw;
                int k_idx = ((oc * kernel_size + kh) * kernel_size + kw) * groups + ic;
                sum += input[i_idx] * weight[k_idx];
            }
        }
    }

    int o_idx = ((n * out_channels + oc) * height + h) * width + w;
    output[o_idx] = sum + bias[c];
}

torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups) {
    auto batch_size = input.size(0);
    auto in_channels = input.size(1);
    auto out_channels = weight.size(0);
    auto height = input.size(2);
    auto width = input.size(3);
    auto kernel_size = weight.size(2);

    auto output = torch::zeros({batch_size, out_channels, height, width}, input.options());

    dim3 block_size(16, 16, 1);
    dim3 grid_size((out_channels * groups + block_size.x - 1) / block_size.x, (height + block_size.y - 1) / block_size.y, (width + block_size.z - 1) / block_size.z);

    convolution_kernel<<<grid_size, block_size>>>(input.data_ptr<float>(), weight.data_ptr<float>(), bias.data_ptr<float>(), output.data_ptr<float>(), batch_size, in_channels, out_channels, height, width, kernel_size, stride, padding, dilation, groups);

    return output;
}
"""

convolution_cpp_source = (
    "torch::Tensor convolution_cuda(torch::Tensor input, torch::Tensor weight, torch::Tensor bias, int stride, int padding, int dilation, int groups);"
)

# Compile the inline CUDA code for convolution
convolution = load_inline(
    name="convolution",
    cpp_sources=convolution_cpp_source,
    cuda_sources=convolution_source,
    functions=["convolution_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


# Define the custom CUDA kernel for LeakyReLU
leaky_relu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void leaky_relu_kernel(const float* input, float* output, int size, float negative_slope) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx < size) {
        output[idx] = input[idx] > 0 ? input[idx] : negative_slope * input[idx];
    }
}

torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope) {
    auto size = input.numel();
    auto output = torch::zeros_like(input);

    const int block_size = 256;
    const int num_blocks = (size + block_size - 1) / block_size;

    leaky_relu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), size, negative_slope);

    return output;
}
"""

leaky_relu_cpp_source = (
    "torch::Tensor leaky_relu_cuda(torch::Tensor input, float negative_slope);"
)

# Compile the inline CUDA code for LeakyReLU
leaky_relu = load_inline(
    name="leaky_relu",
    cpp_sources=leaky_relu_cpp_source,
    cuda_sources=leaky_relu_source,
    functions=["leaky_relu_cuda"],
    verbose=True,
    extra_cflags=[""],
   