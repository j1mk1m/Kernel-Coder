    Your custom CUDA operators should be implemented as standalone C++ functions and loaded using `load_inline` from `torch.utils.cpp_extension`. Each function should be designed to perform a specific operation efficiently on the GPU.

    Be sure to follow the same structure as the example provided, including the definition of the CUDA kernel, the C++ source code, and the loading of the inline CUDA code using `load_inline`.

    Make sure your implementation includes all necessary imports and follows PyTorch conventions for defining models and performing computations. ```python












































s

