Note: Feel free to add any necessary imports at the beginning of your code. Make sure all used libraries are available via pip install. 

Please do not include comments in the code blocks unless they explain non-obvious parts of the code.

**Your task is to optimize the given architecture using custom CUDA operators, focusing on potential performance bottlenecks such as memory bandwidth, compute efficiency, and parallelism.**

### Constraints:

- You must use PyTorch's `load_inline` to compile and load your custom CUDA kernels.
- You can replace any number of operations with custom CUDA kernels, but you cannot change the overall structure of the model (e.g., adding more layers).
- Your solution should aim for significant speedup compared to the original implementation.
- Ensure that the custom CUDA kernels handle edge cases correctly (e.g., empty tensors).

### Hints:

- Consider operator fusion, where multiple operations can be combined into a single kernel for better utilization of GPU resources.
- Explore different algorithms for each operation, such as efficient matrix multiplication techniques, alternative ways to perform global average pooling, etc.
- Pay attention to memory access patterns and ensure they are coalesced for optimal performance.
- Use appropriate grid and block dimensions for launching CUDA kernels.

### Expected Output:

The expected output is a fully functional PyTorch model (`ModelNew`) that uses custom CUDA kernels for specific operations, replacing the original PyTorch operators. The code should compile and run without errors. ```python

















