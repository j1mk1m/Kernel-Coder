### Guidelines:
- Replace any operations that can be accelerated with custom CUDA kernels.
- Feel free to combine multiple operations into a single kernel if it makes sense.
- Consider optimizing memory access patterns.
- Ensure the final architecture still produces the same output as the original `Model`.
- Optimize the forward pass for better performance.

### Hints:
- Average pooling can often be implemented more efficiently using CUDA.
- Transposed convolutions can also benefit from custom CUDA kernels.
- Clamping operations can be combined with other operations if possible.
- Spatial softmax can be implemented using efficient algorithms that avoid unnecessary computations.
- Multiplication by a learnable scale can be done efficiently using CUDA.

### Expected Output:
```python
```