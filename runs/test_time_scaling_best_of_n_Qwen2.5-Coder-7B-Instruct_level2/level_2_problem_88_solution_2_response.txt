### Constraints:
- The code must be compilable and run on a GPU.
- The code must be fully functional and produce the same output as the original architecture.
- You can use any PyTorch functionality but the operators listed below cannot be used:
    - `torch.matmul`
    - `torch.add`
    - `torch.mul`
    - `torch.sigmoid`

### Bonus:
- Implement operator fusion opportunities (combining multiple operators into a single kernel).
- Consider algorithmic changes such as online softmax.

## Solution:

```python
```