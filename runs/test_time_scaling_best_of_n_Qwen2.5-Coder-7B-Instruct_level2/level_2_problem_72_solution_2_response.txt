Please note that the inputs and outputs should be compatible with the original model. The model should still take a tensor of shape `(batch_size, in_channels, depth, height, width)` as input and produce a tensor of shape `(batch_size, out_channels, depth//4, height//4, width//4)` as output.

You can use any CUDA optimization techniques such as shared memory, coalesced memory access, etc., but please ensure that the implementation remains readable and maintainable. Also, feel free to modify the architecture as per your needs to achieve better performance. However, the overall structure and functionality of the model should remain intact.