```python
class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, groups, eps=1e-5):
        super(ModelNew, self).__init__()
        # Implement custom CUDA kernels here
        pass

    def forward(self, x):
        # Use custom CUDA kernels in the forward method here
        pass
```

Note: The goal is to optimize the performance of the model by replacing PyTorch operators with custom CUDA kernels where appropriate. Feel free to experiment with different operators and combinations of operators to achieve the best performance.

---

Here is the expected output:

```python
class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, groups, eps=1e-5):
        super(ModelNew, self).__init__()
        self.conv = CustomConv2d(in_channels, out_channels, kernel_size)
        self.group_norm = CustomGroupNorm(groups, out_channels, eps=eps)
        self.tanh = CustomTanh()
        self.hard_swish = CustomHardswish()

    def forward(self, x):
        x_conv = self.conv(x)
        x_norm = self.group_norm(x_conv)
        x_tanh = self.tanh(x_norm)
        x_hard_swish = self.hard_swish(x_tanh)
        x_res = x_conv + x_hard_swish
        x_logsumexp = torch.logsumexp(x_res, dim=1, keepdim=True)
        return x_logsumexp
```

The `CustomConv2d`, `CustomGroupNorm`, `CustomTanh`, and `CustomHardswish` classes should be implemented using custom CUDA kernels. Ensure that the code compiles and runs correctly.