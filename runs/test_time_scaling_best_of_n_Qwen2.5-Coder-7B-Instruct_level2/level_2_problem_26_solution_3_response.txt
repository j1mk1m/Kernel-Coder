Your solution should aim to maximize performance gains through the use of custom CUDA kernels. Feel free to optimize any part of the architecture, including but not limited to the 3D transposed convolution, addition, and HardSwish activation. Consider using techniques such as operator fusion, algorithmic optimizations, and efficient memory access patterns. 

Remember that the goal is to achieve the highest possible performance while maintaining correctness. 

Please provide the full implementation of `ModelNew` and the necessary helper functions. Ensure that all operations within `ModelNew` are implemented using custom CUDA kernels when appropriate.

### Constraints:
- You can only use PyTorch's C++ API to define and compile the custom CUDA kernels.
- You cannot use any third-party libraries for CUDA programming other than PyTorch's C++ API.
- Your custom CUDA kernels must be able to run on any GPU supported by PyTorch.
- You must ensure that the `forward` method of `ModelNew` returns the same output as the `forward` method of `Model`.

### Tips:
- Consider optimizing the 3D transposed convolution by using efficient memory access patterns and avoiding unnecessary data copies.
- For the addition operation, consider implementing it as a simple element-wise operation.
- For the HardSwish activation, consider implementing it as a piecewise linear function.
- You can use PyTorch's `load_inline` function to compile and link the custom CUDA kernels at runtime.
- Make sure to test your implementation thoroughly to ensure correctness and performance gains.

### Expected Output:
The expected output is the full implementation of `ModelNew` and the necessary helper functions. Ensure that all operations within `ModelNew` are implemented using custom CUDA kernels when appropriate.

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Define custom CUDA kernels here...

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape):
        super(ModelNew, self).__init__()
        # Initialize custom CUDA kernels and parameters here...

    def forward(self, x, add_input):
        # Implement custom CUDA kernels for each operation here...
        pass

# Example usage:
if __name__ == "__main__":
    batch_size = 128
    in_channels = 32
    out_channels = 64
    D, H, W = 16, 16, 16
    kernel_size = 3
    stride = 2
    padding = 1
    output_padding = 1
    bias_shape = (out_channels, 1, 1, 1, 1)

    model = ModelNew(in_channels, out_channels, kernel_size, stride, padding, output_padding, bias_shape)
    x, add_input = get_inputs()
    output = model(x, add_input)
    print(output.shape)  # Should match the output shape of the original Model
```

Make sure that the provided code compiles and runs without errors. Test the performance of `ModelNew` compared to the original `Model`.