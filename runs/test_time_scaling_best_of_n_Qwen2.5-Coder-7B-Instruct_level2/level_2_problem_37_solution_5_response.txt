Please do not use any external libraries other than PyTorch. Use PyTorch's `load_inline` functionality to compile and load the custom CUDA operators.

Make sure your implementation achieves at least 2x speedup over the original PyTorch implementation. You should aim for higher speeds if possible. Your solution must be efficient and scalable for large batch sizes and feature dimensions.

Please provide the full code for both the original and optimized architectures, including the custom CUDA kernels. Ensure that the code is well-commented and easy to understand.