### Requirements:
- Replace the matrix multiplication (`nn.Linear`) with a custom CUDA kernel.
- Apply dropout using a custom CUDA kernel.
- Combine the softmax operation with the previous operations within a single CUDA kernel to avoid additional memory transfers.

Your solution should leverage CUDA's parallel processing capabilities to achieve performance improvements. Ensure that all operations are correctly implemented and the final output matches the original model's behavior.