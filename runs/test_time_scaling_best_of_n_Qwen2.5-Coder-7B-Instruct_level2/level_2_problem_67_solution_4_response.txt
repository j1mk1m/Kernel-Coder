Please follow the same style as the example provided above. Use the `load_inline` function from `torch.utils.cpp_extension` to compile the CUDA kernels. Be sure to include any necessary imports at the beginning of your code snippet.

Here's the code to load the CUDA extension:

```python
from torch.utils.cpp_extension import load_inline

conv_gelu_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void conv_gelu_kernel(float* input, float* output, int batch_size, int channels, int height, int width) {
    // Implement the convolution and GELU operation here
    // This is just a placeholder for the actual implementation
}

torch::Tensor conv_gelu_cuda(torch::Tensor input) {
    auto batch_size = input.size(0);
    auto channels = input.size(1);
    auto height = input.size(2);
    auto width = input.size(3);
    auto output = torch::zeros({batch_size, channels, height, width}, input.options());

    const int block_size = 256;
    const int num_blocks = (batch_size * channels * height * width + block_size - 1) / block_size;

    conv_gelu_kernel<<<num_blocks, block_size>>>(input.data_ptr<float>(), output.data_ptr<float>(), batch_size, channels, height, width);

    return output;
}
"""

conv_gelu_cpp_source = (
    "torch::Tensor conv_gelu_cuda(torch::Tensor input);"
)

conv_gelu = load_inline(
    name="conv_gelu",
    cpp_sources=conv_gelu_cpp_source,
    cuda_sources=conv_gelu_source,
    functions=["conv_gelu_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)
```

Use the `conv_gelu` function to replace the convolution and GELU operations in the `forward` method of `ModelNew`.

```python
class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size):
        super(ModelNew, self).__init__()
        self.conv_gelu = conv_gelu

    def forward(self, x):
        x = self.conv_gelu.conv_gelu_cuda(x)
        x = torch.nn.functional.adaptive_avg_pool2d(x, 1)
        x = x.squeeze(-1).squeeze(-1)
        return x
```

Make sure to adjust the dimensions and types in the CUDA kernel to match those of the input tensor. Also, ensure that the CUDA kernel is correctly implemented to perform the convolution and GELU operations efficiently.