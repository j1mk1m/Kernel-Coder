Note: Make sure your implementation does not use PyTorch's built-in CUDA operators for KL divergence calculation. Instead, implement it using custom CUDA kernels.
```