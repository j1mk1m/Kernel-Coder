Note that it is fine to use libraries such as torch.cuda, but do not use any other external libraries except for those provided by PyTorch itself. 

Also note that it is fine to use existing PyTorch operators in the custom CUDA kernels, e.g., you can call `F.relu()` inside your CUDA kernel if needed. However, try to optimize the overall computation as much as possible. For instance, if you decide to implement a custom convolution, you should aim to achieve high throughput by optimizing memory access patterns and parallelism.

Please provide detailed comments explaining your choices and optimizations.