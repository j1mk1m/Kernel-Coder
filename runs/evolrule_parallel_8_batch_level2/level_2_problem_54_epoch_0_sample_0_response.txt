Also, make sure to import all necessary modules, and that the model can be initialized with get_init_inputs() and run with get_inputs(). The replacement must have the same number of parameters as the original. The new code should be as fast as possible. 

The architecture to optimize is the following:

class Model(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super(Model, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.leaky_relu = nn.LeakyReLU()

    def forward(self, x):
        x = self.conv(x)
        x = x * self.multiplier
        x = self.leaky_relu(x)
        x = torch.nn.functional.gelu(x)
        return x

The steps I want you to take are:

1. Identify which PyTorch operators in the forward pass are worth replacing with custom CUDA kernels for performance improvement. 

2. For each operator you choose to replace, design a custom CUDA kernel that can be inlined in the Python code using load_inline. 

3. Combine multiple operators into a single kernel if it provides a performance benefit (e.g., conv + multiply + activation).

4. Ensure that the replacement kernels have the same functionality and number of parameters as the original model.

5. Write the Python code for the new ModelNew class that uses these custom kernels, making sure it works with the given get_inputs() and get_init_inputs() functions.



Okay, I need to optimize the given PyTorch model using custom CUDA kernels. Let me start by understanding the model's forward pass. The model does a convolution, then multiplies by a learnable scalar (the multiplier), applies LeakyReLU, and then applies GELU. 

First, I should identify which parts can be optimized. The convolution is already a CUDA operator, but maybe combining it with subsequent operations could help. The multiplication by the multiplier is a simple element-wise operation, which might be fused with the convolution. The activations (LeakyReLU and GELU) are also element-wise. Combining them into a single kernel might reduce memory transfers and latency.

Let me think about the steps:

1. The convolution is a 2D convolution. The multiplier is a parameter of shape (out_channels, 1, 1), so it's a per-channel scaling. So after convolution, each channel is scaled by the corresponding multiplier value. That's an element-wise multiplication across channels. 

2. Then there's LeakyReLU followed by GELU. Since both are element-wise activations, maybe they can be combined into a single kernel. However, GELU is a more complex function, but maybe it's worth trying to combine all these steps into a single kernel after the convolution.

Alternatively, maybe I can combine the convolution's output with the scaling and the activations into one kernel. But handling the convolution in CUDA requires implementing the convolution itself, which is more complex. Wait, but the existing PyTorch Conv2d is already a CUDA kernel. So replacing that might not be straightforward. However, maybe the subsequent operations can be fused.

Wait, the problem allows replacing some operators. The original code has four main steps: conv, multiply, leaky_relu, and gelu. 

The multiplication by the multiplier is a simple per-channel scaling. Since the multiplier has shape (out_channels, 1, 1), multiplying after convolution is equivalent to scaling each channel by that scalar. 

So perhaps the multiplication can be combined with the activation functions. Let me think about the data flow:

After convolution, the output is (N, C_out, H, W). The multiplier is (C_out, 1, 1). So multiplying by the multiplier scales each channel. 

Then, applying LeakyReLU and GELU sequentially. Since both are element-wise, perhaps they can be combined into a single kernel. 

So maybe the plan is to:

- Keep the convolution as is (since it's a standard op and already optimized), but then fuse the multiply, LeakyReLU, and GELU into a single kernel. 

Alternatively, perhaps even fuse the multiply into the convolution's computation. But convolution is a separate op. 

Wait, but the problem allows replacing multiple operators. Let me think about possible fusions:

Option 1: Keep convolution as PyTorch's Conv2d, then combine the multiply and the two activations into one kernel. 

Option 2: Replace the entire sequence (conv + multiply + activations) with a custom kernel. But implementing convolution from scratch might be too much. Since the existing Conv2d is already efficient, maybe not worth it. 

Alternatively, perhaps the multiply and the two activations can be done in a single kernel after the convolution. That's probably feasible.

Let me outline the steps for Option 1:

After the convolution, the output is a tensor. The multiply by the multiplier is a per-channel scaling. So each element in channel c is scaled by multiplier[c]. 

Then apply LeakyReLU: max(0, x) + negative_slope * min(0, x). 

Then apply GELU, which is a more complex function. 

Wait, but applying both activations one after the other might have some redundancy. Alternatively, combining their computation might be possible. 

Wait, the model applies LeakyReLU first and then GELU. But perhaps those can be combined into a single element-wise function. Let me check the functions:

Leaky ReLU: x if x>0 else 0.1*x (assuming default slope). 

GELU is a smooth approximation of ReLU, but combining them might not make sense. Hmm, perhaps not. The order is important here. So the user's model applies LeakyReLU first, then GELU. So both must be applied in sequence. 

Alternatively, maybe the GELU can be done as an online approximation, but not sure.

Alternatively, since all operations after convolution are element-wise, combining them into a single kernel would eliminate intermediate memory writes and copies. 

The plan:

- After the convolution, run a custom kernel that does the scaling by the multiplier, then applies LeakyReLU, then GELU. 

This would replace three operations (multiply, leaky_relu, gelu) into one kernel. 

That's the way to go. Let me see how to implement that.

First, the multiplier is a parameter of shape (out_channels, 1, 1). Since the output of the convolution is (N, C, H, W), multiplying by the multiplier would be equivalent to broadcasting the multiplier over H and W dimensions. 

So in CUDA, for each element in the output tensor, the value is scaled by the corresponding channel's multiplier. 

Then apply LeakyReLU: for each element, if x <=0, compute 0.01*x (assuming default slope), else x. 

Then apply GELU. 

Wait, but GELU is a more complex function. The standard GELU is x * 0.5 * (1 + tanh(sqrt(2/pi) * (x + 0.044715 * x^3))). 

Alternatively, using the approximation, but the exact function might be needed. 

Wait, but implementing GELU in CUDA would require computing that formula. Alternatively, perhaps use the torch implementation's approximation? 

Alternatively, using the erf-based formula. 

But for CUDA kernel, we can compute it directly. 

So the steps in the kernel would be:

for each element:

value = conv_out * multiplier[channel]

then apply LeakyReLU:

if (value <=0) ? 0.01 * value : value

then apply GELU:

gelu_value = value * 0.5 * (1 + erf(value / sqrt(2)))

Wait, or the exact formula? Need to check. 

Alternatively, use the standard GELU formula. Let me confirm the formula.

The standard GELU is 0.5 * x * (1 + tanh( sqrt(2/pi) * (x + 0.044715 * x^3) )) 

Alternatively, the approximate form is x * sigmoid(1.702*x). But the user's code uses F.gelu, which I think uses the exact one. 

Hmm, so implementing GELU accurately would be needed. Let me think about the steps.

Alternatively, perhaps combining LeakyReLU and GELU into one step might not be straightforward, but since they are sequential, we can do each step in the kernel.

So the plan is:

Create a custom kernel that takes the convolution output, the multiplier, and the slope for LeakyReLU (assuming it's fixed?), then applies the scaling, then the two activations.

Wait, the LeakyReLU in the original code is an instance of nn.LeakyReLU(), which uses a default negative_slope of 0.01. So we can hardcode that value in the kernel.

Wait, but the original model has self.leaky_relu = nn.LeakyReLU(), which by default has a slope of 0.01. So in the kernel, I can use that value unless the model allows changing it, but since the problem states the replacement must have the same parameters, we can hardcode it here.

So steps in the kernel:

For each element in the tensor:

channel = c (from the tensor's channel index)

scale = multiplier[channel, 0, 0]

scaled_val = input_val * scale 

leaky_val = max(scaled_val, scaled_val * slope) if scaled_val < 0 else scaled_val 

Wait, no. Wait, LeakyReLU is: 

output = x if x > 0 else x * negative_slope.

Wait, so if scaled_val >=0, then leaky_val = scaled_val. Else, scaled_val * 0.01 (if slope is 0.01).

Wait, the LeakyReLU formula is:

out = max(0, x) + negative_slope * min(0, x)

So yes, that's correct.

Then apply GELU to that result.

Thus, the kernel steps are:

1. For each element (n, c, h, w), get the value from the convolution output.

2. Multiply by multiplier[c], since the multiplier's shape is (C, 1, 1). So the multiplier for channel c is multiplier[c][0][0].

3. Apply LeakyReLU: if the scaled value is negative, multiply by 0.01, else keep it.

4. Apply GELU to the result.

Thus, this can be done in a single kernel.

So the plan is to write a CUDA kernel that takes the convolution output tensor, the multiplier parameter, and applies these three steps.

Now, how to structure the code.

First, in the ModelNew class, we can keep the Conv2d as is, but then replace the multiplication, LeakyReLU, and GELU with this fused kernel.

Wait, but the multiplier is a parameter of the model. So in the forward pass, the code would be:

x = self.conv(x) 

then run the custom kernel on x and self.multiplier, then return the result.

Thus, the custom kernel needs to take as inputs the input tensor (x after conv), the multiplier tensor (self.multiplier), and produce the output.

So the kernel's parameters would be:

- input tensor (float*), multiplier (float*), output tensor (float*).

The multiplier has size (out_channels, 1, 1), so when accessed, for each channel c, the value is multiplier[c][0][0].

In CUDA, for each element, the index can be decomposed into (n, c, h, w). The channel c determines the multiplier value to use.

The kernel will need to compute for each element:

value = input[n][c][h][w] * multiplier[c][0][0]

then apply LeakyReLU (slope 0.01), then GELU.

Wait, but the multiplier is a parameter of the model. So in the custom kernel code, the multiplier is a tensor that is passed in each time.

Now, to implement the kernel.

First, the CUDA kernel code:

We can write a kernel function that loops over each element. Since the tensor is 4D, we need to calculate the indices properly.

The kernel would have:

__global__ void fused_ops_kernel(const float* input, const float* multiplier, float* output, int batch_size, int channels, int height, int width, float slope) {

    int idx = blockIdx.x * blockDim.x + threadIdx.x;

    if (idx >= batch_size * channels * height * width) return;

    // compute indices
    int w = idx % width;
    int h = (idx / width) % height;
    int c = (idx / (width * height)) % channels;
    int n = idx / (width * height * channels);

    float val = input[idx]; // but maybe need to handle 4D indexing correctly?

Wait, actually, the input is a 4D tensor stored in a 1D array. So the stride-based access may be different. Alternatively, the exact indices can be computed as follows:

But in CUDA, tensors are stored in row-major order, so the index can be computed as:

index = n * (channels * height * width) + c * (height * width) + h * width + w;

So given the flattened index 'idx', we can compute the components.

Alternatively, to compute n, c, h, w from the linear index:

Let me think:

The total size is B x C x H x W. So for a given index 'idx', we can compute:

w = idx % W

remainder = idx / W

h = remainder % H

remainder = remainder / H

c = remainder % C

n = remainder / C

Thus, for each element, we can get the channel c, then get the multiplier value from multiplier[c][0][0].

Wait, but the multiplier is a tensor of shape (C, 1, 1). So its storage is a 1D array of C elements (since the last two dimensions are 1). So the value for channel c is at position c in the multiplier's storage.

Thus, multiplier_val = multiplier[c * 1 * 1 + 0 * 1 + 0] = multiplier[c].

Wait, if the multiplier is stored as a 1D array, then yes. But in PyTorch, even if the tensor has shape (C, 1, 1), its data is contiguous and the stride would allow accessing it as a 1D array. So multiplier[c] is correct.

So in code, multiplier_val = multiplier[c].

So the steps:

val = input_val * multiplier_val

leaky_val = (val > 0) ? val : val * slope;

gelu_val = compute_gelu(leaky_val)

Wait, but how to compute GELU?

The exact GELU is 0.5 * x * (1 + tanh(sqrt(2/pi)*(x + 0.044715*x^3)))

Alternatively, use the approximation which is x*sigmoid(1.702*x). But the user's code uses F.gelu, which is the exact one. So need to implement the exact formula.

Alternatively, the erf-based formula:

GELU(x) = 0.5*x*(1 + erf(x / sqrt(2)))

Wait, according to some sources, the exact GELU can be approximated with that formula, but I need to confirm.

Wait, the GELU function can be written as 0.5 * x * (1 + erf(x / sqrt(2))). But sometimes the approximation is used for faster computation. Since the user's code uses F.gelu, which might use the exact version, we need to use the precise calculation.

So, in CUDA, the code would need to compute:

gelu_val = 0.5 * leaky_val * (1.0 + erf(leaky_val / sqrt(2.0)));

But erf is available in CUDA's math functions. However, the erf function is part of the CUDA math library, so we can include it.

Wait, in device code, we can use the erf function from <math.h>.

So, in the kernel, after computing the leaky_relu value:

float x = leaky_val;

float gelu_val = 0.5f * x * (1.0f + erf(x / sqrt(2.0f)));

Wait, but sqrt(2.0f) can be a precomputed constant.

Alternatively, the formula can be written as x * 0.5 * (1 + erf(x / sqrt(2))).

Alternatively, the user's code might be using the exact implementation. So we need to make sure that this matches.

Alternatively, maybe it's better to use the approximation, but since the problem requires same functionality, must replicate the exact computation.

Assuming the erf-based formula is correct for the GELU in PyTorch's F.gelu, then this is the way to go.

Now, putting this all together.

The kernel code outline:

#include <torch/extension.h>
#include <cuda_runtime.h>
#include <math.h>

__global__ void fused_ops_kernel(
    const float* input,
    const float* multiplier,
    const float* slope, // Wait, slope is a scalar, so can pass as an argument instead of a tensor.
    float* output,
    int batch_size,
    int channels,
    int height,
    int width
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= batch_size * channels * height * width) return;

    // compute n, c, h, w from idx
    int w = idx % width;
    int h = (idx / width) % height;
    int c = (idx / (width * height)) % channels;
    int n = idx / (width * height * channels);

    // get input value
    int input_offset = n * channels * height * width + c * height * width + h * width + w;
    float val = input[input_offset];

    // get multiplier value (multiplier is shape [C,1,1], so stored as a 1D array)
    float scale = multiplier[c]; // since multiplier is [C][1][1], c is the channel index, and the rest are 1, so multiplier[c] is correct.

    val *= scale;

    // apply leaky relu (slope is 0.01, but can be passed as an argument if needed)
    float slope_val = *slope; // assuming slope is passed as a pointer to a scalar
    val = (val > 0) ? val : val * slope_val;

    // apply gelu
    float x = val;
    float sqrt_2 = sqrt(2.0f);
    float erf_val = erf(x / sqrt_2);
    float gelu = 0.5f * x * (1.0f + erf_val);
    output[input_offset] = gelu;
}

Wait, but the slope is a fixed value (0.01), so we can hardcode it in the kernel to avoid passing an extra parameter. Alternatively, pass it as a constant.

Alternatively, since the problem states that the replacement must have the same parameters as the original, and the original's LeakyReLU uses the default slope (0.01), we can hardcode 0.01 into the kernel. So no need to pass it as a parameter.

So changing the code:

slope_val = 0.01f;

So the kernel becomes:

__global__ void fused_ops_kernel(
    const float* input,
    const float* multiplier,
    float* output,
    int batch_size,
    int channels,
    int height,
 int width
) {
    // ... as before, but with slope hard-coded to 0.01.

This reduces parameters.

Now, the host function:

torch::Tensor fused_ops_cuda(torch::Tensor input, torch::Tensor multiplier) {

    int batch_size = input.size(0);
    int channels = input.size(1);
    int height = input.size(2);
    int width = input.size(3);

    auto output = torch::empty_like(input);

    int num_elements = batch_size * channels * height * width;
    const int block_size = 256;
    int num_blocks = (num_elements + block_size - 1) / block_size;

    // Launch the kernel
    fused_ops_kernel<<<num_blocks, block_size>>>(
        input.data_ptr<float>(),
        multiplier.data_ptr<float>(),
        output.data_ptr<float>(),
        batch_size, channels, height, width
    );

    return output;
}

Wait, but the multiplier tensor must be contiguous? Since we are accessing it as a 1D array, we need to ensure that the multiplier is contiguous. The original code's multiplier is a nn.Parameter, which is stored as a tensor. But in the forward pass, when we call the kernel, we can pass it as is, but perhaps need to ensure it's contiguous.

In the Python code, when the kernel is called, the multiplier is passed as a tensor. So in the kernel function, the multiplier's data is accessed via its data pointer. So as long as multiplier is a contiguous tensor, the code works. 

Alternatively, in the PyTorch code, when we call the kernel, the multiplier is passed as is, but we can add a check for contiguity.

But for now, proceed, assuming the multiplier is contiguous.

Now, in the Python model:

The ModelNew class will have the same Conv2d and multiplier as the original. But instead of doing the multiply, LeakyReLU, and GELU step by step, it will call the fused kernel.

Thus, the code:

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.fused_ops = fused_ops  # the loaded kernel

    def forward(self, x):
        x = self.conv(x)
        x = self.fused_ops.fused_ops_cuda(x, self.multiplier)
        return x

But we need to load the CUDA kernel code via load_inline. Let's structure that.

First, write the CUDA kernel code as a string in Python.

Putting it all together in the Python code:

First, the CUDA kernel source code:

fused_ops_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>
#include <math.h>

__global__ void fused_ops_kernel(
    const float* input,
    const float* multiplier,
    float* output,
    int batch_size,
    int channels,
    int height,
    int width
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= batch_size * channels * height * width) return;

    // compute indices
    int w = idx % width;
    int h = (idx / width) % height;
    int c = (idx / (width * height)) % channels;
    int n = idx / (width * height * channels);

    // compute input offset
    int input_offset = n * channels * height * width + c * height * width + h * width + w;
    float val = input[input_offset];

    // apply scaling by multiplier
    float scale = multiplier[c]; // since multiplier is (C,1,1)
    val *= scale;

    // apply LeakyReLU with slope 0.01
    float slope = 0.01f;
    val = (val > 0) ? val : val * slope;

    // apply GELU
    float x = val;
    float sqrt_2 = sqrt(2.0f);
    float erf_val = erf(x / sqrt_2);
    float gelu = 0.5f * x * (1.0f + erf_val);
    output[input_offset] = gelu;
}

torch::Tensor fused_ops_cuda(torch::Tensor input, torch::Tensor multiplier) {
    int batch_size = input.size(0);
    int channels = input.size(1);
    int height = input.size(2);
    int width = input.size(3);

    auto output = torch::empty_like(input);

    int num_elements = batch_size * channels * height * width;
    const int block_size = 256;
    int num_blocks = (num_elements + block_size - 1) / block_size;

    fused_ops_kernel<<<num_blocks, block_size>>>(
        input.data_ptr<float>(),
        multiplier.data_ptr<float>(),
        output.data_ptr<float>(),
        batch_size, channels, height, width
    );

    return output;
}
"""

Then, the corresponding CPP header:

fused_ops_cpp_source = """
torch::Tensor fused_ops_cuda(torch::Tensor input, torch::Tensor multiplier);
"""

Then, in the Python code:

from torch.utils.cpp_extension import load_inline

fused_ops = load_inline(
    name="fused_ops",
    cpp_sources=fused_ops_cpp_source,
    cuda_sources=fused_ops_source,
    functions=["fused_ops_cuda"],
    verbose=True,
)

Now, the ModelNew class uses this kernel.

Wait, but in the forward pass of the model, the convolution output is a tensor, and the multiplier is a parameter. So the kernel is called with those two tensors.

Now, checking the parameters:

Original Model has conv (parameters: weight and bias), multiplier (parameter). 

The new ModelNew has the same conv and multiplier, so parameters are same. That's good.

Now, the code should work. But there are a few things to check:

- The kernel's calculation of indices: let's confirm the offset calculation.

For a 4D tensor [B, C, H, W], the offset for element (n,c,h,w) is n*(C*H*W) + c*(H*W) + h*W + w. 

Yes, that's correct. 

Another thing: the multiplier is a tensor of shape (out_channels, 1, 1). So when passed to the kernel, its data is contiguous? 

Assuming that the multiplier is a contiguous tensor, which it should be since it's a nn.Parameter. So multiplier.data_ptr<float>() points to a contiguous array of size C (since the other dimensions are 1). So multiplier[c] is correct. 

Now, the GELU implementation. Does the kernel compute it correctly? 

The formula used in the kernel is 0.5 * x * (1 + erf(x / sqrt(2))). 

Looking up GELU, according to PyTorch's documentation, the exact implementation is indeed using the error function. For example, the documentation states:

Exact implementation of the GELU activation function. 

GELU(x) = x * Φ(x), where Φ(x) is the CDF of the standard normal distribution.

Which is equivalent to 0.5 * x * (1 + erf(x / sqrt(2)))

So yes, this is correct. 

Thus, the kernel should correctly replicate the original operations. 

Now, performance considerations: 

The original code's steps after convolution are:

x = x * self.multiplier (element-wise scaling across channels)

x = self.leaky_relu(x) (element-wise)

x = F.gelu(x) (element-wise)

These three steps each involve a kernel launch, memory access, etc. By combining them into a single kernel, we reduce the number of kernel launches and memory copies, which can lead to speedup, especially for small tensors. 

For the given input sizes: batch_size=64, channels=64, 256x256 images. The convolution output is 64 x 64 x 256 x 256 = 64*64*256² = a large number of elements. 

Thus, fusing these operations into a single kernel should help reduce overhead.

Now, the code structure in Python:

The ModelNew class:

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.fused_ops = fused_ops  # the module with the kernel

    def forward(self, x):
        x = self.conv(x)
        x = self.fused_ops.fused_ops_cuda(x, self.multiplier)
        return x

Wait, but in the load_inline call, the functions are ["fused_ops_cuda"], so the function is called via fused_ops.fused_ops_cuda(a, b).

Yes.

Now, the get_init_inputs() function in the problem is:

def get_init_inputs():
    return [in_channels, out_channels, kernel_size, multiplier_shape]

So when creating the model, the parameters are passed as:

model = ModelNew(*get_init_inputs())

Thus, the __init__ of ModelNew must take the same parameters as the original Model, which it does.

Testing that all parameters are present: yes, the conv has its weights and bias, and the multiplier is a parameter. Same as original.

Thus, this should work.

Potential issues:

- The erf function in CUDA may have precision issues? Probably negligible for activations.

- The kernel's block size is set to 256. That's a common choice, but maybe tuning for larger blocks could help. However, for the purpose of this problem, it's acceptable.

- The kernel is launched with (num_blocks, block_size), which is standard.

Now, compiling the kernel:

The load_inline function should compile the CUDA code. The headers are included, and the math functions are used correctly.

Thus, the code should be correct.

Now, to write all this into the Python code block as per the problem's instructions.
</think>

```python
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

fused_ops_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>
#include <math.h>

__global__ void fused_ops_kernel(
    const float* input,
    const float* multiplier,
    float* output,
    int batch_size,
    int channels,
    int height,
    int width
) {
    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    if (idx >= batch_size * channels * height * width) return;

    int w = idx % width;
    int h = (idx / width) % height;
    int c = (idx / (width * height)) % channels;
    int n = idx / (width * height * channels);

    int input_offset = n * channels * height * width + c * height * width + h * width + w;
    float val = input[input_offset];

    float scale = multiplier[c];
    val *= scale;

    float slope = 0.01f;
    val = (val > 0) ? val : val * slope;

    float x = val;
    float sqrt_2 = sqrt(2.0f);
    float erf_val = erf(x / sqrt_2);
    float gelu = 0.5f * x * (1.0f + erf_val);
    output[input_offset] = gelu;
}

torch::Tensor fused_ops_cuda(torch::Tensor input, torch::Tensor multiplier) {
    int batch_size = input.size(0);
    int channels = input.size(1);
    int height = input.size(2);
    int width = input.size(3);

    auto output = torch::empty_like(input);

    int num_elements = batch_size * channels * height * width;
    const int block_size = 256;
    int num_blocks = (num_elements + block_size - 1) / block_size;

    fused_ops_kernel<<<num_blocks, block_size>>>(
        input.data_ptr<float>(),
        multiplier.data_ptr<float>(),
        output.data_ptr<float>(),
        batch_size, channels, height, width
    );

    return output;
}
"""

fused_ops_cpp_source = """
torch::Tensor fused_ops_cuda(torch::Tensor input, torch::Tensor multiplier);
"""

fused_ops = load_inline(
    name="fused_ops",
    cpp_sources=fused_ops_cpp_source,
    cuda_sources=fused_ops_source,
    functions=["fused_ops_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)

class ModelNew(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, multiplier_shape):
        super().__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size)
        self.multiplier = nn.Parameter(torch.randn(multiplier_shape))
        self.fused_ops = fused_ops  # Import the fused kernel

    def forward(self, x):
        x = self.conv(x)
        x = self.fused_ops.fused_ops_cuda(x, self.multiplier)
        return x
```