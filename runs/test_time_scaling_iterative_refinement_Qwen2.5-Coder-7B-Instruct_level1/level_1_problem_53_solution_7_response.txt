Please follow these steps:

1. Identify the operator to be replaced with a custom CUDA kernel.
2. Write the CUDA kernel function.
3. Create a Python wrapper around the CUDA kernel using PyTorch's `load_inline`.
4. Replace the original PyTorch operator with the custom CUDA kernel in the `ModelNew` class.
5. Ensure the new architecture works correctly by comparing the output of `ModelNew` with the output of the original `Model`.

Here is the updated architecture you need to optimize:
```python
import torch
import torch.nn as nn

class Model(nn.Module):
    """
    Simple model that performs min reduction over a specific dimension.
    """
    def __init__(self, dim: int):
        """
        Initializes the model with the dimension to reduce over.

        Args:
            dim (int): The dimension to reduce over.
        """
        super(Model, self).__init__()
        self.dim = dim

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Applies min reduction over the specified dimension to the input tensor.

        Args:
            x (torch.Tensor): Input tensor.

        Returns:
            torch.Tensor: Output tensor after min reduction over the specified dimension.
        """
        return torch.min(x, dim=self.dim)[0]

batch_size = 128
dim1 = 4096
dim2 = 4095

def get_inputs():
    x = torch.rand(batch_size, dim1, dim2)
    return [x]

def get_init_inputs():
    return [1] # Example, change to desired dimension
```

Provide the optimized architecture and the corresponding CUDA kernel in code blocks below. Ensure that the code is syntactically correct and functional when compiled.