Please provide the corrected and optimized code for the architecture ModelNew with the improved CUDA kernel for 2D Average Pooling. ```python
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for 2D Average Pooling
avg_pool_2d_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

__global__ void avg_pool_2d_kernel(const float* input, float* output, int batch_size, int channels, int input_height, int input_width, int kernel_size, int stride, int padding) {
    int n = blockIdx.x * blockDim.x + threadIdx.x;
    int c = blockIdx.y * blockDim.y + threadIdx.y;
    int h_start = blockIdx.z * blockDim.z + threadIdx.z;

    if (n >= batch_size || c >= channels || h_start >= input_height) {
        return;
    }

    int h_end = h_start + kernel_size;
    int w_start = blockIdx.w * blockDim.w + threadIdx.w;
    int w_end = w_start + kernel_size;

    if (w_start >= input_width) {
        return;
    }

    float sum = 0.0f;
    int count = 0;

    for (int i = h_start; i < h_end; ++i) {
        for (int j = w_start; j < w_end; ++j) {
            sum += input[(n * channels + c) * input_height * input_width + i * input_width + j];
            ++count;
        }
    }

    output[n * channels * input_height * input_width + h_start * input_width + w_start] = sum / count;
}

torch::Tensor avg_pool_2d_cuda(torch::Tensor input, int kernel_size, int stride, int padding) {
    auto batch_size = input.size(0);
    auto channels = input.size(1);
    auto input_height = input.size(2);
    auto input_width = input.size(3);

    auto output_height = (input_height + 2 * padding - kernel_size) / stride + 1;
    auto output_width = (input_width + 2 * padding - kernel_size) / stride + 1;

    auto output = torch::zeros({batch_size, channels, output_height, output_width}, input.options());

    const int block_size = 32;
    dim3 blocks((output_width + block_size - 1) / block_size, (output_height + block_size - 1) / block_size, (channels + block_size - 1) / block_size, (input_width + block_size - 1) / block_size);
    dim3 threads(block_size, block_size, block_size, block_size);

    avg_pool_2d_kernel<<<blocks, threads>>>(input.data_ptr<float>(), output.data_ptr<float>(), batch_size, channels, input_height, input_width, kernel_size, stride, padding);

    return output;
}
"""

avg_pool_2d_cpp_source = (
    "torch::Tensor avg_pool_2d_cuda(torch::Tensor input, int kernel_size, int stride, int padding);"
)

# Compile the inline CUDA code for 2D Average Pooling
avg_pool_2d = load_inline(
    name="avg_pool_2d",
    cpp_sources=avg_pool_2d_cpp_source,
    cuda_sources=avg_pool_2d_source,
    functions=["avg_pool_2d_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)


class ModelNew(nn.Module):
    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):
        super(ModelNew, self).__init__()
        self.kernel_size = kernel_size
        self.stride = stride if stride is not None else kernel_size
        self.padding = padding

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return avg_pool_2d.avg_pool_2d_cuda(x, self.kernel_size, self.stride, self.padding)
```

Your generated architecture ModelNew and kernel were evaluated on GPU and checked against the reference architecture Model.

Here is your Evaluation Result:
```
/data/user_data/gyeongwk/Kernel-Coder/cache/test_time_scaling_iterative_refinement_Qwen2.5-Coder-7B-Instruct_level1/level_1_problem_45_solution_0/avg_pool_2d/avg_pool_2d.so: cannot open shared object file: No such file or directory
```