[
  {
    "evaluation_id": "level_1_problem_1_solution_0",
    "task_id": "level_1_problem_1",
    "solution_id": "level_1_problem_1_solution_0",
    "compiled": true,
    "correctness": true,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "correctness_trials": "(5 / 5)",
      "profiler_info": "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \nmatmul_kernel(float const*, float const*, float*, in...         0.00%       0.000us         0.00%       0.000us       0.000us      59.884ms        99.85%      59.884ms      59.884ms             1  \n                                            aten::fill_         0.04%      25.466us         0.12%      75.242us      75.242us      92.225us         0.15%      92.225us      92.225us             1  \nvoid at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      92.225us         0.15%      92.225us      92.225us             1  \n                                            aten::zeros         1.62%       1.013ms         4.08%       2.549ms       2.549ms       0.000us         0.00%      92.225us      92.225us             1  \n                                            aten::empty         2.31%       1.445ms         2.31%       1.445ms       1.445ms       0.000us         0.00%       0.000us       0.000us             1  \n                                            aten::zero_         0.03%      15.944us         0.15%      91.186us      91.186us       0.000us         0.00%      92.225us      92.225us             1  \n                                       cudaLaunchKernel         0.10%      60.697us         0.10%      60.697us      30.349us       0.000us         0.00%       0.000us       0.000us             2  \n                                  cudaDeviceSynchronize        95.90%      59.895ms        95.90%      59.895ms      29.948ms       0.000us         0.00%       0.000us       0.000us             2  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \nSelf CPU time total: 62.455ms\nSelf CUDA time total: 59.976ms\n"
    },
    "runtime": 61.8,
    "runtime_stats": {
      "mean": 61.8,
      "std": 0.416,
      "min": 61.2,
      "max": 63.2,
      "num_trials": 100,
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    }
  },
  {
    "evaluation_id": "level_1_problem_2_solution_0",
    "task_id": "level_1_problem_2",
    "solution_id": "level_1_problem_2_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_3_solution_0",
    "task_id": "level_1_problem_3",
    "solution_id": "level_1_problem_3_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_4_solution_0",
    "task_id": "level_1_problem_4",
    "solution_id": "level_1_problem_4_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_5_solution_0",
    "task_id": "level_1_problem_5",
    "solution_id": "level_1_problem_5_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 1569730 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_6_solution_0",
    "task_id": "level_1_problem_6",
    "solution_id": "level_1_problem_6_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_7_solution_0",
    "task_id": "level_1_problem_7",
    "solution_id": "level_1_problem_7_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.39 GiB is free. Process 1569730 has 43.72 GiB memory in use. Including non-PyTorch memory, this pr..."
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_8_solution_0",
    "task_id": "level_1_problem_8",
    "solution_id": "level_1_problem_8_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_9_solution_0",
    "task_id": "level_1_problem_9",
    "solution_id": "level_1_problem_9_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.39 GiB is free. Process 1569730 has 43.72 GiB memory in use. Including non-PyTorch memory, this pr..."
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_10_solution_0",
    "task_id": "level_1_problem_10",
    "solution_id": "level_1_problem_10_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_11_solution_0",
    "task_id": "level_1_problem_11",
    "solution_id": "level_1_problem_11_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_12_solution_0",
    "task_id": "level_1_problem_12",
    "solution_id": "level_1_problem_12_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "max_difference": [
        "1052.693359",
        "1076.323730",
        "1056.454590",
        "1056.405884",
        "1074.827026"
      ],
      "avg_difference": [
        "1012.274902",
        "1034.198364",
        "1017.525879",
        "1018.519531",
        "1032.980225"
      ],
      "correctness_issue": "Output mismatch",
      "correctness_trials": "(0 / 5)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_13_solution_0",
    "task_id": "level_1_problem_13",
    "solution_id": "level_1_problem_13_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "fused_group_norm_matrix_multiplication_cuda(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3:..."
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_14_solution_0",
    "task_id": "level_1_problem_14",
    "solution_id": "level_1_problem_14_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "'NoneType' object has no attribute 'shape'"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_15_solution_0",
    "task_id": "level_1_problem_15",
    "solution_id": "level_1_problem_15_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_16_solution_0",
    "task_id": "level_1_problem_16",
    "solution_id": "level_1_problem_16_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_17_solution_0",
    "task_id": "level_1_problem_17",
    "solution_id": "level_1_problem_17_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 13)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_18_solution_0",
    "task_id": "level_1_problem_18",
    "solution_id": "level_1_problem_18_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "correctness_issue": "Output shape mismatch: Expected torch.Size([2048, 4096]), got torch.Size([8192, 8192])"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_19_solution_0",
    "task_id": "level_1_problem_19",
    "solution_id": "level_1_problem_19_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 1569730 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_20_solution_0",
    "task_id": "level_1_problem_20",
    "solution_id": "level_1_problem_20_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 3)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_21_solution_0",
    "task_id": "level_1_problem_21",
    "solution_id": "level_1_problem_21_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_22_solution_0",
    "task_id": "level_1_problem_22",
    "solution_id": "level_1_problem_22_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 1569730 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_23_solution_0",
    "task_id": "level_1_problem_23",
    "solution_id": "level_1_problem_23_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-sft-lora_level1/level_1_problem_23_solution_0/softmax/softmax.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_24_solution_0",
    "task_id": "level_1_problem_24",
    "solution_id": "level_1_problem_24_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-sft-lora_level1/level_1_problem_24_solution_0/logsoftmax/logsoftmax.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_25_solution_0",
    "task_id": "level_1_problem_25",
    "solution_id": "level_1_problem_25_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 1569730 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_26_solution_0",
    "task_id": "level_1_problem_26",
    "solution_id": "level_1_problem_26_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_27_solution_0",
    "task_id": "level_1_problem_27",
    "solution_id": "level_1_problem_27_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_28_solution_0",
    "task_id": "level_1_problem_28",
    "solution_id": "level_1_problem_28_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_29_solution_0",
    "task_id": "level_1_problem_29",
    "solution_id": "level_1_problem_29_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_30_solution_0",
    "task_id": "level_1_problem_30",
    "solution_id": "level_1_problem_30_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_31_solution_0",
    "task_id": "level_1_problem_31",
    "solution_id": "level_1_problem_31_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 6.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 1569730 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_32_solution_0",
    "task_id": "level_1_problem_32",
    "solution_id": "level_1_problem_32_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_33_solution_0",
    "task_id": "level_1_problem_33",
    "solution_id": "level_1_problem_33_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "name 'get_inputs' is not defined"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_34_solution_0",
    "task_id": "level_1_problem_34",
    "solution_id": "level_1_problem_34_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 7.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 1569730 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_35_solution_0",
    "task_id": "level_1_problem_35",
    "solution_id": "level_1_problem_35_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_36_solution_0",
    "task_id": "level_1_problem_36",
    "solution_id": "level_1_problem_36_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_37_solution_0",
    "task_id": "level_1_problem_37",
    "solution_id": "level_1_problem_37_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_38_solution_0",
    "task_id": "level_1_problem_38",
    "solution_id": "level_1_problem_38_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_39_solution_0",
    "task_id": "level_1_problem_39",
    "solution_id": "level_1_problem_39_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_40_solution_0",
    "task_id": "level_1_problem_40",
    "solution_id": "level_1_problem_40_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-sft-lora_level1/level_1_problem_40_solution_0/layer_norm/layer_norm.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_41_solution_0",
    "task_id": "level_1_problem_41",
    "solution_id": "level_1_problem_41_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 3.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 421.12 MiB is free. Process 1569730 has 43.72 GiB memory in use. Including non-PyTorch memory, this ..."
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_42_solution_0",
    "task_id": "level_1_problem_42",
    "solution_id": "level_1_problem_42_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_43_solution_0",
    "task_id": "level_1_problem_43",
    "solution_id": "level_1_problem_43_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_44_solution_0",
    "task_id": "level_1_problem_44",
    "solution_id": "level_1_problem_44_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-sft-lora_level1/level_1_problem_44_solution_0/average_pool_1d/average_pool_1d.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_45_solution_0",
    "task_id": "level_1_problem_45",
    "solution_id": "level_1_problem_45_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_46_solution_0",
    "task_id": "level_1_problem_46",
    "solution_id": "level_1_problem_46_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_47_solution_0",
    "task_id": "level_1_problem_47",
    "solution_id": "level_1_problem_47_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 1569730 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_48_solution_0",
    "task_id": "level_1_problem_48",
    "solution_id": "level_1_problem_48_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_49_solution_0",
    "task_id": "level_1_problem_49",
    "solution_id": "level_1_problem_49_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-sft-lora_level1/level_1_problem_49_solution_0/max_reduction/max_reduction.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_50_solution_0",
    "task_id": "level_1_problem_50",
    "solution_id": "level_1_problem_50_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_51_solution_0",
    "task_id": "level_1_problem_51",
    "solution_id": "level_1_problem_51_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_52_solution_0",
    "task_id": "level_1_problem_52",
    "solution_id": "level_1_problem_52_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_53_solution_0",
    "task_id": "level_1_problem_53",
    "solution_id": "level_1_problem_53_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 38)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_54_solution_0",
    "task_id": "level_1_problem_54",
    "solution_id": "level_1_problem_54_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_55_solution_0",
    "task_id": "level_1_problem_55",
    "solution_id": "level_1_problem_55_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_56_solution_0",
    "task_id": "level_1_problem_56",
    "solution_id": "level_1_problem_56_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_57_solution_0",
    "task_id": "level_1_problem_57",
    "solution_id": "level_1_problem_57_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_58_solution_0",
    "task_id": "level_1_problem_58",
    "solution_id": "level_1_problem_58_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "name 'in_channels' is not defined"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_59_solution_0",
    "task_id": "level_1_problem_59",
    "solution_id": "level_1_problem_59_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_60_solution_0",
    "task_id": "level_1_problem_60",
    "solution_id": "level_1_problem_60_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_61_solution_0",
    "task_id": "level_1_problem_61",
    "solution_id": "level_1_problem_61_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_62_solution_0",
    "task_id": "level_1_problem_62",
    "solution_id": "level_1_problem_62_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 6)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_63_solution_0",
    "task_id": "level_1_problem_63",
    "solution_id": "level_1_problem_63_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_64_solution_0",
    "task_id": "level_1_problem_64",
    "solution_id": "level_1_problem_64_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 14)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_65_solution_0",
    "task_id": "level_1_problem_65",
    "solution_id": "level_1_problem_65_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_66_solution_0",
    "task_id": "level_1_problem_66",
    "solution_id": "level_1_problem_66_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_67_solution_0",
    "task_id": "level_1_problem_67",
    "solution_id": "level_1_problem_67_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_68_solution_0",
    "task_id": "level_1_problem_68",
    "solution_id": "level_1_problem_68_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 14)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_69_solution_0",
    "task_id": "level_1_problem_69",
    "solution_id": "level_1_problem_69_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_70_solution_0",
    "task_id": "level_1_problem_70",
    "solution_id": "level_1_problem_70_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_71_solution_0",
    "task_id": "level_1_problem_71",
    "solution_id": "level_1_problem_71_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_72_solution_0",
    "task_id": "level_1_problem_72",
    "solution_id": "level_1_problem_72_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "invalid syntax (<string>, line 14)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_73_solution_0",
    "task_id": "level_1_problem_73",
    "solution_id": "level_1_problem_73_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_74_solution_0",
    "task_id": "level_1_problem_74",
    "solution_id": "level_1_problem_74_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "correctness_issue": "Output shape mismatch: Expected torch.Size([32, 64, 131084]), got torch.Size([32, 32, 131072])"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_75_solution_0",
    "task_id": "level_1_problem_75",
    "solution_id": "level_1_problem_75_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-sft-lora_level1/level_1_problem_75_solution_0/conv_transpose2d/conv_transpose2d.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_76_solution_0",
    "task_id": "level_1_problem_76",
    "solution_id": "level_1_problem_76_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_77_solution_0",
    "task_id": "level_1_problem_77",
    "solution_id": "level_1_problem_77_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "cuda_error": "CUDA Error: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_78_solution_0",
    "task_id": "level_1_problem_78",
    "solution_id": "level_1_problem_78_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "name 'markdown' is not defined"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_79_solution_0",
    "task_id": "level_1_problem_79",
    "solution_id": "level_1_problem_79_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_80_solution_0",
    "task_id": "level_1_problem_80",
    "solution_id": "level_1_problem_80_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-sft-lora_level1/level_1_problem_80_solution_0/convolution_2d/convolution_2d.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_81_solution_0",
    "task_id": "level_1_problem_81",
    "solution_id": "level_1_problem_81_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_82_solution_0",
    "task_id": "level_1_problem_82",
    "solution_id": "level_1_problem_82_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_83_solution_0",
    "task_id": "level_1_problem_83",
    "solution_id": "level_1_problem_83_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_84_solution_0",
    "task_id": "level_1_problem_84",
    "solution_id": "level_1_problem_84_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_85_solution_0",
    "task_id": "level_1_problem_85",
    "solution_id": "level_1_problem_85_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_86_solution_0",
    "task_id": "level_1_problem_86",
    "solution_id": "level_1_problem_86_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_87_solution_0",
    "task_id": "level_1_problem_87",
    "solution_id": "level_1_problem_87_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_88_solution_0",
    "task_id": "level_1_problem_88",
    "solution_id": "level_1_problem_88_solution_0",
    "compiled": true,
    "correctness": true,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "correctness_trials": "(5 / 5)",
      "profiler_info": "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n                 gelu_kernel(float const*, float*, int)         0.00%       0.000us         0.00%       0.000us       0.000us      30.688ms        98.79%      30.688ms      30.688ms             1  \n                                            aten::fill_         0.04%      14.355us         0.13%      41.784us      41.784us     376.033us         1.21%     376.033us     376.033us             1  \nvoid at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     376.033us         1.21%     376.033us     376.033us             1  \n                                       aten::zeros_like         0.07%      22.827us         4.59%       1.493ms       1.493ms       0.000us         0.00%     376.033us     376.033us             1  \n                                       aten::empty_like         0.08%      26.529us         4.36%       1.417ms       1.417ms       0.000us         0.00%       0.000us       0.000us             1  \n                                    aten::empty_strided         4.28%       1.391ms         4.28%       1.391ms       1.391ms       0.000us         0.00%       0.000us       0.000us             1  \n                                            aten::zero_         0.03%      11.055us         0.16%      52.839us      52.839us       0.000us         0.00%     376.033us     376.033us             1  \n                                       cudaLaunchKernel         0.11%      34.803us         0.11%      34.803us      17.402us       0.000us         0.00%       0.000us       0.000us             2  \n                                  cudaDeviceSynchronize        95.38%      30.998ms        95.38%      30.998ms      15.499ms       0.000us         0.00%       0.000us       0.000us             2  \n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \nSelf CPU time total: 32.498ms\nSelf CUDA time total: 31.064ms\n"
    },
    "runtime": 31.2,
    "runtime_stats": {
      "mean": 31.2,
      "std": 0.443,
      "min": 31.1,
      "max": 33.2,
      "num_trials": 100,
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    }
  },
  {
    "evaluation_id": "level_1_problem_89_solution_0",
    "task_id": "level_1_problem_89",
    "solution_id": "level_1_problem_89_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_90_solution_0",
    "task_id": "level_1_problem_90",
    "solution_id": "level_1_problem_90_solution_0",
    "compiled": true,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "runtime_error": "CUDA out of memory. Tried to allocate 4.00 GiB. GPU 0 has a total capacity of 47.40 GiB of which 3.41 GiB is free. Process 1569730 has 43.72 GiB memory in use. Including non-PyTorch memory, this process has 260.00 MiB memory in use. Of the allocated memory 0 bytes is allocated by PyTorch, and 0 bytes is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_91_solution_0",
    "task_id": "level_1_problem_91",
    "solution_id": "level_1_problem_91_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_92_solution_0",
    "task_id": "level_1_problem_92",
    "solution_id": "level_1_problem_92_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_93_solution_0",
    "task_id": "level_1_problem_93",
    "solution_id": "level_1_problem_93_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_94_solution_0",
    "task_id": "level_1_problem_94",
    "solution_id": "level_1_problem_94_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_95_solution_0",
    "task_id": "level_1_problem_95",
    "solution_id": "level_1_problem_95_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-sft-lora_level1/level_1_problem_95_solution_0/cross_entropy_loss_logsumexp_grad_scale/cross_entropy_loss_logsumexp_grad_scale.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_96_solution_0",
    "task_id": "level_1_problem_96",
    "solution_id": "level_1_problem_96_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_97_solution_0",
    "task_id": "level_1_problem_97",
    "solution_id": "level_1_problem_97_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "compilation_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-sft-lora_level1/level_1_problem_97_solution_0/scaled_dot_product_attention/scaled_dot_product_attention.so: undefined symbol: _ZNK2at10TensorBase8data_ptrI6__halfEEPT_v"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_98_solution_0",
    "task_id": "level_1_problem_98",
    "solution_id": "level_1_problem_98_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_99_solution_0",
    "task_id": "level_1_problem_99",
    "solution_id": "level_1_problem_99_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0",
      "other_error": "/data/user_data/zichunyu/Kernel-Coder/cache/test_time_scaling_base_Qwen2.5-Coder-7B-Instruct-sft-lora_level1/level_1_problem_99_solution_0/triplet_margin_loss/triplet_margin_loss.so: cannot open shared object file: No such file or directory"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  },
  {
    "evaluation_id": "level_1_problem_100_solution_0",
    "task_id": "level_1_problem_100",
    "solution_id": "level_1_problem_100_solution_0",
    "compiled": false,
    "correctness": false,
    "metadata": {
      "other_error": "error: 'NoneType' object is not callable",
      "hardware": "NVIDIA RTX A6000",
      "device": "cuda:0"
    },
    "runtime": -1.0,
    "runtime_stats": {}
  }
]