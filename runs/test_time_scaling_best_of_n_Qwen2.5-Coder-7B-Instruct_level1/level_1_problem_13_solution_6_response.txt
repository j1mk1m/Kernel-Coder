Please note that the goal here is to optimize the performance of the `forward` method using custom CUDA operators. You can replace any part of the operation with a custom implementation, including but not limited to, matrix multiplication, activation functions, etc. Feel free to use any algorithmic optimizations or operator fusion techniques you see fit. The final code should be efficient and performant when run on a GPU.