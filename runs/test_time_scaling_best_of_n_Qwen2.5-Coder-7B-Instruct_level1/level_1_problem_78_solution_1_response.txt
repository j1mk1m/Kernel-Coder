Here is the expected format of the response:

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.cpp_extension import load_inline

# Your custom CUDA code here

class ModelNew(nn.Module):
    def __init__(self, in_channels: int, out_channels: int, kernel_size: tuple, stride: tuple = (1, 1), padding: tuple = (0, 0), bias: bool = False):
        super(ModelNew, self).__init__()
        # Your custom CUDA operators here

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        # Your custom CUDA operators here
        pass
```

Make sure that your custom CUDA operators are well-documented and explain why they were chosen over the original PyTorch operators. Also, ensure that your custom CUDA operators are efficient and provide significant speedup compared to the original PyTorch operators.