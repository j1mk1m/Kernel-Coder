### Constraints:

1. You must use PyTorch's `load_inline` function to compile and load the CUDA kernels.
2. Your custom CUDA kernels should be efficient and take advantage of GPU parallelism.
3. You can modify any part of the model, including the architecture, the forward method, and adding new methods or layers.
4. You should aim to achieve significant speedup compared to the original implementation using PyTorch operators.

## Answer:
```