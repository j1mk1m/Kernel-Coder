### Guidelines:
- **Custom CUDA Kernels**: Replace any operations that can benefit from custom CUDA kernels, such as convolutions, matrix multiplications, activation functions, etc.
- **Operator Fusion**: Combine multiple operations into a single kernel if possible to reduce overhead.
- **Algorithmic Changes**: Consider alternative algorithms that could be more efficient on GPU, such as fused batch normalization, sparse attention mechanisms, etc.
- **Memory Efficiency**: Optimize memory usage to minimize data transfer between CPU and GPU.

Ensure that your implementation maintains the same functionality as the original Model class.