Hint: Consider using PyTorch's `load_inline` function to compile and link CUDA code directly within Python. Also, be aware of potential memory bandwidth limitations when implementing convolution operations on GPUs.

Here is a template for how you might structure the solution:

```python
import torch
import torch.nn as nn
from torch.utils.cpp_extension import load_inline

# Define the custom CUDA kernel for 3D Average Pooling
average_pool_3d_source = """
#include <torch/extension.h>
#include <cuda_runtime.h>

// Implement the CUDA kernel for 3D Average Pooling here
// ...

torch::Tensor average_pool_3d_cuda(torch::Tensor x, int kernel_size, int stride, int padding) {
    // Implement the CUDA function here
    // ...
    return out;
}
"""

average_pool_3d_cpp_source = (
    "torch::Tensor average_pool_3d_cuda(torch::Tensor x, int kernel_size, int stride, int padding);"
)

# Compile the inline CUDA code for 3D Average Pooling
average_pool_3d = load_inline(
    name="average_pool_3d",
    cpp_sources=average_pool_3d_cpp_source,
    cuda_sources=average_pool_3d_source,
    functions=["average_pool_3d_cuda"],
    verbose=True,
    extra_cflags=[""],
    extra_ldflags=[""],
)

class ModelNew(nn.Module):
    def __init__(self, kernel_size: int, stride: int = None, padding: int = 0):
        super(ModelNew, self).__init__()
        self.average_pool = average_pool_3d

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.average_pool.average_pool_3d_cuda(x, kernel_size, stride, padding)

if __name__ == "__main__":
    batch_size = 16
    channels = 32
    depth = 128
    height = 128
    width = 256
    kernel_size = 3
    stride = 2
    padding = 1

    model = ModelNew(kernel_size, stride, padding)
    inputs = get_inputs()
    outputs = model(inputs[0])
    print(outputs.shape)
```

```python
# Ensure the code compiles and runs without errors
assert outputs.shape == (batch_size, channels, (depth - kernel_size + 2 * padding) // stride + 1, (height - kernel_size + 2 * padding) // stride + 1, (width - kernel_size + 2 * padding) // stride + 1)
```

Your task is to implement the `average_pool_3d_source` section to optimize the 3D Average Pooling operation using custom CUDA kernels. Make sure to handle edge cases such as different padding values and strides.