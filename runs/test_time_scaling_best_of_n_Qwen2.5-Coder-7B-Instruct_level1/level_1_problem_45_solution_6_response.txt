The goal is to achieve maximum performance improvement while maintaining functionality. Feel free to use any PyTorch features including autograd, but avoid using built-in PyTorch operations that are already implemented in C++. If you need to create custom CUDA kernels, provide the source code for those kernels as well. Make sure to include all necessary imports and setup code for loading the custom CUDA kernels. 

Please ensure that the custom CUDA kernels are correctly integrated into the `ModelNew` class and used in place of the original PyTorch operations. Additionally, please document any assumptions made during the optimization process and any potential limitations of the optimized implementation.